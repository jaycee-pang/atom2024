{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importing random forest classifier from assemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Save models\n",
    "import joblib\n",
    "\n",
    "import random\n",
    "random.seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "# from sklearn 0.19.2 documentation:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar(shrink=0.7)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASA+_per_atom</th>\n",
       "      <th>ASA-</th>\n",
       "      <th>ASA_H_per_atom</th>\n",
       "      <th>ASA_P</th>\n",
       "      <th>ASA_per_atom</th>\n",
       "      <th>BCUT_PEOE_0</th>\n",
       "      <th>BCUT_PEOE_1</th>\n",
       "      <th>BCUT_PEOE_2</th>\n",
       "      <th>BCUT_PEOE_3</th>\n",
       "      <th>BCUT_SLOGP_0_per_atom</th>\n",
       "      <th>...</th>\n",
       "      <th>vsurf_Wp2_per_atom</th>\n",
       "      <th>vsurf_Wp3</th>\n",
       "      <th>vsurf_Wp4</th>\n",
       "      <th>vsurf_Wp5</th>\n",
       "      <th>vsurf_Wp6</th>\n",
       "      <th>vsurf_Wp7</th>\n",
       "      <th>vsurf_Wp8</th>\n",
       "      <th>weinerPath</th>\n",
       "      <th>weinerPol_per_atom</th>\n",
       "      <th>zagreb_per_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.215013</td>\n",
       "      <td>142.21526</td>\n",
       "      <td>6.836120</td>\n",
       "      <td>244.47214</td>\n",
       "      <td>15.890644</td>\n",
       "      <td>-2.194154</td>\n",
       "      <td>-0.719023</td>\n",
       "      <td>0.731004</td>\n",
       "      <td>2.217017</td>\n",
       "      <td>-0.086358</td>\n",
       "      <td>...</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>243.750</td>\n",
       "      <td>81.125</td>\n",
       "      <td>33.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>513</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>3.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.736764</td>\n",
       "      <td>220.71700</td>\n",
       "      <td>7.970176</td>\n",
       "      <td>205.31177</td>\n",
       "      <td>11.080960</td>\n",
       "      <td>-2.681831</td>\n",
       "      <td>-0.546122</td>\n",
       "      <td>0.637987</td>\n",
       "      <td>2.689039</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>9.878788</td>\n",
       "      <td>205.000</td>\n",
       "      <td>42.250</td>\n",
       "      <td>14.000</td>\n",
       "      <td>4.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>2.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.211856</td>\n",
       "      <td>304.34698</td>\n",
       "      <td>8.814355</td>\n",
       "      <td>271.20950</td>\n",
       "      <td>13.745438</td>\n",
       "      <td>-2.403042</td>\n",
       "      <td>-0.574742</td>\n",
       "      <td>0.596937</td>\n",
       "      <td>2.408815</td>\n",
       "      <td>-0.042698</td>\n",
       "      <td>...</td>\n",
       "      <td>12.236364</td>\n",
       "      <td>216.750</td>\n",
       "      <td>48.000</td>\n",
       "      <td>19.125</td>\n",
       "      <td>5.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4067</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.901980</td>\n",
       "      <td>195.95447</td>\n",
       "      <td>8.445429</td>\n",
       "      <td>222.74628</td>\n",
       "      <td>13.395346</td>\n",
       "      <td>-2.583713</td>\n",
       "      <td>-0.575453</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>2.567737</td>\n",
       "      <td>-0.057201</td>\n",
       "      <td>...</td>\n",
       "      <td>12.941667</td>\n",
       "      <td>216.250</td>\n",
       "      <td>63.125</td>\n",
       "      <td>26.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1508</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.612832</td>\n",
       "      <td>287.15073</td>\n",
       "      <td>9.292597</td>\n",
       "      <td>194.76367</td>\n",
       "      <td>12.833755</td>\n",
       "      <td>-2.537550</td>\n",
       "      <td>-0.628175</td>\n",
       "      <td>0.660120</td>\n",
       "      <td>2.707292</td>\n",
       "      <td>-0.049639</td>\n",
       "      <td>...</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>152.500</td>\n",
       "      <td>44.750</td>\n",
       "      <td>19.875</td>\n",
       "      <td>7.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>3569</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>3.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>10.206247</td>\n",
       "      <td>174.56108</td>\n",
       "      <td>11.438849</td>\n",
       "      <td>117.39546</td>\n",
       "      <td>13.786759</td>\n",
       "      <td>-2.647072</td>\n",
       "      <td>-0.620867</td>\n",
       "      <td>0.690330</td>\n",
       "      <td>2.605075</td>\n",
       "      <td>-0.055629</td>\n",
       "      <td>...</td>\n",
       "      <td>11.690000</td>\n",
       "      <td>112.750</td>\n",
       "      <td>19.250</td>\n",
       "      <td>8.375</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2944</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>8.224840</td>\n",
       "      <td>221.81551</td>\n",
       "      <td>10.469413</td>\n",
       "      <td>138.76630</td>\n",
       "      <td>14.219854</td>\n",
       "      <td>-2.554365</td>\n",
       "      <td>-0.615955</td>\n",
       "      <td>0.599157</td>\n",
       "      <td>2.565347</td>\n",
       "      <td>-0.088887</td>\n",
       "      <td>...</td>\n",
       "      <td>13.371622</td>\n",
       "      <td>159.875</td>\n",
       "      <td>43.250</td>\n",
       "      <td>14.125</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>975</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>2.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>8.642949</td>\n",
       "      <td>161.90437</td>\n",
       "      <td>8.153549</td>\n",
       "      <td>186.68533</td>\n",
       "      <td>12.940353</td>\n",
       "      <td>-2.492239</td>\n",
       "      <td>-0.584590</td>\n",
       "      <td>0.657366</td>\n",
       "      <td>2.468000</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>...</td>\n",
       "      <td>11.259615</td>\n",
       "      <td>138.875</td>\n",
       "      <td>37.250</td>\n",
       "      <td>13.875</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>3.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>7.236550</td>\n",
       "      <td>241.08192</td>\n",
       "      <td>7.003955</td>\n",
       "      <td>254.33978</td>\n",
       "      <td>11.466057</td>\n",
       "      <td>-2.665590</td>\n",
       "      <td>-0.491930</td>\n",
       "      <td>0.530384</td>\n",
       "      <td>2.600261</td>\n",
       "      <td>-0.048795</td>\n",
       "      <td>...</td>\n",
       "      <td>8.043860</td>\n",
       "      <td>118.500</td>\n",
       "      <td>19.125</td>\n",
       "      <td>7.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4011</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>8.511531</td>\n",
       "      <td>277.76974</td>\n",
       "      <td>8.521127</td>\n",
       "      <td>280.75598</td>\n",
       "      <td>13.279703</td>\n",
       "      <td>-2.568112</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>0.691940</td>\n",
       "      <td>2.629537</td>\n",
       "      <td>-0.056514</td>\n",
       "      <td>...</td>\n",
       "      <td>12.631356</td>\n",
       "      <td>234.375</td>\n",
       "      <td>54.000</td>\n",
       "      <td>19.125</td>\n",
       "      <td>4.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3645</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>2.983051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ASA+_per_atom       ASA-  ASA_H_per_atom      ASA_P  ASA_per_atom  \\\n",
       "0        10.215013  142.21526        6.836120  244.47214     15.890644   \n",
       "1         7.736764  220.71700        7.970176  205.31177     11.080960   \n",
       "2         8.211856  304.34698        8.814355  271.20950     13.745438   \n",
       "3         8.901980  195.95447        8.445429  222.74628     13.395346   \n",
       "4         7.612832  287.15073        9.292597  194.76367     12.833755   \n",
       "..             ...        ...             ...        ...           ...   \n",
       "277      10.206247  174.56108       11.438849  117.39546     13.786759   \n",
       "278       8.224840  221.81551       10.469413  138.76630     14.219854   \n",
       "279       8.642949  161.90437        8.153549  186.68533     12.940353   \n",
       "280       7.236550  241.08192        7.003955  254.33978     11.466057   \n",
       "281       8.511531  277.76974        8.521127  280.75598     13.279703   \n",
       "\n",
       "     BCUT_PEOE_0  BCUT_PEOE_1  BCUT_PEOE_2  BCUT_PEOE_3  \\\n",
       "0      -2.194154    -0.719023     0.731004     2.217017   \n",
       "1      -2.681831    -0.546122     0.637987     2.689039   \n",
       "2      -2.403042    -0.574742     0.596937     2.408815   \n",
       "3      -2.583713    -0.575453     0.617978     2.567737   \n",
       "4      -2.537550    -0.628175     0.660120     2.707292   \n",
       "..           ...          ...          ...          ...   \n",
       "277    -2.647072    -0.620867     0.690330     2.605075   \n",
       "278    -2.554365    -0.615955     0.599157     2.565347   \n",
       "279    -2.492239    -0.584590     0.657366     2.468000   \n",
       "280    -2.665590    -0.491930     0.530384     2.600261   \n",
       "281    -2.568112    -0.618748     0.691940     2.629537   \n",
       "\n",
       "     BCUT_SLOGP_0_per_atom  ...  vsurf_Wp2_per_atom  vsurf_Wp3  vsurf_Wp4  \\\n",
       "0                -0.086358  ...           21.333333    243.750     81.125   \n",
       "1                -0.052606  ...            9.878788    205.000     42.250   \n",
       "2                -0.042698  ...           12.236364    216.750     48.000   \n",
       "3                -0.057201  ...           12.941667    216.250     63.125   \n",
       "4                -0.049639  ...            9.900000    152.500     44.750   \n",
       "..                     ...  ...                 ...        ...        ...   \n",
       "277              -0.055629  ...           11.690000    112.750     19.250   \n",
       "278              -0.088887  ...           13.371622    159.875     43.250   \n",
       "279              -0.066054  ...           11.259615    138.875     37.250   \n",
       "280              -0.048795  ...            8.043860    118.500     19.125   \n",
       "281              -0.056514  ...           12.631356    234.375     54.000   \n",
       "\n",
       "     vsurf_Wp5  vsurf_Wp6  vsurf_Wp7  vsurf_Wp8  weinerPath  \\\n",
       "0       33.000     10.000      0.750      0.000         513   \n",
       "1       14.000      4.375      0.375      0.000        3825   \n",
       "2       19.125      5.750      0.250      0.000        4067   \n",
       "3       26.000      8.000      1.000      0.000        1508   \n",
       "4       19.875      7.750      1.000      0.375        3569   \n",
       "..         ...        ...        ...        ...         ...   \n",
       "277      8.375      2.625      0.125      0.000        2944   \n",
       "278     14.125      2.250      0.000      0.000         975   \n",
       "279     13.875      3.500      0.250      0.000        1301   \n",
       "280      7.250      2.250      0.000      0.000        4011   \n",
       "281     19.125      4.250      0.125      0.000        3645   \n",
       "\n",
       "     weinerPol_per_atom  zagreb_per_atom  \n",
       "0              0.925926         3.407407  \n",
       "1              0.878788         2.939394  \n",
       "2              0.909091         3.200000  \n",
       "3              0.933333         3.066667  \n",
       "4              0.818182         3.018182  \n",
       "..                  ...              ...  \n",
       "277            0.880000         3.200000  \n",
       "278            0.810811         2.918919  \n",
       "279            0.846154         3.025641  \n",
       "280            0.982456         3.333333  \n",
       "281            0.932203         2.983051  \n",
       "\n",
       "[282 rows x 306 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data file\n",
    "uq_path = \"/Users/radhi/Desktop/CAPSTONE_DATA/NEK_data_4Berkeley/NEK3\" \n",
    "train_x_df = pd.read_csv(uq_path+\"/NEK3_binding_random_fold1_trainX.csv\")\n",
    "train_y_df = pd.read_csv(uq_path+\"/NEK3_binding_random_fold1_trainY.csv\")\n",
    "test_x_df = pd.read_csv(uq_path+\"/NEK3_binding_random_fold1_testX.csv\")\n",
    "test_y_df = pd.read_csv(uq_path+\"/NEK3_binding_random_fold1_testY.csv\")\n",
    "test_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1122, 306)\n",
      "(1122,)\n"
     ]
    }
   ],
   "source": [
    "# Transform data to PyTorch tensors\n",
    "\n",
    "# Scale data\n",
    "x_df = pd.concat([train_x_df, test_x_df])\n",
    "\n",
    "scaling=StandardScaler()\n",
    " \n",
    "# Use fit and transform method \n",
    "scaling.fit(x_df)\n",
    "Scaled_data=scaling.transform(x_df)\n",
    "train_x = scaling.transform(train_x_df)\n",
    "test_x = scaling.transform(test_x_df) \n",
    "\n",
    "train_y = train_y_df.to_numpy().flatten()\n",
    "test_y = test_y_df.to_numpy().flatten()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Construct a RF classification model\n",
    "\n",
    "# creating a RF classifier\n",
    "clf = BalancedRandomForestClassifier(n_estimators = 100, class_weight = \"balanced\")  \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(train_x, train_y)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "train_pred_y = clf.predict(train_x)\n",
    "test_pred_y = clf.predict(test_x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"650pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 650.25 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 646.25,-307 646.25,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#47a4e7\" stroke=\"black\" points=\"454.88,-303 267.12,-303 267.12,-250 454.88,-250 454.88,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vdw_vol_per_atom &lt;= 2.382</text>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.066, 0.934]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"353.62,-214 170.38,-214 170.38,-161 353.62,-161 353.62,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"262\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GCUT_SLOGP_1 &lt;= 1.373</text>\n",
       "<text text-anchor=\"middle\" x=\"262\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 94.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"262\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.058, 0.942]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M331.56,-249.63C321.68,-240.95 310.51,-231.13 300.06,-221.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"302.45,-219.39 292.63,-215.42 297.83,-224.65 302.45,-219.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"293.1\" y=\"-233.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>50</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"550,-214 372,-214 372,-161 550,-161 550,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GCUT_PEOE_3 &lt;= &#45;2.212</text>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;50 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M390.73,-249.63C400.72,-240.95 412,-231.13 422.56,-221.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"424.82,-224.62 430.07,-215.41 420.23,-219.33 424.82,-224.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"429.48\" y=\"-233.56\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#44a2e6\" stroke=\"black\" points=\"184,-125 0,-125 0,-72 184,-72 184,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">b_count_per_atom &lt;= &#45;2.17</text>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 89.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.052, 0.948]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.45,-160.63C193.04,-151.21 172.02,-140.45 152.8,-130.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.49,-127.55 143.99,-126.11 151.3,-133.78 154.49,-127.55\"/>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>47</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"347.88,-125 202.12,-125 202.12,-72 347.88,-72 347.88,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_CW6 &lt;= &#45;1.038</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;47 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.83,-160.87C266.97,-153.24 268.24,-144.72 269.47,-136.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"272.91,-137.15 270.93,-126.75 265.99,-136.12 272.91,-137.15\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"103,-36 49,-36 49,0 103,0 103,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.76,-71.8C85.17,-63.99 83.41,-55.36 81.78,-47.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.26,-46.91 79.83,-37.81 78.4,-48.31 85.26,-46.91\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"175,-36 121,-36 121,0 175,0 175,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.34,-71.8C116.36,-63.35 123.07,-53.95 129.13,-45.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.8,-47.74 134.76,-37.56 126.1,-43.67 131.8,-47.74\"/>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>48</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"274,-36 220,-36 220,0 274,0 274,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 47&#45;&gt;48 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>47&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.83,-71.8C263.01,-63.89 259.9,-55.16 257.02,-47.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.35,-46 253.69,-37.76 253.75,-48.35 260.35,-46\"/>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>49</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"346,-36 292,-36 292,0 346,0 346,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"319\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 47&#45;&gt;49 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>47&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.41,-71.8C293.99,-63.62 299.07,-54.55 303.71,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.71,-48.09 308.55,-37.65 300.6,-44.66 306.71,-48.09\"/>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>51</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"507.25,-117.5 390.75,-117.5 390.75,-79.5 507.25,-79.5 507.25,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"449\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"449\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;51 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>50&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.46,-160.87C456.09,-150.92 454.51,-139.47 453.09,-129.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456.56,-128.71 451.73,-119.28 449.63,-129.66 456.56,-128.71\"/>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>52</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"642.25,-117.5 525.75,-117.5 525.75,-79.5 642.25,-79.5 642.25,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"584\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"584\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.57,-160.63C513.79,-149.16 532.8,-135.72 548.85,-124.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"550.53,-127.46 556.68,-118.83 546.49,-121.74 550.53,-127.46\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x2c1ccd340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"584pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 584.12 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 580.12,-307 580.12,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#46a4e7\" stroke=\"black\" points=\"378.62,-303 223.88,-303 223.88,-250 378.62,-250 378.62,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.25\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">PC&#45;_per_atom &lt;= 0.99</text>\n",
       "<text text-anchor=\"middle\" x=\"301.25\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"301.25\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.062, 0.938]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#43a2e6\" stroke=\"black\" points=\"290.5,-214 144,-214 144,-161 290.5,-161 290.5,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.25\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_Wp7 &lt;= 3.77</text>\n",
       "<text text-anchor=\"middle\" x=\"217.25\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 86.6%</text>\n",
       "<text text-anchor=\"middle\" x=\"217.25\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.048, 0.952]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.5,-249.87C268.2,-241.27 258.81,-231.55 250,-222.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.63,-220.1 243.16,-215.34 247.59,-224.96 252.63,-220.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.67\" y=\"-233.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>54</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"464.38,-214 308.12,-214 308.12,-161 464.38,-161 464.38,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SlogP_VSA0 &lt;= &#45;1.191</text>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13.4%</text>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;54 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.29,-249.87C334.69,-241.27 344.19,-231.55 353.11,-222.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.55,-224.93 360.03,-215.33 350.54,-220.04 355.55,-224.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.38\" y=\"-233.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#42a1e6\" stroke=\"black\" points=\"146.5,-125 0,-125 0,-72 146.5,-72 146.5,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_HB3 &lt;= 0.954</text>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 82.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.042, 0.958]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.44,-160.63C159.19,-151.42 141.85,-140.95 125.88,-131.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.81,-128.38 117.44,-126.2 124.19,-134.37 127.81,-128.38\"/>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>51</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"286.12,-125 164.38,-125 164.38,-72 286.12,-72 286.12,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FASA+ &lt;= &#45;0.331</text>\n",
       "<text text-anchor=\"middle\" x=\"225.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"225.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;51 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.61,-160.87C220.31,-153.24 221.09,-144.72 221.85,-136.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.31,-137.04 222.74,-126.76 218.34,-136.39 225.31,-137.04\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"68.25,-36 14.25,-36 14.25,0 68.25,0 68.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"41.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.77,-71.8C59.51,-63.8 55.91,-54.96 52.59,-46.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.9,-45.67 48.89,-37.73 49.42,-48.31 55.9,-45.67\"/>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>46</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"140.25,-36 86.25,-36 86.25,0 140.25,0 140.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;46 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.35,-71.8C90.47,-63.71 95.03,-54.76 99.21,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.31,-48.18 103.73,-37.68 96.07,-45 102.31,-48.18\"/>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>52</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"232.25,-36 178.25,-36 178.25,0 232.25,0 232.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 51&#45;&gt;52 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>51&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.7,-71.8C216.71,-63.99 214.51,-55.36 212.48,-47.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"215.9,-46.62 210.04,-37.8 209.12,-48.35 215.9,-46.62\"/>\n",
       "</g>\n",
       "<!-- 53 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>53</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"304.25,-36 250.25,-36 250.25,0 304.25,0 304.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 51&#45;&gt;53 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>51&#45;&gt;53</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M242.28,-71.8C247.81,-63.44 253.97,-54.15 259.55,-45.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.33,-47.86 264.93,-37.59 256.49,-44 262.33,-47.86\"/>\n",
       "</g>\n",
       "<!-- 55 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>55</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"436.5,-117.5 320,-117.5 320,-79.5 436.5,-79.5 436.5,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.25\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.4%</text>\n",
       "<text text-anchor=\"middle\" x=\"378.25\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 54&#45;&gt;55 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>54&#45;&gt;55</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.89,-160.87C382.98,-150.92 381.93,-139.47 380.98,-129.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"384.47,-128.92 380.07,-119.29 377.5,-129.56 384.47,-128.92\"/>\n",
       "</g>\n",
       "<!-- 56 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>56</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"576.12,-117.5 454.38,-117.5 454.38,-79.5 576.12,-79.5 576.12,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"515.25\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"515.25\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 54&#45;&gt;56 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>54&#45;&gt;56</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M424.6,-160.63C441.62,-149.16 461.55,-135.72 478.38,-124.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"480.3,-127.29 486.64,-118.8 476.39,-121.49 480.3,-127.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x2c1ccd8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"376pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 376.00 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 372,-307 372,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#44a3e6\" stroke=\"black\" points=\"202.5,-303 56,-303 56,-250 202.5,-250 202.5,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.25\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">h_pavgQ &lt;= &#45;2.163</text>\n",
       "<text text-anchor=\"middle\" x=\"129.25\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"129.25\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.054, 0.946]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"116.5,-206.5 0,-206.5 0,-168.5 116.5,-168.5 116.5,-206.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.25\" y=\"-189.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"58.25\" y=\"-174.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.33,-249.87C99.51,-239.06 89.24,-226.47 80.3,-215.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.16,-213.49 74.12,-207.95 77.73,-217.91 83.16,-213.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.65\" y=\"-225.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#43a2e6\" stroke=\"black\" points=\"266,-214 134.5,-214 134.5,-161 266,-161 266,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.25\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FASA&#45; &lt;= &#45;1.554</text>\n",
       "<text text-anchor=\"middle\" x=\"200.25\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 97.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"200.25\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.05, 0.95]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.17,-249.87C157.04,-241.45 164.79,-231.95 172.11,-222.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.67,-225.38 178.28,-215.42 169.24,-220.96 174.67,-225.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.75\" y=\"-233.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"176.5,-117.5 60,-117.5 60,-79.5 176.5,-79.5 176.5,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.25\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"118.25\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M176.09,-160.87C165.7,-149.84 153.56,-136.97 143.1,-125.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.92,-123.76 136.52,-118.88 140.83,-128.56 145.92,-123.76\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#42a2e6\" stroke=\"black\" points=\"368,-125 194.5,-125 194.5,-72 368,-72 368,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">BCUT_SLOGP_1 &lt;= 1.57</text>\n",
       "<text text-anchor=\"middle\" x=\"281.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"281.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.045, 0.955]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.11,-160.87C232.12,-152.27 241.17,-142.55 249.67,-133.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"251.99,-136.06 256.24,-126.36 246.87,-131.29 251.99,-136.06\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"272.25,-36 218.25,-36 218.25,0 272.25,0 272.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"245.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269.46,-71.8C265.76,-63.71 261.65,-54.76 257.88,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.18,-45.34 253.83,-37.71 254.82,-48.25 261.18,-45.34\"/>\n",
       "</g>\n",
       "<!-- 64 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>64</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"344.25,-36 290.25,-36 290.25,0 344.25,0 344.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;64 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;64</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M293.04,-71.8C296.74,-63.71 300.85,-54.76 304.62,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.68,-48.25 308.67,-37.71 301.32,-45.34 307.68,-48.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x2c1ccd340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export the first three decision trees from the forest\n",
    "\n",
    "for i in range(3):\n",
    "    tree = clf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=train_x_df.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[749 309]\n",
      " [  0  64]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "train_cm = confusion_matrix(train_y, train_pred_y)\n",
    "\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 train set\",fontsize=20)\n",
    "plot_confusion_matrix(train_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[172  93]\n",
      " [  5  12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "test_cm = confusion_matrix(test_y, test_pred_y)\n",
    "\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 test set\",fontsize=20)\n",
    "plot_confusion_matrix(test_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc8400&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc0700&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc8400&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc0700&gt;})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight='balanced'),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc8400>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2c4fc0700>})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a long time. Try loading the saved model.\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,80)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = BalancedRandomForestClassifier(class_weight = \"balanced\")\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=30, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 56, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "# Best hyperparameters: {'max_depth': 34, 'n_estimators': 336}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balanceRFC_randomCV_NEK3_binding.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "\n",
    "# save\n",
    "joblib.dump(best_rf, \"balanceRFC_randomCV_NEK3_binding.pkl\") \n",
    "\n",
    "# load\n",
    "#clf2 = joblib.load(\"balanceRFC_randomCV_NEK2_binding.pkl\")\n",
    "#clf2.predict(X[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[739 319]\n",
      " [  0  64]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "train_pred_y_best = best_rf.predict(train_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "train_best_cm = confusion_matrix(train_y, train_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 train set\",fontsize=20)\n",
    "plot_confusion_matrix(train_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[178  87]\n",
      " [  4  13]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "test_pred_y_best = best_rf.predict(test_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "test_best_cm = confusion_matrix(test_y, test_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 test set\",fontsize=20)\n",
    "plot_confusion_matrix(test_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6773049645390071\n",
      "Precision: 0.13\n",
      "Recall: 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_y, test_pred_y_best)\n",
    "precision = precision_score(test_y, test_pred_y_best)\n",
    "recall = recall_score(test_y, test_pred_y_best)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   9.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   9.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   9.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   9.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   9.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   9.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   5.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   9.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   9.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   9.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   9.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time= 4.1min\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time= 4.1min\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time= 4.0min\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time= 4.0min\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time= 4.0min\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time= 4.1min\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time= 4.1min\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time= 4.1min\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=8,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=8,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
       "             n_jobs=8,\n",
       "             param_grid={'max_depth': [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         'min_samples_leaf': [2, 3, 4, 5],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a very long time. Try load from the best model.\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(100, 2000, 5, dtype = int),\n",
    "    'max_depth': [20, 40, 60, 80, 100, 150, 200, 220],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Base model\n",
    "rf_grid = RandomForestClassifier(criterion = 'entropy', bootstrap = True)\n",
    "# Instantiate the grid search model\n",
    "grid_rf_search = GridSearchCV(estimator = rf_grid, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = 8, verbose = 2)\n",
    "grid_rf_search.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_grid = grid_rf_search.best_estimator_\n",
    "grid_rf_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balanceRFC_gridCV_NEK3_binding.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "\n",
    "# save\n",
    "joblib.dump(best_rf_grid, \"balanceRFC_gridCV_NEK3_binding.pkl\") \n",
    "\n",
    "# load\n",
    "#clf2 = joblib.load(\"balanceRFC_gridCV_NEK2_binding.pkl\")\n",
    "#clf2.predict(X[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1058    0]\n",
      " [   5   59]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "train_pred_y_best = best_rf_grid.predict(train_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "train_best_cm = confusion_matrix(train_y, train_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 train set (grid)\",fontsize=20)\n",
    "plot_confusion_matrix(train_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[265   0]\n",
      " [ 17   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "test_pred_y_best = best_rf_grid.predict(test_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "test_best_cm = confusion_matrix(test_y, test_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK3 test set (grid)\",fontsize=20)\n",
    "plot_confusion_matrix(test_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(best_rf_grid.estimators_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1    2         3    4         5         6    7    8    9   ...  \\\n",
       "0     1.0  1.00  1.0  1.000000  1.0  0.500000  1.000000  1.0  1.0  1.0  ...   \n",
       "1     1.0  1.00  1.0  1.000000  1.0  1.000000  1.000000  1.0  1.0  1.0  ...   \n",
       "2     1.0  1.00  1.0  1.000000  1.0  1.000000  0.666667  1.0  1.0  1.0  ...   \n",
       "3     1.0  1.00  1.0  1.000000  1.0  1.000000  1.000000  1.0  1.0  1.0  ...   \n",
       "4     1.0  1.00  1.0  1.000000  1.0  1.000000  1.000000  1.0  1.0  1.0  ...   \n",
       "...   ...   ...  ...       ...  ...       ...       ...  ...  ...  ...  ...   \n",
       "1117  0.0  0.00  1.0  0.000000  0.0  0.000000  1.000000  0.0  0.5  1.0  ...   \n",
       "1118  1.0  0.00  0.0  0.333333  0.0  0.333333  0.000000  0.0  1.0  1.0  ...   \n",
       "1119  1.0  0.50  0.0  0.500000  1.0  0.000000  1.000000  0.0  0.0  1.0  ...   \n",
       "1120  0.0  1.00  1.0  0.500000  1.0  0.000000  0.000000  1.0  0.0  0.0  ...   \n",
       "1121  1.0  0.25  1.0  1.000000  0.0  1.000000  1.000000  1.0  0.0  0.0  ...   \n",
       "\n",
       "       90        91        92    93   94   95        96        97   98    99  \n",
       "0     1.0  1.000000  1.000000  1.00  1.0  1.0  1.000000  1.000000  1.0  1.00  \n",
       "1     1.0  1.000000  1.000000  1.00  1.0  1.0  1.000000  1.000000  1.0  1.00  \n",
       "2     1.0  1.000000  1.000000  1.00  1.0  1.0  1.000000  1.000000  1.0  1.00  \n",
       "3     1.0  1.000000  1.000000  1.00  1.0  1.0  1.000000  1.000000  1.0  1.00  \n",
       "4     1.0  1.000000  1.000000  1.00  1.0  1.0  1.000000  1.000000  1.0  1.00  \n",
       "...   ...       ...       ...   ...  ...  ...       ...       ...  ...   ...  \n",
       "1117  0.5  0.333333  0.000000  0.25  1.0  0.0  0.333333  0.500000  0.0  1.00  \n",
       "1118  0.0  0.000000  1.000000  0.00  1.0  1.0  0.333333  0.666667  1.0  0.25  \n",
       "1119  0.0  1.000000  1.000000  0.00  1.0  0.0  0.500000  0.000000  0.0  0.00  \n",
       "1120  0.0  1.000000  0.000000  1.00  1.0  1.0  0.000000  1.000000  0.0  0.00  \n",
       "1121  0.5  0.000000  0.666667  1.00  1.0  1.0  0.000000  0.500000  0.0  0.00  \n",
       "\n",
       "[1122 rows x 100 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree predictions\n",
    "train_proba0_df = pd.DataFrame()\n",
    "train_proba1_df = pd.DataFrame()\n",
    "test_proba0_df = pd.DataFrame()\n",
    "test_proba1_df = pd.DataFrame()\n",
    "\n",
    "for tree_num in np.arange(len(best_rf_grid.estimators_)):\n",
    "    train_proba_temp = best_rf_grid.estimators_[tree_num].predict_proba(train_x)\n",
    "    train_proba0_df[tree_num] = train_proba_temp[:,0]\n",
    "    train_proba1_df[tree_num] = train_proba_temp[:,1]\n",
    "    test_proba_temp = best_rf_grid.estimators_[tree_num].predict_proba(test_x)\n",
    "    test_proba0_df[tree_num] = test_proba_temp[:,0]\n",
    "    test_proba1_df[tree_num] = test_proba_temp[:,1]\n",
    "    \n",
    "train_proba0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.294449\n",
       "1      0.280385\n",
       "2      0.227858\n",
       "3      0.210983\n",
       "4      0.219043\n",
       "         ...   \n",
       "277    0.428043\n",
       "278    0.100000\n",
       "279    0.246183\n",
       "280    0.366743\n",
       "281    0.256432\n",
       "Length: 282, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = test_proba0_df.std(axis=1)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_y_pred_grid</th>\n",
       "      <th>train_y</th>\n",
       "      <th>train_proba0_std_grid</th>\n",
       "      <th>train_proba1_std_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111351</td>\n",
       "      <td>0.111351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157534</td>\n",
       "      <td>0.157534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041464</td>\n",
       "      <td>0.041464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201084</td>\n",
       "      <td>0.201084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448721</td>\n",
       "      <td>0.448721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442777</td>\n",
       "      <td>0.442777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441190</td>\n",
       "      <td>0.441190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469792</td>\n",
       "      <td>0.469792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458214</td>\n",
       "      <td>0.458214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_y_pred_grid  train_y  train_proba0_std_grid  train_proba1_std_grid\n",
       "0                     0        0               0.111351               0.111351\n",
       "1                     0        0               0.157534               0.157534\n",
       "2                     0        0               0.041464               0.041464\n",
       "3                     0        0               0.201084               0.201084\n",
       "4                     0        0               0.100000               0.100000\n",
       "...                 ...      ...                    ...                    ...\n",
       "1117                  1        1               0.448721               0.448721\n",
       "1118                  1        1               0.442777               0.442777\n",
       "1119                  1        1               0.441190               0.441190\n",
       "1120                  1        1               0.469792               0.469792\n",
       "1121                  1        1               0.458214               0.458214\n",
       "\n",
       "[1122 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty dataframe\n",
    "train_perf_df = pd.DataFrame()\n",
    "test_perf_df = pd.DataFrame()\n",
    "\n",
    "# Predictions\n",
    "train_perf_df['train_y_pred_grid'] = train_pred_y_best\n",
    "test_perf_df['test_y_pred_grid'] = test_pred_y_best\n",
    "\n",
    "# Actual\n",
    "train_perf_df['train_y'] = train_y\n",
    "test_perf_df['test_y'] = test_y\n",
    "\n",
    "# Variances\n",
    "train_perf_df['train_proba0_std_grid'] = train_proba0_df.std(axis=1)\n",
    "train_perf_df['train_proba1_std_grid'] = train_proba1_df.std(axis=1)\n",
    "test_perf_df['test_proba0_std_grid'] = test_proba0_df.std(axis=1)\n",
    "test_perf_df['test_proba1_std_grid'] = test_proba1_df.std(axis=1)\n",
    "\n",
    "train_perf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
