{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importing random forest classifier from assemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Save models\n",
    "import joblib\n",
    "\n",
    "import random\n",
    "random.seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "# from sklearn 0.19.2 documentation:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar(shrink=0.7)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASA+_per_atom</th>\n",
       "      <th>ASA-</th>\n",
       "      <th>ASA_H_per_atom</th>\n",
       "      <th>ASA_P</th>\n",
       "      <th>ASA_per_atom</th>\n",
       "      <th>BCUT_PEOE_0</th>\n",
       "      <th>BCUT_PEOE_1</th>\n",
       "      <th>BCUT_PEOE_2</th>\n",
       "      <th>BCUT_PEOE_3</th>\n",
       "      <th>BCUT_SLOGP_0_per_atom</th>\n",
       "      <th>...</th>\n",
       "      <th>vsurf_Wp2_per_atom</th>\n",
       "      <th>vsurf_Wp3</th>\n",
       "      <th>vsurf_Wp4</th>\n",
       "      <th>vsurf_Wp5</th>\n",
       "      <th>vsurf_Wp6</th>\n",
       "      <th>vsurf_Wp7</th>\n",
       "      <th>vsurf_Wp8</th>\n",
       "      <th>weinerPath</th>\n",
       "      <th>weinerPol_per_atom</th>\n",
       "      <th>zagreb_per_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.994013</td>\n",
       "      <td>175.26022</td>\n",
       "      <td>9.389342</td>\n",
       "      <td>160.19148</td>\n",
       "      <td>12.411823</td>\n",
       "      <td>-2.771648</td>\n",
       "      <td>-0.577210</td>\n",
       "      <td>0.571201</td>\n",
       "      <td>2.757304</td>\n",
       "      <td>-0.052158</td>\n",
       "      <td>...</td>\n",
       "      <td>8.502358</td>\n",
       "      <td>131.625</td>\n",
       "      <td>39.500</td>\n",
       "      <td>16.500</td>\n",
       "      <td>4.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2284</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>2.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.143989</td>\n",
       "      <td>172.74998</td>\n",
       "      <td>8.340377</td>\n",
       "      <td>158.41364</td>\n",
       "      <td>10.510427</td>\n",
       "      <td>-2.761202</td>\n",
       "      <td>-0.605943</td>\n",
       "      <td>0.736091</td>\n",
       "      <td>2.765514</td>\n",
       "      <td>-0.048581</td>\n",
       "      <td>...</td>\n",
       "      <td>11.167808</td>\n",
       "      <td>314.375</td>\n",
       "      <td>84.125</td>\n",
       "      <td>29.750</td>\n",
       "      <td>5.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6535</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>2.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.558447</td>\n",
       "      <td>275.62744</td>\n",
       "      <td>10.419536</td>\n",
       "      <td>185.81779</td>\n",
       "      <td>15.728617</td>\n",
       "      <td>-2.267313</td>\n",
       "      <td>-0.722016</td>\n",
       "      <td>0.690390</td>\n",
       "      <td>2.228887</td>\n",
       "      <td>-0.064243</td>\n",
       "      <td>...</td>\n",
       "      <td>12.732143</td>\n",
       "      <td>115.250</td>\n",
       "      <td>17.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1462</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.640180</td>\n",
       "      <td>209.40883</td>\n",
       "      <td>9.224951</td>\n",
       "      <td>131.75505</td>\n",
       "      <td>11.913830</td>\n",
       "      <td>-2.534188</td>\n",
       "      <td>-0.638915</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>2.705784</td>\n",
       "      <td>-0.055374</td>\n",
       "      <td>...</td>\n",
       "      <td>9.086735</td>\n",
       "      <td>94.375</td>\n",
       "      <td>19.375</td>\n",
       "      <td>8.625</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2904</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>3.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.034180</td>\n",
       "      <td>194.92766</td>\n",
       "      <td>11.159462</td>\n",
       "      <td>154.57048</td>\n",
       "      <td>14.929475</td>\n",
       "      <td>-2.472854</td>\n",
       "      <td>-0.686740</td>\n",
       "      <td>0.731408</td>\n",
       "      <td>2.491220</td>\n",
       "      <td>-0.059509</td>\n",
       "      <td>...</td>\n",
       "      <td>15.618902</td>\n",
       "      <td>214.250</td>\n",
       "      <td>54.125</td>\n",
       "      <td>22.500</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1705</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>3.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>9.364868</td>\n",
       "      <td>148.06656</td>\n",
       "      <td>9.751122</td>\n",
       "      <td>122.57384</td>\n",
       "      <td>11.608300</td>\n",
       "      <td>-2.537512</td>\n",
       "      <td>-0.599106</td>\n",
       "      <td>0.504315</td>\n",
       "      <td>2.707295</td>\n",
       "      <td>-0.041365</td>\n",
       "      <td>...</td>\n",
       "      <td>9.369318</td>\n",
       "      <td>173.875</td>\n",
       "      <td>60.000</td>\n",
       "      <td>29.625</td>\n",
       "      <td>13.875</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.375</td>\n",
       "      <td>4841</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>9.508312</td>\n",
       "      <td>134.60069</td>\n",
       "      <td>8.863824</td>\n",
       "      <td>177.13689</td>\n",
       "      <td>11.547717</td>\n",
       "      <td>-2.665385</td>\n",
       "      <td>-0.478010</td>\n",
       "      <td>0.442054</td>\n",
       "      <td>2.647204</td>\n",
       "      <td>-0.042139</td>\n",
       "      <td>...</td>\n",
       "      <td>9.153409</td>\n",
       "      <td>164.750</td>\n",
       "      <td>28.250</td>\n",
       "      <td>10.250</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3842</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>2.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>8.014165</td>\n",
       "      <td>278.35916</td>\n",
       "      <td>9.845626</td>\n",
       "      <td>181.29170</td>\n",
       "      <td>13.266225</td>\n",
       "      <td>-2.441787</td>\n",
       "      <td>-0.582110</td>\n",
       "      <td>0.593952</td>\n",
       "      <td>2.439651</td>\n",
       "      <td>-0.046212</td>\n",
       "      <td>...</td>\n",
       "      <td>11.514151</td>\n",
       "      <td>157.250</td>\n",
       "      <td>27.875</td>\n",
       "      <td>10.250</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>9.103675</td>\n",
       "      <td>200.99684</td>\n",
       "      <td>9.508262</td>\n",
       "      <td>174.29413</td>\n",
       "      <td>12.149082</td>\n",
       "      <td>-2.566612</td>\n",
       "      <td>-0.600858</td>\n",
       "      <td>0.577008</td>\n",
       "      <td>2.714610</td>\n",
       "      <td>-0.042108</td>\n",
       "      <td>...</td>\n",
       "      <td>8.604167</td>\n",
       "      <td>140.750</td>\n",
       "      <td>33.000</td>\n",
       "      <td>12.875</td>\n",
       "      <td>3.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5121</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>8.277690</td>\n",
       "      <td>283.83401</td>\n",
       "      <td>9.268148</td>\n",
       "      <td>237.64000</td>\n",
       "      <td>14.020948</td>\n",
       "      <td>-2.318739</td>\n",
       "      <td>-0.635836</td>\n",
       "      <td>0.645020</td>\n",
       "      <td>2.756264</td>\n",
       "      <td>-0.050437</td>\n",
       "      <td>...</td>\n",
       "      <td>9.895000</td>\n",
       "      <td>141.750</td>\n",
       "      <td>33.625</td>\n",
       "      <td>13.750</td>\n",
       "      <td>4.625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3061</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>3.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ASA+_per_atom       ASA-  ASA_H_per_atom      ASA_P  ASA_per_atom  \\\n",
       "0         5.994013  175.26022        9.389342  160.19148     12.411823   \n",
       "1         8.143989  172.74998        8.340377  158.41364     10.510427   \n",
       "2         7.558447  275.62744       10.419536  185.81779     15.728617   \n",
       "3         7.640180  209.40883        9.224951  131.75505     11.913830   \n",
       "4        10.034180  194.92766       11.159462  154.57048     14.929475   \n",
       "..             ...        ...             ...        ...           ...   \n",
       "243       9.364868  148.06656        9.751122  122.57384     11.608300   \n",
       "244       9.508312  134.60069        8.863824  177.13689     11.547717   \n",
       "245       8.014165  278.35916        9.845626  181.29170     13.266225   \n",
       "246       9.103675  200.99684        9.508262  174.29413     12.149082   \n",
       "247       8.277690  283.83401        9.268148  237.64000     14.020948   \n",
       "\n",
       "     BCUT_PEOE_0  BCUT_PEOE_1  BCUT_PEOE_2  BCUT_PEOE_3  \\\n",
       "0      -2.771648    -0.577210     0.571201     2.757304   \n",
       "1      -2.761202    -0.605943     0.736091     2.765514   \n",
       "2      -2.267313    -0.722016     0.690390     2.228887   \n",
       "3      -2.534188    -0.638915     0.706667     2.705784   \n",
       "4      -2.472854    -0.686740     0.731408     2.491220   \n",
       "..           ...          ...          ...          ...   \n",
       "243    -2.537512    -0.599106     0.504315     2.707295   \n",
       "244    -2.665385    -0.478010     0.442054     2.647204   \n",
       "245    -2.441787    -0.582110     0.593952     2.439651   \n",
       "246    -2.566612    -0.600858     0.577008     2.714610   \n",
       "247    -2.318739    -0.635836     0.645020     2.756264   \n",
       "\n",
       "     BCUT_SLOGP_0_per_atom  ...  vsurf_Wp2_per_atom  vsurf_Wp3  vsurf_Wp4  \\\n",
       "0                -0.052158  ...            8.502358    131.625     39.500   \n",
       "1                -0.048581  ...           11.167808    314.375     84.125   \n",
       "2                -0.064243  ...           12.732143    115.250     17.500   \n",
       "3                -0.055374  ...            9.086735     94.375     19.375   \n",
       "4                -0.059509  ...           15.618902    214.250     54.125   \n",
       "..                     ...  ...                 ...        ...        ...   \n",
       "243              -0.041365  ...            9.369318    173.875     60.000   \n",
       "244              -0.042139  ...            9.153409    164.750     28.250   \n",
       "245              -0.046212  ...           11.514151    157.250     27.875   \n",
       "246              -0.042108  ...            8.604167    140.750     33.000   \n",
       "247              -0.050437  ...            9.895000    141.750     33.625   \n",
       "\n",
       "     vsurf_Wp5  vsurf_Wp6  vsurf_Wp7  vsurf_Wp8  weinerPath  \\\n",
       "0       16.500      4.875      0.000      0.000        2284   \n",
       "1       29.750      5.875      0.125      0.000        6535   \n",
       "2        6.000      2.125      0.000      0.000        1462   \n",
       "3        8.625      3.500      0.750      0.000        2904   \n",
       "4       22.500      6.500      0.875      0.000        1705   \n",
       "..         ...        ...        ...        ...         ...   \n",
       "243     29.625     13.875      5.125      0.375        4841   \n",
       "244     10.250      2.625      0.000      0.000        3842   \n",
       "245     10.250      3.000      0.125      0.000        3401   \n",
       "246     12.875      3.750      0.250      0.000        5121   \n",
       "247     13.750      4.625      0.250      0.000        3061   \n",
       "\n",
       "     weinerPol_per_atom  zagreb_per_atom  \n",
       "0              0.679245         2.566038  \n",
       "1              0.780822         2.821918  \n",
       "2              1.200000         3.885714  \n",
       "3              0.877551         3.183673  \n",
       "4              1.048780         3.560976  \n",
       "..                  ...              ...  \n",
       "243            0.833333         2.787879  \n",
       "244            0.969697         2.939394  \n",
       "245            1.000000         3.433962  \n",
       "246            0.909091         2.969697  \n",
       "247            0.940000         3.320000  \n",
       "\n",
       "[248 rows x 306 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data file\n",
    "uq_path = \"/Users/radhi/Desktop/CAPSTONE_DATA/NEK_data_4Berkeley/NEK5\" \n",
    "train_x_df = pd.read_csv(uq_path+\"/NEK5_binding_random_fold1_trainX.csv\")\n",
    "train_y_df = pd.read_csv(uq_path+\"/NEK5_binding_random_fold1_trainY.csv\")\n",
    "test_x_df = pd.read_csv(uq_path+\"/NEK5_binding_random_fold1_testX.csv\")\n",
    "test_y_df = pd.read_csv(uq_path+\"/NEK5_binding_random_fold1_testY.csv\")\n",
    "test_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 306)\n",
      "(989,)\n"
     ]
    }
   ],
   "source": [
    "# Transform data to PyTorch tensors\n",
    "\n",
    "# Scale data\n",
    "x_df = pd.concat([train_x_df, test_x_df])\n",
    "\n",
    "scaling=StandardScaler()\n",
    " \n",
    "# Use fit and transform method \n",
    "scaling.fit(x_df)\n",
    "Scaled_data=scaling.transform(x_df)\n",
    "train_x = scaling.transform(train_x_df)\n",
    "test_x = scaling.transform(test_x_df) \n",
    "\n",
    "train_y = train_y_df.to_numpy().flatten()\n",
    "test_y = test_y_df.to_numpy().flatten()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Construct a RF classification model\n",
    "\n",
    "# creating a RF classifier\n",
    "clf = BalancedRandomForestClassifier(n_estimators = 100, class_weight = \"balanced\")  \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(train_x, train_y)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "train_pred_y = clf.predict(train_x)\n",
    "test_pred_y = clf.predict(test_x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"420pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 420.12 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 416.12,-307 416.12,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#4ba6e7\" stroke=\"black\" points=\"359.62,-303 168.88,-303 168.88,-250 359.62,-250 359.62,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.25\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">VDistMa_per_atom &lt;= 0.995</text>\n",
       "<text text-anchor=\"middle\" x=\"264.25\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"264.25\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.082, 0.918]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"271.88,-214 82.62,-214 82.62,-161 271.88,-161 271.88,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.25\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsa_hyd_per_atom &lt;= 1.258</text>\n",
       "<text text-anchor=\"middle\" x=\"177.25\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 87.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"177.25\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.059, 0.941]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.62,-249.87C229.93,-241.18 220.1,-231.35 210.89,-222.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"213.62,-219.92 204.07,-215.32 208.67,-224.87 213.62,-219.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"203\" y=\"-233.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>52</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"412.12,-206.5 290.38,-206.5 290.38,-168.5 412.12,-168.5 412.12,-206.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.25\" y=\"-189.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"351.25\" y=\"-174.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;52 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.88,-249.87C300.91,-238.84 313.78,-225.97 324.89,-214.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.31,-217.39 331.9,-207.85 322.36,-212.44 327.31,-217.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.97\" y=\"-225.98\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#44a2e6\" stroke=\"black\" points=\"146.5,-125 0,-125 0,-72 146.5,-72 146.5,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_CW4 &lt;= 1.539</text>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 82.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"73.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.052, 0.948]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.33,-160.63C135.84,-151.86 123.97,-141.93 112.9,-132.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.31,-130.12 105.39,-126.39 110.82,-135.49 115.31,-130.12\"/>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>49</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"400.12,-125 164.38,-125 164.38,-72 400.12,-72 400.12,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"282.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GCUT_SMR_3_per_atom &lt;= &#45;0.857</text>\n",
       "<text text-anchor=\"middle\" x=\"282.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"282.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;49 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.47,-160.63C219.06,-151.86 231.04,-141.93 242.22,-132.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"244.34,-135.46 249.8,-126.38 239.87,-130.07 244.34,-135.46\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"97.25,-36 43.25,-36 43.25,0 97.25,0 97.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.27,-71.8C71.97,-64.08 71.65,-55.56 71.35,-47.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.85,-47.7 70.97,-37.84 67.85,-47.97 74.85,-47.7\"/>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>46</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"169.25,-36 115.25,-36 115.25,0 169.25,0 169.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"142.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;46 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.84,-71.8C103.43,-63.17 111.89,-53.54 119.48,-44.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.04,-47.29 126.02,-37.47 116.79,-42.67 122.04,-47.29\"/>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>50</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"275.25,-36 221.25,-36 221.25,0 275.25,0 275.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 49&#45;&gt;50 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>49&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.12,-71.8C267.66,-63.8 263.82,-54.96 260.3,-46.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.54,-45.5 256.36,-37.72 257.12,-48.29 263.54,-45.5\"/>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>51</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"347.25,-36 293.25,-36 293.25,0 347.25,0 347.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"320.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 49&#45;&gt;51 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>49&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.69,-71.8C298.61,-63.71 302.94,-54.76 306.91,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.99,-48.22 311.2,-37.69 303.69,-45.17 309.99,-48.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x2c221ef40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"395pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 395.38 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 391.38,-307 391.38,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#46a4e7\" stroke=\"black\" points=\"206.5,-303 60,-303 60,-250 206.5,-250 206.5,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.25\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_HB6 &lt;= &#45;1.103</text>\n",
       "<text text-anchor=\"middle\" x=\"133.25\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"133.25\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.063, 0.937]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"116.5,-206.5 0,-206.5 0,-168.5 116.5,-168.5 116.5,-206.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.25\" y=\"-189.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"58.25\" y=\"-174.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111.15,-249.87C101.74,-238.95 90.77,-226.22 81.26,-215.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.18,-213.21 74.99,-207.92 78.87,-217.78 84.18,-213.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"72.16\" y=\"-225.91\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#44a3e6\" stroke=\"black\" points=\"281.5,-214 135,-214 135,-161 281.5,-161 281.5,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.25\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_Wp6 &lt;= &#45;0.578</text>\n",
       "<text text-anchor=\"middle\" x=\"208.25\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 92.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"208.25\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.054, 0.946]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.35,-249.87C162.68,-241.36 170.97,-231.75 178.77,-222.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.19,-225.26 185.06,-215.4 175.88,-220.68 181.19,-225.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.9\" y=\"-233.38\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#fbece1\" stroke=\"black\" points=\"207.5,-125 13,-125 13,-72 207.5,-72 207.5,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"110.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">std_dim3_per_atom &lt;= 0.384</text>\n",
       "<text text-anchor=\"middle\" x=\"110.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19.8%</text>\n",
       "<text text-anchor=\"middle\" x=\"110.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.542, 0.458]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.11,-160.63C169.33,-151.95 158.27,-142.13 147.92,-132.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150.38,-130.44 140.58,-126.42 145.73,-135.68 150.38,-130.44\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#3fa0e6\" stroke=\"black\" points=\"387.38,-125 225.12,-125 225.12,-72 387.38,-72 387.38,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.25\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">PEOE_VSA+4 &lt;= 3.525</text>\n",
       "<text text-anchor=\"middle\" x=\"306.25\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 72.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"306.25\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.029, 0.971]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;10 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.39,-160.63C247.17,-151.95 258.23,-142.13 268.58,-132.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.77,-135.68 275.92,-126.42 266.12,-130.44 270.77,-135.68\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"127.25,-36 73.25,-36 73.25,0 127.25,0 127.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.98,-71.8C105.99,-64.08 104.91,-55.56 103.9,-47.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.38,-47.31 102.65,-37.83 100.44,-48.19 107.38,-47.31\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"199.25,-36 145.25,-36 145.25,0 199.25,0 199.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.55,-71.8C137.29,-63.26 144.81,-53.75 151.58,-45.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.17,-47.54 157.62,-37.52 148.68,-43.2 154.17,-47.54\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"302.25,-36 248.25,-36 248.25,0 302.25,0 302.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.1,-71.8C292.94,-63.8 289.45,-54.96 286.24,-46.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.58,-45.75 282.65,-37.74 283.07,-48.32 289.58,-45.75\"/>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>40</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"374.25,-36 320.25,-36 320.25,0 374.25,0 374.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.25\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;40 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>10&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.67,-71.8C323.94,-63.62 328.68,-54.55 333.01,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"335.97,-48.16 337.5,-37.67 329.77,-44.92 335.97,-48.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x2c221ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"427pt\" height=\"311pt\"\n",
       " viewBox=\"0.00 0.00 427.12 311.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 307)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-307 423.12,-307 423.12,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#4ca6e7\" stroke=\"black\" points=\"231.12,-303 42.62,-303 42.62,-250 231.12,-250 231.12,-303\"/>\n",
       "<text text-anchor=\"middle\" x=\"136.88\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CASA+_per_atom &lt;= &#45;1.017</text>\n",
       "<text text-anchor=\"middle\" x=\"136.88\" y=\"-270.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"136.88\" y=\"-255.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.086, 0.914]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"121.75,-206.5 0,-206.5 0,-168.5 121.75,-168.5 121.75,-206.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.88\" y=\"-189.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"60.88\" y=\"-174.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M114.48,-249.87C104.95,-238.95 93.83,-226.22 84.19,-215.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.05,-213.15 77.84,-207.92 81.78,-217.75 87.05,-213.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.16\" y=\"-225.92\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#47a4e7\" stroke=\"black\" points=\"286.12,-214 139.62,-214 139.62,-161 286.12,-161 286.12,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.88\" y=\"-196.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">vsurf_HB7 &lt;= &#45;1.248</text>\n",
       "<text text-anchor=\"middle\" x=\"212.88\" y=\"-181.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88.8%</text>\n",
       "<text text-anchor=\"middle\" x=\"212.88\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.066, 0.934]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.27,-249.87C166.7,-241.36 175.1,-231.75 183,-222.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.44,-225.22 189.39,-215.39 180.17,-220.62 185.44,-225.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.06\" y=\"-233.39\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"176.12,-117.5 59.62,-117.5 59.62,-79.5 176.12,-79.5 176.12,-117.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"117.88\" y=\"-100.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"117.88\" y=\"-85.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.63,-160.63C172.57,-149.59 158.52,-136.72 146.43,-125.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.88,-123.15 139.14,-118.97 144.15,-128.31 148.88,-123.15\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"419.12,-125 194.62,-125 194.62,-72 419.12,-72 419.12,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.88\" y=\"-107.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Q_VSA_POL_per_atom &lt;= &#45;1.343</text>\n",
       "<text text-anchor=\"middle\" x=\"306.88\" y=\"-92.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"306.88\" y=\"-77.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.058, 0.942]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M240.82,-160.63C250.12,-152.03 260.6,-142.33 270.44,-133.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"272.8,-135.81 277.76,-126.45 268.04,-130.67 272.8,-135.81\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"297.88,-36 243.88,-36 243.88,0 297.88,0 297.88,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.88\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M295.09,-71.8C291.38,-63.71 287.27,-54.76 283.51,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.8,-45.34 279.45,-37.71 280.44,-48.25 286.8,-45.34\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c0c0c0\" stroke=\"black\" points=\"369.88,-36 315.88,-36 315.88,0 369.88,0 369.88,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"342.88\" y=\"-12.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.66,-71.8C322.37,-63.71 326.48,-54.76 330.24,-46.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.31,-48.25 334.3,-37.71 326.95,-45.34 333.31,-48.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x142f608e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export the first three decision trees from the forest\n",
    "\n",
    "for i in range(3):\n",
    "    tree = clf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=train_x_df.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[692 220]\n",
      " [  0  77]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "train_cm = confusion_matrix(train_y, train_pred_y)\n",
    "\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 train set\",fontsize=20)\n",
    "plot_confusion_matrix(train_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[172  56]\n",
      " [  6  14]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "test_cm = confusion_matrix(test_y, test_pred_y)\n",
    "\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 test set\",fontsize=20)\n",
    "plot_confusion_matrix(test_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:576: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:588: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:600: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x142ec7be0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17417d400&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x142ec7be0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17417d400&gt;})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=BalancedRandomForestClassifier(class_weight='balanced'),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x142ec7be0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x17417d400>})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a long time. Try loading the saved model.\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,80)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = BalancedRandomForestClassifier(class_weight = \"balanced\")\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=30, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 28, 'n_estimators': 99}\n"
     ]
    }
   ],
   "source": [
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "# Best hyperparameters: {'max_depth': 34, 'n_estimators': 336}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balanceRFC_randomCV_NEK5_binding.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "\n",
    "# save\n",
    "joblib.dump(best_rf, \"balanceRFC_randomCV_NEK5_binding.pkl\") \n",
    "\n",
    "# load\n",
    "#clf2 = joblib.load(\"balanceRFC_randomCV_NEK2_binding.pkl\")\n",
    "#clf2.predict(X[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[699 213]\n",
      " [  0  77]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "train_pred_y_best = best_rf.predict(train_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "train_best_cm = confusion_matrix(train_y, train_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 train set\",fontsize=20)\n",
    "plot_confusion_matrix(train_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[174  54]\n",
      " [  6  14]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "test_pred_y_best = best_rf.predict(test_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "test_best_cm = confusion_matrix(test_y, test_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 test set\",fontsize=20)\n",
    "plot_confusion_matrix(test_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7580645161290323\n",
      "Precision: 0.20588235294117646\n",
      "Recall: 0.7\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_y, test_pred_y_best)\n",
    "precision = precision_score(test_y, test_pred_y_best)\n",
    "recall = recall_score(test_y, test_pred_y_best)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.2s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=60, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   6.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=80, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   6.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=100, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=150, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=200, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1050; total time=   4.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1050; total time=   4.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=1525; total time=   6.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   8.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=2, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=1525; total time=   6.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=3, min_samples_split=4, n_estimators=2000; total time=   7.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=1525; total time=   5.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=3, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=4, min_samples_split=4, n_estimators=2000; total time=   7.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   4.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=2, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   1.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.0s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=575; total time=   2.1s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=3, n_estimators=2000; total time=   7.6s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.9s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1050; total time=   3.8s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=1525; total time=   5.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   7.2s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.7s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.5s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.3s\n",
      "[CV] END max_depth=220, min_samples_leaf=5, min_samples_split=4, n_estimators=2000; total time=   6.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=8,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=8,\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
       "             n_jobs=8,\n",
       "             param_grid={'max_depth': [20, 40, 60, 80, 100, 150, 200, 220],\n",
       "                         'min_samples_leaf': [2, 3, 4, 5],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': array([ 100,  575, 1050, 1525, 2000])},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a very long time. Try load from the best model.\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(100, 2000, 5, dtype = int),\n",
    "    'max_depth': [20, 40, 60, 80, 100, 150, 200, 220],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Base model\n",
    "rf_grid = RandomForestClassifier(criterion = 'entropy', bootstrap = True)\n",
    "# Instantiate the grid search model\n",
    "grid_rf_search = GridSearchCV(estimator = rf_grid, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = 8, verbose = 2)\n",
    "grid_rf_search.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 80,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_grid = grid_rf_search.best_estimator_\n",
    "grid_rf_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balanceRFC_gridCV_NEK5_binding.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "\n",
    "# save\n",
    "joblib.dump(best_rf_grid, \"balanceRFC_gridCV_NEK5_binding.pkl\") \n",
    "\n",
    "# load\n",
    "#clf2 = joblib.load(\"balanceRFC_gridCV_NEK2_binding.pkl\")\n",
    "#clf2.predict(X[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[912   0]\n",
      " [  3  74]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "train_pred_y_best = best_rf_grid.predict(train_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "train_best_cm = confusion_matrix(train_y, train_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 train set (grid)\",fontsize=20)\n",
    "plot_confusion_matrix(train_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[227   1]\n",
      " [ 15   5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions with the best model\n",
    "test_pred_y_best = best_rf_grid.predict(test_x)\n",
    "\n",
    "# Create the confusion matrix\n",
    "test_best_cm = confusion_matrix(test_y, test_pred_y_best)\n",
    "class_names = [\"0\",\"1\"]\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "label_font = {'size':'18'}  # Adjust to fit\n",
    "\n",
    "ax = plt.figure(figsize=(5,5))\n",
    "plt.title(\"NEK5 test set (grid)\",fontsize=20)\n",
    "plot_confusion_matrix(test_best_cm, classes=class_names, normalize=False)\n",
    "plt.xlabel(\"Predicted\",fontdict=label_font);\n",
    "plt.ylabel(\"Actual\",fontdict=label_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(best_rf_grid.estimators_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1    2    3    4    5         6    7    8    9   ...   90  \\\n",
       "0    1.0  1.000000  1.0  1.0  1.0  1.0  1.000000  1.0  1.0  1.0  ...  1.0   \n",
       "1    1.0  1.000000  1.0  1.0  1.0  1.0  1.000000  1.0  1.0  1.0  ...  1.0   \n",
       "2    1.0  1.000000  1.0  1.0  1.0  1.0  1.000000  0.5  1.0  1.0  ...  1.0   \n",
       "3    1.0  1.000000  1.0  1.0  1.0  1.0  1.000000  1.0  1.0  1.0  ...  1.0   \n",
       "4    1.0  1.000000  1.0  1.0  1.0  1.0  1.000000  1.0  1.0  1.0  ...  1.0   \n",
       "..   ...       ...  ...  ...  ...  ...       ...  ...  ...  ...  ...  ...   \n",
       "984  0.0  0.000000  1.0  0.0  0.5  1.0  0.000000  0.0  1.0  0.0  ...  0.0   \n",
       "985  1.0  0.000000  1.0  1.0  1.0  0.0  0.000000  0.0  0.0  1.0  ...  0.6   \n",
       "986  1.0  0.000000  0.0  0.5  0.0  0.0  0.500000  1.0  1.0  1.0  ...  0.0   \n",
       "987  0.0  0.000000  1.0  0.0  0.0  0.0  0.000000  1.0  0.0  0.0  ...  1.0   \n",
       "988  1.0  0.333333  0.0  1.0  0.0  0.5  0.666667  0.0  0.5  1.0  ...  1.0   \n",
       "\n",
       "           91        92        93        94   95   96   97   98   99  \n",
       "0    1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0  \n",
       "1    1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0  \n",
       "2    1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0  \n",
       "3    1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0  \n",
       "4    1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0  \n",
       "..        ...       ...       ...       ...  ...  ...  ...  ...  ...  \n",
       "984  1.000000  0.000000  0.333333  0.000000  1.0  0.0  1.0  1.0  0.5  \n",
       "985  0.000000  0.000000  0.000000  1.000000  1.0  0.5  0.0  1.0  1.0  \n",
       "986  0.500000  0.333333  0.000000  0.666667  0.0  0.0  0.0  0.0  0.0  \n",
       "987  0.000000  0.000000  1.000000  1.000000  0.0  0.0  0.0  0.5  1.0  \n",
       "988  0.333333  0.000000  1.000000  0.000000  1.0  0.0  1.0  0.5  1.0  \n",
       "\n",
       "[989 rows x 100 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree predictions\n",
    "train_proba0_df = pd.DataFrame()\n",
    "train_proba1_df = pd.DataFrame()\n",
    "test_proba0_df = pd.DataFrame()\n",
    "test_proba1_df = pd.DataFrame()\n",
    "\n",
    "for tree_num in np.arange(len(best_rf_grid.estimators_)):\n",
    "    train_proba_temp = best_rf_grid.estimators_[tree_num].predict_proba(train_x)\n",
    "    train_proba0_df[tree_num] = train_proba_temp[:,0]\n",
    "    train_proba1_df[tree_num] = train_proba_temp[:,1]\n",
    "    test_proba_temp = best_rf_grid.estimators_[tree_num].predict_proba(test_x)\n",
    "    test_proba0_df[tree_num] = test_proba_temp[:,0]\n",
    "    test_proba1_df[tree_num] = test_proba_temp[:,1]\n",
    "    \n",
    "train_proba0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.371472\n",
       "1      0.247881\n",
       "2      0.111351\n",
       "3      0.148647\n",
       "4      0.100000\n",
       "         ...   \n",
       "243    0.430898\n",
       "244    0.377706\n",
       "245    0.428529\n",
       "246    0.487774\n",
       "247    0.238683\n",
       "Length: 248, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = test_proba0_df.std(axis=1)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_y_pred_grid</th>\n",
       "      <th>train_y</th>\n",
       "      <th>train_proba0_std_grid</th>\n",
       "      <th>train_proba1_std_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180184</td>\n",
       "      <td>0.180184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.102832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151785</td>\n",
       "      <td>0.151785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417680</td>\n",
       "      <td>0.417680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457102</td>\n",
       "      <td>0.457102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415247</td>\n",
       "      <td>0.415247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.420952</td>\n",
       "      <td>0.420952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.438891</td>\n",
       "      <td>0.438891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_y_pred_grid  train_y  train_proba0_std_grid  train_proba1_std_grid\n",
       "0                    0        0               0.180184               0.180184\n",
       "1                    0        0               0.102832               0.102832\n",
       "2                    0        0               0.151785               0.151785\n",
       "3                    0        0               0.000000               0.000000\n",
       "4                    0        0               0.000000               0.000000\n",
       "..                 ...      ...                    ...                    ...\n",
       "984                  1        1               0.417680               0.417680\n",
       "985                  1        1               0.457102               0.457102\n",
       "986                  1        1               0.415247               0.415247\n",
       "987                  1        1               0.420952               0.420952\n",
       "988                  1        1               0.438891               0.438891\n",
       "\n",
       "[989 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty dataframe\n",
    "train_perf_df = pd.DataFrame()\n",
    "test_perf_df = pd.DataFrame()\n",
    "\n",
    "# Predictions\n",
    "train_perf_df['train_y_pred_grid'] = train_pred_y_best\n",
    "test_perf_df['test_y_pred_grid'] = test_pred_y_best\n",
    "\n",
    "# Actual\n",
    "train_perf_df['train_y'] = train_y\n",
    "test_perf_df['test_y'] = test_y\n",
    "\n",
    "# Variances\n",
    "train_perf_df['train_proba0_std_grid'] = train_proba0_df.std(axis=1)\n",
    "train_perf_df['train_proba1_std_grid'] = train_proba1_df.std(axis=1)\n",
    "test_perf_df['test_proba0_std_grid'] = test_proba0_df.std(axis=1)\n",
    "test_perf_df['test_proba1_std_grid'] = test_proba1_df.std(axis=1)\n",
    "\n",
    "train_perf_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
