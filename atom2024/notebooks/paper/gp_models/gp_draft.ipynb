{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix, f1_score, roc_curve,precision_recall_curve, auc\n",
    "# from scipy.stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc, recall_score, confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/radhi/Desktop/GitHub/atom2024/atom2024/notebooks/')\n",
    "from RF_GSCV import * # RF_GSCV contains the calculate metrics function to get the TP, TN, FP, FN scores \n",
    "from RF_atomver import prediction_type \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DirichletGPModel(ExactGP):\n",
    "    \"\"\"\n",
    "    A Dirichlet Gaussian Process (GP) model for multi-class classification.\n",
    "    This model uses a Gaussian Process with a Dirichlet prior to handle multi-class classification tasks.\n",
    "    It extends the ExactGP class from GPyTorch, a library for Gaussian Processes in PyTorch.\n",
    "    Attributes:\n",
    "        mean_module (gpytorch.means.ConstantMean): The mean module for the GP, initialized with a constant mean function for each class.\n",
    "        covar_module (gpytorch.kernels.ScaleKernel): The covariance module for the GP, using a scaled RBF kernel for each class.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training data features.\n",
    "        train_y (torch.Tensor): Training data labels.\n",
    "        likelihood (gpytorch.likelihoods.Likelihood): The likelihood function.\n",
    "        num_classes (int): The number of classes for the classification task.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes,kernal):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        if kernal == 'matern': \n",
    "            self.covar_module = ScaleKernel(MaternKernel(nu=0.5, batch_shape=torch.Size((num_classes,))),\n",
    "                batch_shape=torch.Size((num_classes,))\n",
    "            )\n",
    "        elif kernal == 'RBF': \n",
    "            self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),)\n",
    "\n",
    "        else: \n",
    "            print('invalid')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the GP model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data features.\n",
    "        Returns:\n",
    "            gpytorch.distributions.MultivariateNormal: The multivariate normal distribution representing the GP posterior.\n",
    "        \"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self,model, likelihood, iterations): \n",
    "        self.model = model\n",
    "        self.likelihood = likelihood \n",
    "        smoke_test = ('CI' in os.environ)\n",
    "        self.n_iterations = 2 if smoke_test else iterations\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        self.loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "    def train(self, train_x, train_y): \n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        predictions = [] \n",
    "        for i in range(self.n_iterations): \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(train_x)\n",
    "            loss = -self.loss_fn(output, self.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if (i%10==0): \n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, self.n_iterations, loss.item(),\n",
    "                    self.model.covar_module.base_kernel.lengthscale.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "             \n",
    "            self.optimizer.step() \n",
    "    def predict(self, input): \n",
    "        \"\"\"\n",
    "        Make predictions using the GP model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input data for making predictions.\n",
    "        \n",
    "        Returns:\n",
    "            dist (gpytorch.distributions.MultivariateNormal): The distribution representing the GP posterior.\n",
    "            observed_pred (gpytorch.distributions.MultivariateNormal): The predicted distribution considering the likelihood.\n",
    "            pred_means (torch.Tensor): The means of the predicted distributions.\n",
    "            class_pred (torch.Tensor): The predicted class labels.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            dist = self.model(input)     # output distribution\n",
    "            pred_means = dist.loc          # means of distributino \n",
    "            observed_pred = self.likelihood(self.model(input))    # likelihood predictions mean and var  \n",
    "\n",
    "            class_pred = self.model(input).loc.max(0)[1]\n",
    "            \n",
    "        return dist, observed_pred, pred_means, class_pred\n",
    "    \n",
    "\n",
    "    def evaluate(self, x_input, y_true): \n",
    "        \"\"\"\n",
    "        Evaluate the GP model.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor): The true labels for the input data.\n",
    "        \n",
    "        Returns:\n",
    "            y_pred (numpy.ndarray): The predicted class labels.\n",
    "        \"\"\"\n",
    "        y_pred = self.model(x_input).loc.max(0)[1].numpy()\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def calculate_metrics(y_true, y_pred): \n",
    "        \n",
    "        # return tp, tn, fp, fn\n",
    "        y_true = pd.Series(y_true) if not isinstance(y_true, pd.Series) else y_true\n",
    "        y_pred = pd.Series(y_pred) if not isinstance(y_pred, pd.Series) else y_pred\n",
    "        \n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        \n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "    def gp_results(self, x_input, y_true, plot_title=None): \n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics and print results.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor or numpy.ndarray): The true labels for the input data.\n",
    "            plot_title (str, optional): The title for the confusion matrix plot.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing evaluation metrics and confusion matrix components.\n",
    "        \"\"\"\n",
    "        y_pred = self.evaluate(x_input, y_true) \n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.numpy().reshape(-1)\n",
    "        # plot_confusion_matrix(y_true, y_pred, ['0','1'], title=plot_title)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        dist = self.model(x_input)     # get predicted distributions \n",
    "        pred_means = dist.loc          # means for predicted dist  \n",
    "\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        tp, tn, fp, fn = calculate_metrics(y_true, y_pred) \n",
    "       \n",
    "        specificity = tn / (tn + fp) \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_flattened = cm.flatten().tolist()\n",
    "        f1 = f1_score(y_true,y_pred)\n",
    "        roc_auc = roc_auc_score(y_true,y_pred)\n",
    "        mcc = matthews_corrcoef(y_true,y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_true,y_pred)\n",
    "        print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, specificity: {specificity:.4f}, cm: {cm}')\n",
    "        return {'accuracy': accuracy, 'precision': precision,  'recall':recall, 'specificity':specificity, \n",
    "                'f1':f1,'ROC_AUC': roc_auc,'MCC': mcc,'balanced_accuracy': bal_acc,'cm': cm_flattened,\n",
    "                'TN': tn, 'FN': fn, 'FP': fp, 'TP': tp }\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_torch_tens_float(filepath, filename): \n",
    "    trainX_df = pd.read_csv(filepath+filename+'_trainX.csv')\n",
    "    trainy_df = pd.read_csv(filepath+filename+'_train_y.csv')\n",
    "    testX_df = pd.read_csv(filepath+filename+'_testX.csv')\n",
    "    testy_df = pd.read_csv(filepath+filename+'_test_y.csv')\n",
    "\n",
    "    train_x_temp = trainX_df.to_numpy().astype(\"double\") # double \n",
    "    test_x_temp = testX_df.to_numpy().astype(\"double\") #double \n",
    "    \n",
    "    train_y_temp = trainy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "    test_y_temp = testy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "   \n",
    "    trainX = torch.as_tensor(train_x_temp, dtype=torch.float32)\n",
    "    trainy = torch.as_tensor(train_y_temp, dtype=torch.float32)\n",
    "    testX = torch.as_tensor(test_x_temp, dtype=torch.float32)\n",
    "    testy = torch.as_tensor(test_y_temp, dtype=torch.float32)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_results(trainX, trainy, testX, testy, root_name, kernal, n_iterations=300, n_samples=100):\n",
    "    \"\"\"\n",
    "    Train a Dirichlet Gaussian Process model and save the training and test performance results.\n",
    "\n",
    "    This function trains a Dirichlet GP model on the given training data, evaluates it on both the training\n",
    "    and test data, and saves various performance metrics and predictions to pandas DataFrames.\n",
    "\n",
    "    Args:\n",
    "        trainX (torch.Tensor): The training data features.\n",
    "        trainy (torch.Tensor): The training data labels.\n",
    "        testX (torch.Tensor): The test data features.\n",
    "        testy (torch.Tensor): The test data labels.\n",
    "        root_name (str): The root name used for labeling the model in the results.\n",
    "        n_iterations (int, optional): The number of training iterations. Default is 300.\n",
    "        n_samples (int, optional): The number of samples for prediction. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "        train_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the training data.\n",
    "        test_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the test data.\n",
    "    \"\"\"\n",
    "    likelihood = DirichletClassificationLikelihood(trainy.long(), learn_additional_noise=True)\n",
    "    model = DirichletGPModel(trainX, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes, kernal=kernal)\n",
    "    # n_iterations = 300\n",
    "    trainer = Trainer(model, likelihood, n_iterations)\n",
    "    trainer.train(trainX, trainy) \n",
    "  \n",
    "    train_dist, train_observed_pred, train_pred_means, train_pred  = trainer.predict(trainX)\n",
    "    train_results = trainer.gp_results(trainX, trainy)\n",
    "    test_dist, test_observed_pred, test_pred_means, test_pred  = trainer.predict(testX)\n",
    "    test_results = trainer.gp_results(testX, testy)\n",
    "    \n",
    "    train_observed_pred.mean.numpy()\n",
    "    train_pred_variance2D = train_observed_pred.variance.numpy()\n",
    "    test_observed_pred.mean.numpy()\n",
    "    test_pred_variance2D=test_observed_pred.variance.numpy()\n",
    "    \n",
    "    train_pred_samples = train_dist.sample(torch.Size((256,))).exp()\n",
    "    train_probabilities = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "\n",
    "    train_prob_stds = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    "    test_pred_samples = test_dist.sample(torch.Size((100,))).exp()\n",
    "\n",
    "    test_probabilities = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "    test_prob_stds = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    " \n",
    "    train_perf_df = pd.DataFrame()\n",
    "    test_perf_df = pd.DataFrame()\n",
    "    train_perf_df['mean_pred_class0'] = train_observed_pred.mean.numpy()[0,]\n",
    "    train_perf_df['mean_pred_class1'] = train_observed_pred.mean.numpy()[1,]\n",
    "    train_perf_df['y'] = trainy\n",
    "    train_perf_df['y_pred'] = train_pred_means.max(0)[1]\n",
    "    train_perf_df['var_pred_class0']=train_observed_pred.variance.numpy()[0,]\n",
    "    train_perf_df['var_pred_class1']=train_observed_pred.variance.numpy()[1,]\n",
    "    train_perf_df['pred_prob_class0'] = train_probabilities.numpy()[0,]\n",
    "    train_perf_df['pred_prob_class1'] = train_probabilities.numpy()[1,]\n",
    "    train_perf_df['pred_prob_std_class0'] = train_prob_stds.numpy()[0,]\n",
    "    train_perf_df['pred_prob_std_class1'] = train_prob_stds.numpy()[1,]\n",
    "    train_perf_df['subset'] = 'train' \n",
    "\n",
    "    \n",
    "    test_perf_df['mean_pred_class0'] = test_observed_pred.mean.numpy()[0,]\n",
    "    test_perf_df['mean_pred_class1'] = test_observed_pred.mean.numpy()[1,]\n",
    "    test_perf_df['y'] = testy\n",
    "    test_perf_df['y_pred'] = test_pred_means.max(0)[1]\n",
    "    test_perf_df['var_pred_class0']=test_observed_pred.variance.numpy()[0,]\n",
    "    test_perf_df['var_pred_class1']=test_observed_pred.variance.numpy()[1,]\n",
    "    test_perf_df['pred_prob_class0'] = test_probabilities.numpy()[0,]\n",
    "    test_perf_df['pred_prob_class1'] = test_probabilities.numpy()[1,]\n",
    "    test_perf_df['pred_prob_std_class0'] =test_prob_stds.numpy()[0,]\n",
    "    test_perf_df['pred_prob_std_class1'] = test_prob_stds.numpy()[1,]\n",
    "    test_perf_df['subset'] = 'test' \n",
    "    test_cm = confusion_matrix(testy, test_perf_df['y_pred'])\n",
    "    test_cm_flattened = test_cm.flatten().tolist()\n",
    "   \n",
    "    return train_perf_df, test_perf_df, model, likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.693   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.693   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.693   noise: 2.576\n",
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.693   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.693   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.693   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.693   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.897\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.895\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.894\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[36  0]\n",
      " [ 0 36]]\n",
      "accuracy: 0.5000, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[9 0]\n",
      " [9 0]]\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.251   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.435   lengthscale: 2.036   noise: 1.981\n",
      "Iter 31/300 - Loss: 5.252   lengthscale: 3.138   noise: 2.567\n",
      "Iter 41/300 - Loss: 5.188   lengthscale: 4.413   noise: 2.983\n",
      "Iter 51/300 - Loss: 5.163   lengthscale: 5.598   noise: 3.240\n",
      "Iter 61/300 - Loss: 5.152   lengthscale: 6.563   noise: 3.371\n",
      "Iter 71/300 - Loss: 5.145   lengthscale: 7.327   noise: 3.410\n",
      "Iter 81/300 - Loss: 5.140   lengthscale: 7.946   noise: 3.385\n",
      "Iter 91/300 - Loss: 5.136   lengthscale: 8.467   noise: 3.318\n",
      "Iter 101/300 - Loss: 5.132   lengthscale: 8.918   noise: 3.224\n",
      "Iter 111/300 - Loss: 5.129   lengthscale: 9.319   noise: 3.112\n",
      "Iter 121/300 - Loss: 5.126   lengthscale: 9.680   noise: 2.988\n",
      "Iter 131/300 - Loss: 5.123   lengthscale: 10.008   noise: 2.857\n",
      "Iter 141/300 - Loss: 5.120   lengthscale: 10.307   noise: 2.722\n",
      "Iter 151/300 - Loss: 5.118   lengthscale: 10.582   noise: 2.582\n",
      "Iter 161/300 - Loss: 5.115   lengthscale: 10.834   noise: 2.440\n",
      "Iter 171/300 - Loss: 5.112   lengthscale: 11.067   noise: 2.296\n",
      "Iter 181/300 - Loss: 5.110   lengthscale: 11.282   noise: 2.152\n",
      "Iter 191/300 - Loss: 5.107   lengthscale: 11.480   noise: 2.007\n",
      "Iter 201/300 - Loss: 5.105   lengthscale: 11.664   noise: 1.864\n",
      "Iter 211/300 - Loss: 5.103   lengthscale: 11.834   noise: 1.723\n",
      "Iter 221/300 - Loss: 5.100   lengthscale: 11.992   noise: 1.584\n",
      "Iter 231/300 - Loss: 5.098   lengthscale: 12.140   noise: 1.450\n",
      "Iter 241/300 - Loss: 5.096   lengthscale: 12.280   noise: 1.320\n",
      "Iter 251/300 - Loss: 5.094   lengthscale: 12.412   noise: 1.197\n",
      "Iter 261/300 - Loss: 5.092   lengthscale: 12.539   noise: 1.080\n",
      "Iter 271/300 - Loss: 5.090   lengthscale: 12.662   noise: 0.972\n",
      "Iter 281/300 - Loss: 5.088   lengthscale: 12.782   noise: 0.871\n",
      "Iter 291/300 - Loss: 5.087   lengthscale: 12.903   noise: 0.779\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[36  0]\n",
      " [ 0 36]]\n",
      "accuracy: 0.5556, precision: 0.5714, recall: 0.4444, specificity: 0.6667, cm: [[6 3]\n",
      " [5 4]]\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.929   lengthscale: 1.211   noise: 1.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21/300 - Loss: 5.405   lengthscale: 1.960   noise: 1.977\n",
      "Iter 31/300 - Loss: 5.169   lengthscale: 3.030   noise: 2.520\n",
      "Iter 41/300 - Loss: 5.085   lengthscale: 4.127   noise: 2.824\n",
      "Iter 51/300 - Loss: 5.066   lengthscale: 4.820   noise: 2.928\n",
      "Iter 61/300 - Loss: 5.057   lengthscale: 5.114   noise: 2.905\n",
      "Iter 71/300 - Loss: 5.049   lengthscale: 5.196   noise: 2.800\n",
      "Iter 81/300 - Loss: 5.042   lengthscale: 5.206   noise: 2.637\n",
      "Iter 91/300 - Loss: 5.035   lengthscale: 5.215   noise: 2.432\n",
      "Iter 101/300 - Loss: 5.027   lengthscale: 5.243   noise: 2.200\n",
      "Iter 111/300 - Loss: 5.020   lengthscale: 5.285   noise: 1.955\n",
      "Iter 121/300 - Loss: 5.013   lengthscale: 5.329   noise: 1.708\n",
      "Iter 131/300 - Loss: 5.005   lengthscale: 5.367   noise: 1.468\n",
      "Iter 141/300 - Loss: 4.998   lengthscale: 5.399   noise: 1.243\n",
      "Iter 151/300 - Loss: 4.991   lengthscale: 5.431   noise: 1.037\n",
      "Iter 161/300 - Loss: 4.985   lengthscale: 5.468   noise: 0.855\n",
      "Iter 171/300 - Loss: 4.979   lengthscale: 5.512   noise: 0.698\n",
      "Iter 181/300 - Loss: 4.974   lengthscale: 5.564   noise: 0.568\n",
      "Iter 191/300 - Loss: 4.969   lengthscale: 5.622   noise: 0.464\n",
      "Iter 201/300 - Loss: 4.965   lengthscale: 5.684   noise: 0.381\n",
      "Iter 211/300 - Loss: 4.962   lengthscale: 5.749   noise: 0.316\n",
      "Iter 221/300 - Loss: 4.959   lengthscale: 5.816   noise: 0.266\n",
      "Iter 231/300 - Loss: 4.957   lengthscale: 5.882   noise: 0.226\n",
      "Iter 241/300 - Loss: 4.955   lengthscale: 5.947   noise: 0.195\n",
      "Iter 251/300 - Loss: 4.953   lengthscale: 6.010   noise: 0.170\n",
      "Iter 261/300 - Loss: 4.952   lengthscale: 6.071   noise: 0.150\n",
      "Iter 271/300 - Loss: 4.951   lengthscale: 6.130   noise: 0.133\n",
      "Iter 281/300 - Loss: 4.950   lengthscale: 6.187   noise: 0.119\n",
      "Iter 291/300 - Loss: 4.949   lengthscale: 6.242   noise: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[36  0]\n",
      " [ 0 36]]\n",
      "accuracy: 0.8889, precision: 0.8889, recall: 0.8889, specificity: 0.8889, cm: [[8 1]\n",
      " [1 8]]\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.908   lengthscale: 1.291   noise: 1.296\n",
      "Iter 21/300 - Loss: 5.368   lengthscale: 2.157   noise: 1.965\n",
      "Iter 31/300 - Loss: 5.198   lengthscale: 3.099   noise: 2.506\n",
      "Iter 41/300 - Loss: 5.154   lengthscale: 3.758   noise: 2.864\n",
      "Iter 51/300 - Loss: 5.138   lengthscale: 4.160   noise: 3.057\n",
      "Iter 61/300 - Loss: 5.131   lengthscale: 4.424   noise: 3.129\n",
      "Iter 71/300 - Loss: 5.127   lengthscale: 4.627   noise: 3.116\n",
      "Iter 81/300 - Loss: 5.123   lengthscale: 4.803   noise: 3.049\n",
      "Iter 91/300 - Loss: 5.120   lengthscale: 4.968   noise: 2.945\n",
      "Iter 101/300 - Loss: 5.117   lengthscale: 5.127   noise: 2.818\n",
      "Iter 111/300 - Loss: 5.113   lengthscale: 5.281   noise: 2.676\n",
      "Iter 121/300 - Loss: 5.110   lengthscale: 5.430   noise: 2.523\n",
      "Iter 131/300 - Loss: 5.106   lengthscale: 5.573   noise: 2.364\n",
      "Iter 141/300 - Loss: 5.102   lengthscale: 5.712   noise: 2.201\n",
      "Iter 151/300 - Loss: 5.099   lengthscale: 5.845   noise: 2.035\n",
      "Iter 161/300 - Loss: 5.095   lengthscale: 5.974   noise: 1.869\n",
      "Iter 171/300 - Loss: 5.091   lengthscale: 6.098   noise: 1.704\n",
      "Iter 181/300 - Loss: 5.088   lengthscale: 6.220   noise: 1.541\n",
      "Iter 191/300 - Loss: 5.084   lengthscale: 6.338   noise: 1.384\n",
      "Iter 201/300 - Loss: 5.081   lengthscale: 6.455   noise: 1.233\n",
      "Iter 211/300 - Loss: 5.077   lengthscale: 6.570   noise: 1.091\n",
      "Iter 221/300 - Loss: 5.074   lengthscale: 6.686   noise: 0.959\n",
      "Iter 231/300 - Loss: 5.071   lengthscale: 6.801   noise: 0.838\n",
      "Iter 241/300 - Loss: 5.068   lengthscale: 6.918   noise: 0.730\n",
      "Iter 251/300 - Loss: 5.065   lengthscale: 7.037   noise: 0.633\n",
      "Iter 261/300 - Loss: 5.063   lengthscale: 7.158   noise: 0.549\n",
      "Iter 271/300 - Loss: 5.061   lengthscale: 7.281   noise: 0.476\n",
      "Iter 281/300 - Loss: 5.059   lengthscale: 7.408   noise: 0.414\n",
      "Iter 291/300 - Loss: 5.057   lengthscale: 7.537   noise: 0.361\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[36  0]\n",
      " [ 0 36]]\n",
      "accuracy: 0.8333, precision: 0.8750, recall: 0.7778, specificity: 0.8889, cm: [[8 1]\n",
      " [2 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/radhi/miniconda3/envs/atom2024/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gp_kfold_results = \"/Users/radhi/Desktop/GitHub/atom2024/atom2024/notebooks/paper/results/gp_kfold_results/\"\n",
    "datapath = '/Users/radhi/Desktop/GitHub/atom2024/atom2024/notebooks/paper/datasets/80train_20test/k_fold/validation/'\n",
    "neks = ['NEK2_binding', 'NEK2_inhibition', 'NEK3_binding', 'NEK5_binding','NEK9_binding','NEK9_inhibition']\n",
    "feats = ['MOE','MFP']\n",
    "samps = ['none_scaled','UNDER', 'SMOTE', 'ADASYN']\n",
    "kernal_type = ['RBF','matern' ]\n",
    "folds = ['fold1','fold2','fold3','fold4','fold5']\n",
    "final_cols = []\n",
    "train_results = []\n",
    "test_results = []\n",
    "final_cols=['model','NEK','strategy','feat_type','kernel_type','fold', 'cm','recall', 'specificity', 'accuracy', 'precision', \n",
    "                'f1', 'ROC_AUC', 'MCC', 'balanced_accuracy']\n",
    "for nek in neks:\n",
    "    for feat in feats:\n",
    "        for samp in samps:\n",
    "            for fold in folds:\n",
    "                for kernal in kernal_type:\n",
    "                    root_name = f'{nek}_{feat}_{samp}_{fold}'\n",
    "                    trainX, trainy, testX, testy = make_torch_tens_float(datapath,f'{root_name}_validation')\n",
    "                    train_perf, test_perf, model, likelihood= save_results(trainX, trainy, testX, testy, root_name, kernal, n_iterations=300, n_samples=100)   \n",
    "                    with open(f'{gp_kfold_results}{root_name}_{kernal}.pkl', 'wb') as f: \n",
    "                        pickle.dump(model,f)\n",
    "                    with open(f'{gp_kfold_results}{root_name}_{kernal}_likelihood.pkl', 'wb') as f: \n",
    "                        pickle.dump(likelihood,f)\n",
    "                \n",
    "                    for i, df in enumerate(list([train_perf, test_perf])): \n",
    "                        df['NEK'] = nek\n",
    "                        df['feat_type']=feat \n",
    "                        df['strategy']=feat \n",
    "                        df['fold']=fold \n",
    "                        df['kernel_type']=f'GP_{kernal}'\n",
    "                        df['model'] =f'{root_name}_{kernal}'\n",
    "                        if i == 0:\n",
    "                            df.to_csv(f'{gp_kfold_results}{root_name}_{kernal}_train.csv', index=False)\n",
    "                            train_results.append(df.iloc[[0]][final_cols].values.flatten())\n",
    "                        if i == 1: \n",
    "                            df.to_csv(f'{gp_kfold_results}{root_name}_{kernal}_test.csv', index=False)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
