{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2600b2-3662-4520-862f-c7b5e1a47b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from imblearn.over_sampling import SMOTEN, ADASYN, SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2974c77e-da8e-4231-81e5-b8308a372175",
   "metadata": {},
   "outputs": [],
   "source": [
    "neks = ['NEK2_binding', 'NEK2_inhibition', 'NEK3_binding', 'NEK5_binding','NEK9_binding','NEK9_inhibition']\n",
    "samplings=['none_scaled', 'UNDER','SMOTE','ADASYN']\n",
    "folds=['fold1','fold2','fold3','fold4','fold5'] \n",
    "feats=['MOE','MFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f688207-4988-4a70-a8b2-89d3a388d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(df, num): \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=num)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(df, df['active'])):\n",
    "        df.loc[df.index[test_index],'fold'] = f\"fold{i+1}\"\n",
    "    return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380abf39-f9a2-4a3a-ab90-e4a704916ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_subsets(df, test_fold, label):\n",
    "   \"\"\"function to label 'train' or 'test' in the 'subset' column\n",
    "   to be used to create train/test OR train/val\n",
    "   fold_df: dataframe with column 'fold'\n",
    "   test_fold (str): fold to make the test set (the remaining folds will be train)\n",
    "   label (str): 'test' or 'valididation' \n",
    "   \"\"\" \n",
    "   df['subset'] = df['fold'].apply(lambda x: 'test' if x == test_fold else 'train')\n",
    "   return df[['NEK','compound_id', 'active', 'base_rdkit_smiles', 'subset']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed78d16-7a17-46e3-b862-aa478439c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def over_sampling(data_path=None,filename=None, df=None, sampling=None, printOut=False):\n",
    "    \"\"\"Oversample the datasetes using the SMOTE or ADASYN\n",
    "    Keeps the feature names and id cols\n",
    "    file_name (full/absolute path): use the scaled dataframe we just created above 'NEK#_(binding/inhibition)_(MOE/MFP)_none_scaled_df.csv'\n",
    "    sampling (str): 'SMOTE' or 'ADASYN'\n",
    "    returns: oversampled dataframe\n",
    "    \"\"\"\n",
    "    id_cols = ['NEK', 'compound_id', 'base_rdkit_smiles','subset', 'active'] \n",
    "    if data_path is not None: \n",
    "        df = pd.read_csv(data_path+filename) # this is the already scaled ver\n",
    "    \n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "\n",
    "    # train and test \n",
    "    train = df[df['subset']=='train'] \n",
    "    test =df[df['subset']=='test'] \n",
    "    nek = df['NEK'].iloc[0]\n",
    "    # separate just id cols\n",
    "    just_ids = ['NEK', 'compound_id', 'base_rdkit_smiles','subset']\n",
    "    train_just_ids = train[just_ids]\n",
    "    test_just_ids = test[just_ids]\n",
    "\n",
    "    # just feats and 'active'\n",
    "    trainX = train[feat_cols]\n",
    "    testX = test[feat_cols]\n",
    "    \n",
    "    trainy = train['active']\n",
    "    testy = test['active']\n",
    "    \n",
    "    if sampling == 'ADASYN':\n",
    "        oversample = ADASYN(random_state=42)\n",
    "    else: \n",
    "        oversample = SMOTE(random_state=42)\n",
    "\n",
    "    \n",
    "    trainX_temp, trainy_temp = oversample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    if printOut: \n",
    "        print(f'train after {sampling}: {trainX_temp.shape}')\n",
    "    \n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feat_cols)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "\n",
    "    num_real = len(train)\n",
    "    num_synthetic = len(trainX_resamp)-num_real\n",
    "    synthetic_ids = pd.DataFrame({'NEK': [nek] * num_synthetic,\n",
    "        'compound_id': [f'synthetic_{sampling}_{i}' for i in range(num_synthetic)],\n",
    "        'base_rdkit_smiles': [f'synthetic_{sampling}'] * num_synthetic,\n",
    "        'subset': ['train']*num_synthetic}) # ,'active':[1]*num_synthetic}\n",
    "\n",
    "    real_ids = train_just_ids.reset_index(drop=True)\n",
    "    combined_ids = pd.concat([real_ids,synthetic_ids], ignore_index=True)\n",
    "    \n",
    "    train_resamp = pd.concat([combined_ids, trainX_resamp, trainy_resamp[['active']]], axis=1)\n",
    "\n",
    "    print(train_resamp.columns[train_resamp.columns.duplicated()])\n",
    "    test_df_final = pd.concat([test_just_ids.reset_index(drop=True),\n",
    "                               testX.reset_index(drop=True), testy.reset_index(drop=True)],axis=1)\n",
    "    \n",
    "    final_df = pd.concat([train_resamp, test_df_final]).reset_index(drop=True)\n",
    "    return final_df[list(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1e57e2-e14a-46c5-a3b5-16449c78e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "def under_sampling(data_path=None,filename=None, df=None): \n",
    "    if data_path is not None: \n",
    "        df = pd.read_csv(data_path+filename) # this is the already scaled ver\n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "    \n",
    "    # train and test \n",
    "    train = df[df['subset']=='train'] \n",
    "    test =df[df['subset']=='test'] \n",
    "\n",
    "    # separate just id cols\n",
    "    just_ids = ['NEK', 'compound_id', 'base_rdkit_smiles','subset']\n",
    "    train_just_ids = train[just_ids]\n",
    "    test_just_ids = test[just_ids]\n",
    "\n",
    "    # just feats and 'active'\n",
    "    trainX = train[feat_cols]\n",
    "    testX = test[feat_cols]\n",
    "    \n",
    "    trainy = train['active']\n",
    "    testy = test['active']\n",
    "    \n",
    "    undersample = RandomUnderSampler(random_state=42)\n",
    "    \n",
    "    trainX_temp, trainy_temp = undersample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    \n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feat_cols)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "    \n",
    "    train_ids_resamp = train_just_ids.iloc[trainX_resamp.index].reset_index(drop=True)\n",
    "    train_resamp= pd.concat([train_ids_resamp, trainX_resamp,trainy_resamp], axis=1)\n",
    "    # train_resamp['subset'] = 'train'\n",
    "\n",
    "    test_df_final = pd.concat([test_just_ids.reset_index(drop=True),testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "    # test_df_final['subset'] = 'test'\n",
    "    final_df = pd.concat([train_resamp,test_df_final]).reset_index(drop=True)\n",
    "    return final_df[list(df.columns)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0e9cd-d0ed-490b-86ef-dd425d19933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(feat_type,data_path=None, filename=None,moe_path=None, moe_file=None, moe_df=None, df=None,mfp_radius=2, nBits=2048): \n",
    "    if (feat_type == 'MOE') and (moe_path is not None) and (data_path is not None): \n",
    "        feat_df = create_moe(data_path, filename, moe_path, moe_file)\n",
    "    elif (feat_type == 'MOE') and (df is not None) and (moe_df is not None): \n",
    "        feat_df = create_moe(df=df, moe_df=moe_df)\n",
    "    elif (feat_type == 'MFP') and (data_path is not None): \n",
    "        feat_df = create_mfp(data_path, filename, mfp_radius, nBits)\n",
    "    elif (feat_type == 'MFP') and (df is not None): \n",
    "        feat_df = create_mfp(df=df)\n",
    "    \n",
    "    return feat_df\n",
    "\n",
    "def create_moe(data_path=None, filename=None, moe_path=None, moe_file=None, df=None, moe_df=None):\n",
    "    \"\"\"(intended use for already existing dataset)\n",
    "    This function will use an existing dataframe with smiles column to\n",
    "    get the features from an existing file (moe_path+moe_file) with the MOE features generated\"\"\"\n",
    "    drop_cols = ['active', 'compound_id']\n",
    "    id_cols = ['NEK', 'compound_id','base_rdkit_smiles','subset', 'active']\n",
    "   \n",
    "    if data_path is not None: \n",
    "        df = remove_duplicates(data_path, filename)\n",
    "    df=df.drop(columns=drop_cols)\n",
    "    if moe_path is not None: \n",
    "        moe_df=remove_duplicates(moe_path,moe_file)\n",
    "    final_df=moe_df.merge(df, how='outer', on=['base_rdkit_smiles'], suffixes=('_moe_desc', '_og'))\n",
    "    NEK_col = final_df['NEK_og'] \n",
    "    subset_col = final_df['subset_og']\n",
    "    \n",
    "    final_df = final_df.loc[:,~final_df.columns.str.endswith(('_moe_desc', '_og'))]\n",
    "    final_df['NEK']=NEK_col\n",
    "    final_df['subset']=subset_col\n",
    "    \n",
    "    feat_cols = set(list(final_df.columns))-set(id_cols)\n",
    "    final_order_cols = list(id_cols)+list(feat_cols)\n",
    "    final_df =final_df[final_order_cols] \n",
    "    if 'fold' in final_df.columns: \n",
    "        final_df=final_df.drop(columns=['fold']) \n",
    "    return final_df\n",
    "def smiles_to_fps(smiles_list, radius=2, nBits=2048):\n",
    "    fps = []\n",
    "    for smi in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is not None:\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "            arr = np.zeros((1,), dtype=np.int8)\n",
    "            Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            fps.append(arr)\n",
    "    return np.array(fps)\n",
    "\n",
    "def create_mfp(file_path=None, filename=None, df=None,mfp_radius=2, nBits=2048):\n",
    "    if file_path is not None: \n",
    "        df = pd.read_csv(file_path+filename)\n",
    "    \n",
    "    id_cols = ['NEK', 'compound_id','base_rdkit_smiles','subset', 'active'] \n",
    "    \n",
    "   \n",
    "    smiles = df['base_rdkit_smiles']\n",
    "    mfp_feats = smiles_to_fps(smiles,mfp_radius,nBits)\n",
    "    mfp_df = pd.DataFrame(mfp_feats)\n",
    "    # if mfp_df['base_rdkit_smiles'].isnull().any():\n",
    "    #     print(\"Warning: Missing values found in 'base_rdkit_smiles' column in df.\")\n",
    "    valid_smiles = smiles[smiles.apply(lambda x: Chem.MolFromSmiles(x) is not None)]\n",
    "    \n",
    "    feat_cols = set(list(mfp_df.columns))-set(id_cols)\n",
    "    final_order_cols = list(id_cols)+list(feat_cols)\n",
    "\n",
    "    mfp_df.reset_index(drop=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    final_df = pd.concat([df,mfp_df],axis=1)\n",
    "\n",
    "    final_df = final_df[final_order_cols]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6e4e3-2eae-4daa-b47d-fddab0725be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrays(file_path=None, root_name=None, df=None,nonfeat_cols=None): \n",
    "    if file_path is not None: \n",
    "        df=pd.read_csv(f'{file_path}{root_name}.csv')\n",
    "    train=df[df['subset']=='train']\n",
    "    test=df[df['subset']=='test']\n",
    "    train_y = train['active'].to_numpy().reshape(-1) \n",
    "    test_y =test['active'].to_numpy().reshape(-1) \n",
    "    trainX = train.drop(columns= nonfeat_cols) \n",
    "    testX = test.drop(columns= nonfeat_cols) \n",
    "    return trainX, train_y, testX, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae073984-1f2c-4aef-a5a6-866361af878f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "248facb9-3af8-4020-b649-e1b43b471070",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# (amanda's version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004341e-eb92-437e-aaef-5c9e7b243882",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/paper/datasets/80train_20test/featurized/'\n",
    "rng = np.random.default_rng(seed=42) # Create a Generator object with a seed \n",
    "numbers = rng.integers(low=0, high=1e6, size=10)  # Generate random numbers\n",
    "# print(numbers) # [ 89250 773956 654571 438878 433015 858597  85945 697368 201469  94177] \n",
    "for i, num in enumerate(numbers): # 5fold x10 \n",
    "    for nek in neks: \n",
    "        for feat in ['MOE','MFP']: \n",
    "            split_df = pd.read_csv(f'{datapath}{nek}_{feat}_none_scaled.csv')\n",
    "            train=split_df[split_df['subset']=='train']             \n",
    "            folded_train_df = create_folds(train,num) # 5 fold split (validation models) in this iteration \n",
    "            for fold in folds: # then use these 5 folds for train/validation \n",
    "                kfold_df=label_subsets(folded_train_df, fold, 'test') \n",
    "                if feat == 'MOE': \n",
    "                    featurized_df = featurize(feat_type='MOE',data_path=None, filename=None,moe_path=None, moe_file=None, moe_df=folded_train_df,df=kfold_df) \n",
    "         \n",
    "                else: \n",
    "                    featurized_df = featurize(feat_type='MFP', df=kfold_df,mfp_radius=2, nBits=2048)\n",
    "\n",
    "                for samp in [\"none_scaled\",'UNDER', 'SMOTE', 'ADASYN']:\n",
    "                    if samp == 'UNDER': \n",
    "                        sampled_df = under_sampling(data_path=None,filename=None,df=featurized_df) \n",
    "                        \n",
    "                    elif samp == \"SMOTE\" or samp == \"ADASYN\": \n",
    "                        sampled_df=over_sampling(data_path=None,filename=None,df=featurized_df, sampling=samp) \n",
    "\n",
    "                    elif samp == 'none_scaled': \n",
    "                        sampled_df = featurized_df \n",
    "\n",
    "                    # TRAIN here \n",
    "                        \n",
    "                    root_name = f'{nek}_{feat}_{samp}'\n",
    "                    print(f'{nek} {feat} {samp} {fold} (it: {i})')\n",
    "                    id_cols = ['NEK', 'compound_id','base_rdkit_smiles','subset', 'active'] \n",
    "                    trainX, train_y, testX, test_y=get_arrays(file_path=None, root_name=None, df=sampled_df,nonfeat_cols=id_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1647d51e-d098-4a31-89ec-b192998a973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x350CD4E40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5172c7d9-0c15-45d0-a1c4-4dc138dca120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x3516BE2E0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c3b5f-1e84-4f74-8f59-fb9694faf258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsci",
   "language": "python",
   "name": "atomsci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
