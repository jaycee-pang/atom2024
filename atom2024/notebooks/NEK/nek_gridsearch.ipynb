{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import imblearn as imb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "# import utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from split_data import *\n",
    "\n",
    "from RF_atomver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_types = ['moe', 'mfp']\n",
    "samplings = ['scaled', 'UNDER']\n",
    "model_types = ['RF','BRFC']\n",
    "nektype = ['binding','inhibition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrays(file_path, df_filename, filename_type=None, save=False):\n",
    "    \"\"\"use dataframes to get trainX, trainy, testX, testy out. Optional: save those files to csv\n",
    "    file_path: directory\n",
    "    df_filename: dataframe NEK#_binding_moe_{sampling}_df.csv (sampling: scaled, UNDER, SMOTE, ADASYN)\n",
    "    split dataframe to train and test, and x and y\n",
    "    save: bool, option to save splits to separate csv files (train X, train y, test X, test y) \n",
    "    returns: numpy arrays train X, train y, testX, test y\"\"\"\n",
    "    df = pd.read_csv(file_path+df_filename)\n",
    "    train_df= df[df['subset']=='train']\n",
    "    test_df = df[df['subset']=='test']\n",
    "    train_y = train_df['active'].to_numpy().reshape(-1)\n",
    "    test_y=test_df['active'].to_numpy().reshape(-1)\n",
    "    train_x_df = train_df.drop(columns='active')\n",
    "\n",
    "  \n",
    "    test_x_df = test_df.drop(columns='active')\n",
    "    \n",
    "    train_x_df = train_df.drop(columns='active')\n",
    "    test_x_df = test_df.drop(columns='active')\n",
    "    trainX = train_x_df.select_dtypes(include='number').to_numpy()\n",
    "    testX = test_x_df.select_dtypes(include='number').to_numpy()\n",
    "    \n",
    "    print(f'train X shape: {trainX.shape}, y: {train_y.shape}, test X: {testX.shape}, y:{test_y.shape}')\n",
    "    if (save and filename_type is not None): \n",
    "        trainxdf = pd.DataFrame(trainX)\n",
    "        trainxdf.to_csv(file_path+filename_type+'_trainX.csv', index=False)\n",
    "        # train_x_df.to_csv(filename_type+'_trainX.csv', index=False)\n",
    "        trainy_df = pd.DataFrame(train_y)\n",
    "        trainy_df.to_csv(file_path+filename_type+'_train_y.csv', index=False) \n",
    "        # test_x_df.to_csv(filename_type+'_testX.csv', index=False)\n",
    "        testxdf = pd.DataFrame(testX)\n",
    "        testxdf.to_csv(file_path+filename_type+'_testX.csv', index=False)\n",
    "        testy_df = pd.DataFrame(test_y)\n",
    "        testy_df.to_csv(file_path+filename_type+'_test_y.csv', index=False) \n",
    "        \n",
    "    return trainX, train_y, testX, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek_list = [\"2\", \"3\", \"5\", \"9\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = [] \n",
    "model_params_list = [] \n",
    "model_names = []\n",
    "cms=[]\n",
    "for n in nek_list:\n",
    "    for i in nektype: \n",
    "        for j in feat_types: \n",
    "            for k in samplings: \n",
    "                for l in model_types: \n",
    "                    print(f'NEK{n} {i}, {j}, {k}, {l}')\n",
    "                    # 1. need file path to pickle files (grid_search1)\n",
    "                    # 2. need filepath to datasets (these are the dataframes _df.csv) \n",
    "                    # call datasets (dataframe that gets split up into train x, train y, test x, test y)\n",
    "                    if (n== '2' or n == '9'): \n",
    "                        \n",
    "\n",
    "           \n",
    "                    # df_name = f'NEK2_{i}_{j}_{k}_df.csv'\n",
    "                    # trainX, trainy, testX, testy = get_arrays(file_path,df_name)\n",
    "                    # model_name = f'NEK2_{i}_{j}_{k}_{l}_GS.pkl'\n",
    "                    \n",
    "                    # print(f'\\n{model_name}')\n",
    "                    # model_names.append(model_name) \n",
    "                    # with open(model_name, 'rb') as f: \n",
    "                    #     model_search = pickle.load(f) \n",
    "                    # model =model_search.best_estimator_\n",
    "                    # model_params_list.append(model.get_params())\n",
    "                    # results = rf_results2(model, trainX, trainy, testX, testy)\n",
    "                    # results_list.append(results)\n",
    "                    # cm = confusion_matrix(testy, results['test_pred'])\n",
    "                    # cms.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
