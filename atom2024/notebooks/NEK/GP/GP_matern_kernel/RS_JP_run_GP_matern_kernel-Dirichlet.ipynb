{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf456674-bc2e-47f4-8898-7c91d24d510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix, f1_score, roc_curve,precision_recall_curve, auc\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/')\n",
    "from RF_GSCV import * # RF_GSCV contains the calculate metrics function to get the TP, TN, FP, FN scores \n",
    "from RF_atomver import prediction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "379ec7ea-fcfa-4e95-b240-791ec2db8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DirichletGPModel(ExactGP):\n",
    "    \"\"\"\n",
    "    A Dirichlet Gaussian Process (GP) model for multi-class classification.\n",
    "    This model uses a Gaussian Process with a Dirichlet prior to handle multi-class classification tasks.\n",
    "    It extends the ExactGP class from GPyTorch, a library for Gaussian Processes in PyTorch.\n",
    "    Attributes:\n",
    "        mean_module (gpytorch.means.ConstantMean): The mean module for the GP, initialized with a constant mean function for each class.\n",
    "        covar_module (gpytorch.kernels.ScaleKernel): The covariance module for the GP, using a scaled RBF kernel for each class.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training data features.\n",
    "        train_y (torch.Tensor): Training data labels.\n",
    "        likelihood (gpytorch.likelihoods.Likelihood): The likelihood function.\n",
    "        num_classes (int): The number of classes for the classification task.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(MaternKernel(nu=0.5, batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the GP model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data features.\n",
    "        Returns:\n",
    "            gpytorch.distributions.MultivariateNormal: The multivariate normal distribution representing the GP posterior.\n",
    "        \"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d38620-904f-4ffb-aa50-ce6beabf1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self,model, likelihood, iterations): \n",
    "        self.model = model\n",
    "        self.likelihood = likelihood \n",
    "        smoke_test = ('CI' in os.environ)\n",
    "        self.n_iterations = 2 if smoke_test else iterations\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        self.loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "    def train(self, train_x, train_y): \n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        predictions = [] \n",
    "        for i in range(self.n_iterations): \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(train_x)\n",
    "            loss = -self.loss_fn(output, self.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if (i%10==0): \n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, self.n_iterations, loss.item(),\n",
    "                    self.model.covar_module.base_kernel.lengthscale.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "             \n",
    "            self.optimizer.step() \n",
    "    def predict(self, input): \n",
    "        \"\"\"\n",
    "        Make predictions using the GP model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input data for making predictions.\n",
    "        \n",
    "        Returns:\n",
    "            dist (gpytorch.distributions.MultivariateNormal): The distribution representing the GP posterior.\n",
    "            observed_pred (gpytorch.distributions.MultivariateNormal): The predicted distribution considering the likelihood.\n",
    "            pred_means (torch.Tensor): The means of the predicted distributions.\n",
    "            class_pred (torch.Tensor): The predicted class labels.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            dist = self.model(input)     # output distribution\n",
    "            pred_means = dist.loc          # means of distributino \n",
    "            observed_pred = self.likelihood(self.model(input))    # likelihood predictions mean and var  \n",
    "\n",
    "            class_pred = self.model(input).loc.max(0)[1]\n",
    "            \n",
    "        return dist, observed_pred, pred_means, class_pred\n",
    "    \n",
    "\n",
    "    def evaluate(self, x_input, y_true): \n",
    "        \"\"\"\n",
    "        Evaluate the GP model.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor): The true labels for the input data.\n",
    "        \n",
    "        Returns:\n",
    "            y_pred (numpy.ndarray): The predicted class labels.\n",
    "        \"\"\"\n",
    "        y_pred = self.model(x_input).loc.max(0)[1].numpy()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def gp_results(self, x_input, y_true, plot_title=None): \n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics and print results.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor or numpy.ndarray): The true labels for the input data.\n",
    "            plot_title (str, optional): The title for the confusion matrix plot.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing evaluation metrics and confusion matrix components.\n",
    "        \"\"\"\n",
    "        y_pred = self.evaluate(x_input, y_true) \n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.numpy().reshape(-1)\n",
    "        # plot_confusion_matrix(y_true, y_pred, ['0','1'], title=plot_title)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        dist = self.model(x_input)     # get predicted distributions \n",
    "        pred_means = dist.loc          # means for predicted dist  \n",
    "\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        tp, tn, fp, fn = calculate_metrics(y_true, y_pred) \n",
    "        sensitivity = tp / (tp + fn) \n",
    "        specificity = tn / (tn + fp) \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, specificity: {specificity:.4f}, cm: {cm}')\n",
    "        return {'accuracy': accuracy, 'precision': precision,  'recall':recall, 'specificity':specificity, 'TN': tn, 'FN': fn, 'FP': fp, 'TP': tp }\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03196461-714f-41ad-ab58-67c40014acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_torch_tens_float(filepath, filename): \n",
    "    trainX_df = pd.read_csv(filepath+filename+'_trainX.csv')\n",
    "    trainy_df = pd.read_csv(filepath+filename+'_train_y.csv')\n",
    "    testX_df = pd.read_csv(filepath+filename+'_testX.csv')\n",
    "    testy_df = pd.read_csv(filepath+filename+'_test_y.csv')\n",
    "\n",
    "    train_x_temp = trainX_df.to_numpy().astype(\"double\") # double \n",
    "    test_x_temp = testX_df.to_numpy().astype(\"double\") #double \n",
    "    \n",
    "    train_y_temp = trainy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "    test_y_temp = testy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "    \n",
    "    # trainX = torch.from_numpy(train_x_temp)\n",
    "    # trainy = torch.from_numpy(train_y_temp)\n",
    "    # testX = torch.from_numpy(test_x_temp)\n",
    "    # testy = torch.from_numpy(test_y_temp)\n",
    "    trainX = torch.as_tensor(train_x_temp, dtype=torch.float32)\n",
    "    trainy = torch.as_tensor(train_y_temp, dtype=torch.float32)\n",
    "    testX = torch.as_tensor(test_x_temp, dtype=torch.float32)\n",
    "    testy = torch.as_tensor(test_y_temp, dtype=torch.float32)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6faad9bf-cb3a-4e74-87d2-f8fe148378aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_path= '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_matern_kernel/'\n",
    "def save_results(trainX, trainy, testX, testy, root_name, n_iterations=300, n_samples=100):\n",
    "    \"\"\"\n",
    "    Train a Dirichlet Gaussian Process model and save the training and test performance results.\n",
    "\n",
    "    This function trains a Dirichlet GP model on the given training data, evaluates it on both the training\n",
    "    and test data, and saves various performance metrics and predictions to pandas DataFrames.\n",
    "\n",
    "    Args:\n",
    "        trainX (torch.Tensor): The training data features.\n",
    "        trainy (torch.Tensor): The training data labels.\n",
    "        testX (torch.Tensor): The test data features.\n",
    "        testy (torch.Tensor): The test data labels.\n",
    "        root_name (str): The root name used for labeling the model in the results.\n",
    "        n_iterations (int, optional): The number of training iterations. Default is 300.\n",
    "        n_samples (int, optional): The number of samples for prediction. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "        train_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the training data.\n",
    "        test_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the test data.\n",
    "    \"\"\"\n",
    "    likelihood = DirichletClassificationLikelihood(trainy.long(), learn_additional_noise=True)\n",
    "    model = DirichletGPModel(trainX, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "    # n_iterations = 300\n",
    "    trainer = Trainer(model, likelihood, n_iterations)\n",
    "    trainer.train(trainX, trainy) \n",
    "  \n",
    "    train_dist, train_observed_pred, train_pred_means, train_pred  = trainer.predict(trainX)\n",
    "    train_results = trainer.gp_results(trainX, trainy)\n",
    "    test_dist, test_observed_pred, test_pred_means, test_pred  = trainer.predict(testX)\n",
    "    test_results = trainer.gp_results(testX, testy)\n",
    "    \n",
    "    train_observed_pred.mean.numpy()\n",
    "    train_pred_variance2D = train_observed_pred.variance.numpy()\n",
    "    test_observed_pred.mean.numpy()\n",
    "    test_pred_variance2D=test_observed_pred.variance.numpy()\n",
    "    \n",
    "    train_pred_samples = train_dist.sample(torch.Size((256,))).exp()\n",
    "    train_probabilities = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "\n",
    "    train_prob_stds = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    "    test_pred_samples = test_dist.sample(torch.Size((100,))).exp()\n",
    "\n",
    "    test_probabilities = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "    test_prob_stds = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    " \n",
    "    train_perf_df = pd.DataFrame()\n",
    "    test_perf_df = pd.DataFrame()\n",
    "    train_perf_df['mean_pred_class0'] = train_observed_pred.mean.numpy()[0,]\n",
    "    train_perf_df['mean_pred_class1'] = train_observed_pred.mean.numpy()[1,]\n",
    "    train_perf_df['y'] = trainy\n",
    "    train_perf_df['y_pred'] = train_pred_means.max(0)[1]\n",
    "    train_perf_df['var_pred_class0']=train_observed_pred.variance.numpy()[0,]\n",
    "    train_perf_df['var_pred_class1']=train_observed_pred.variance.numpy()[1,]\n",
    "    train_perf_df['pred_prob_class0'] = train_probabilities.numpy()[0,]\n",
    "    train_perf_df['pred_prob_class1'] = train_probabilities.numpy()[1,]\n",
    "    train_perf_df['pred_prob_std_class0'] = train_prob_stds.numpy()[0,]\n",
    "    train_perf_df['pred_prob_std_class1'] = train_prob_stds.numpy()[1,]\n",
    "    train_perf_df['model'] = f'{root_name}_GP_Dirichlet_matern'\n",
    "    train_perf_df['subset'] = 'train' \n",
    "    train_cm = confusion_matrix(trainy, train_perf_df['y_pred'])\n",
    "    cm_flattened = train_cm.flatten().tolist()\n",
    "    train_perf_df['cm']= [cm_flattened]* len(train_perf_df)\n",
    "    train_perf_df['prediction_type'] = train_perf_df.apply(lambda x: prediction_type(x['y'], x['y_pred']), axis=1)\n",
    "    train_perf_df['ROC-AUC'] = roc_auc_score(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['MCC'] = matthews_corrcoef(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['Balanced Accuracy'] = balanced_accuracy_score(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['f1'] = f1_score(trainy, train_perf_df['y_pred'])\n",
    "    \n",
    "    test_perf_df['mean_pred_class0'] = test_observed_pred.mean.numpy()[0,]\n",
    "    test_perf_df['mean_pred_class1'] = test_observed_pred.mean.numpy()[1,]\n",
    "    test_perf_df['y'] = testy\n",
    "    test_perf_df['y_pred'] = test_pred_means.max(0)[1]\n",
    "    test_perf_df['var_pred_class0']=test_observed_pred.variance.numpy()[0,]\n",
    "    test_perf_df['var_pred_class1']=test_observed_pred.variance.numpy()[1,]\n",
    "    test_perf_df['pred_prob_class0'] = test_probabilities.numpy()[0,]\n",
    "    test_perf_df['pred_prob_class1'] = test_probabilities.numpy()[1,]\n",
    "    test_perf_df['pred_prob_std_class0'] =test_prob_stds.numpy()[0,]\n",
    "    test_perf_df['pred_prob_std_class1'] = test_prob_stds.numpy()[1,]\n",
    "    test_perf_df['model'] = f'{root_name}_GP_Dirichlet_matern'\n",
    "    test_perf_df['subset'] = 'test' \n",
    "    test_cm = confusion_matrix(testy, test_perf_df['y_pred'])\n",
    "    test_cm_flattened = test_cm.flatten().tolist()\n",
    "    test_perf_df['cm']= [test_cm_flattened]* len(test_perf_df)\n",
    "    test_perf_df['prediction_type'] = test_perf_df.apply(lambda x: prediction_type(x['y'], x['y_pred']), axis=1)\n",
    "    test_perf_df['ROC-AUC'] = roc_auc_score(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['MCC'] = matthews_corrcoef(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['Balanced Accuracy'] = balanced_accuracy_score(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['f1'] = f1_score(testy, test_perf_df['y_pred'])\n",
    "    with open(f'{GP_path}{root_name}_GP_Dirichlet_matern_model.pkl', 'wb') as f: \n",
    "        pickle.dump(model,f)\n",
    "    with open(f'{GP_path}{root_name}_GP_Dirichlet_matern_likelihood.pkl', 'wb') as f: \n",
    "        pickle.dump(likelihood,f)\n",
    "    for k, val in train_results.items(): \n",
    "        train_perf_df[k] = val\n",
    "    for k, val in test_results.items():\n",
    "        test_perf_df[k] = val\n",
    "    return train_perf_df, test_perf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb7b782a-0791-480d-8a34-cc415cb653eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "NEK2 binding moe scaled\n",
      "trainX:torch.Size([1125, 306]), train y: torch.Size([1125]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.108   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.483   lengthscale: 1.119   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.469   lengthscale: 1.801   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.758   lengthscale: 2.796   noise: 1.316\n",
      "Iter 41/300 - Loss: 3.394   lengthscale: 4.012   noise: 1.427\n",
      "Iter 51/300 - Loss: 3.283   lengthscale: 5.080   noise: 1.419\n",
      "Iter 61/300 - Loss: 3.238   lengthscale: 5.995   noise: 1.345\n",
      "Iter 71/300 - Loss: 3.212   lengthscale: 6.756   noise: 1.240\n",
      "Iter 81/300 - Loss: 3.197   lengthscale: 7.395   noise: 1.121\n",
      "Iter 91/300 - Loss: 3.169   lengthscale: 7.970   noise: 0.998\n",
      "Iter 101/300 - Loss: 3.152   lengthscale: 8.453   noise: 0.876\n",
      "Iter 111/300 - Loss: 3.145   lengthscale: 8.898   noise: 0.761\n",
      "Iter 121/300 - Loss: 3.131   lengthscale: 9.313   noise: 0.659\n",
      "Iter 131/300 - Loss: 3.116   lengthscale: 9.707   noise: 0.573\n",
      "Iter 141/300 - Loss: 3.105   lengthscale: 10.059   noise: 0.503\n",
      "Iter 151/300 - Loss: 3.105   lengthscale: 10.363   noise: 0.448\n",
      "Iter 161/300 - Loss: 3.097   lengthscale: 10.645   noise: 0.406\n",
      "Iter 171/300 - Loss: 3.095   lengthscale: 10.871   noise: 0.374\n",
      "Iter 181/300 - Loss: 3.093   lengthscale: 11.088   noise: 0.348\n",
      "Iter 191/300 - Loss: 3.086   lengthscale: 11.302   noise: 0.328\n",
      "Iter 201/300 - Loss: 3.085   lengthscale: 11.519   noise: 0.311\n",
      "Iter 211/300 - Loss: 3.082   lengthscale: 11.722   noise: 0.297\n",
      "Iter 221/300 - Loss: 3.083   lengthscale: 11.899   noise: 0.284\n",
      "Iter 231/300 - Loss: 3.083   lengthscale: 12.071   noise: 0.273\n",
      "Iter 241/300 - Loss: 3.081   lengthscale: 12.213   noise: 0.263\n",
      "Iter 251/300 - Loss: 3.081   lengthscale: 12.327   noise: 0.254\n",
      "Iter 261/300 - Loss: 3.080   lengthscale: 12.445   noise: 0.246\n",
      "Iter 271/300 - Loss: 3.077   lengthscale: 12.552   noise: 0.238\n",
      "Iter 281/300 - Loss: 3.078   lengthscale: 12.656   noise: 0.231\n",
      "Iter 291/300 - Loss: 3.071   lengthscale: 12.767   noise: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9600, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1080    0]\n",
      " [  45    0]]\n",
      "accuracy: 0.9576, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[271   0]\n",
      " [ 12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 binding moe UNDER\n",
      "trainX:torch.Size([90, 306]), train y: torch.Size([90]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.264   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.051   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.260   lengthscale: 3.155   noise: 2.571\n",
      "Iter 41/300 - Loss: 5.202   lengthscale: 4.419   noise: 3.001\n",
      "Iter 51/300 - Loss: 5.183   lengthscale: 5.572   noise: 3.285\n",
      "Iter 61/300 - Loss: 5.175   lengthscale: 6.518   noise: 3.455\n",
      "Iter 71/300 - Loss: 5.170   lengthscale: 7.291   noise: 3.539\n",
      "Iter 81/300 - Loss: 5.167   lengthscale: 7.937   noise: 3.563\n",
      "Iter 91/300 - Loss: 5.164   lengthscale: 8.492   noise: 3.546\n",
      "Iter 101/300 - Loss: 5.162   lengthscale: 8.981   noise: 3.504\n",
      "Iter 111/300 - Loss: 5.160   lengthscale: 9.417   noise: 3.444\n",
      "Iter 121/300 - Loss: 5.158   lengthscale: 9.811   noise: 3.372\n",
      "Iter 131/300 - Loss: 5.157   lengthscale: 10.167   noise: 3.293\n",
      "Iter 141/300 - Loss: 5.155   lengthscale: 10.492   noise: 3.208\n",
      "Iter 151/300 - Loss: 5.154   lengthscale: 10.790   noise: 3.118\n",
      "Iter 161/300 - Loss: 5.152   lengthscale: 11.063   noise: 3.025\n",
      "Iter 171/300 - Loss: 5.151   lengthscale: 11.314   noise: 2.928\n",
      "Iter 181/300 - Loss: 5.149   lengthscale: 11.546   noise: 2.829\n",
      "Iter 191/300 - Loss: 5.148   lengthscale: 11.761   noise: 2.727\n",
      "Iter 201/300 - Loss: 5.146   lengthscale: 11.959   noise: 2.622\n",
      "Iter 211/300 - Loss: 5.145   lengthscale: 12.142   noise: 2.516\n",
      "Iter 221/300 - Loss: 5.144   lengthscale: 12.312   noise: 2.409\n",
      "Iter 231/300 - Loss: 5.142   lengthscale: 12.468   noise: 2.301\n",
      "Iter 241/300 - Loss: 5.141   lengthscale: 12.613   noise: 2.192\n",
      "Iter 251/300 - Loss: 5.140   lengthscale: 12.747   noise: 2.084\n",
      "Iter 261/300 - Loss: 5.138   lengthscale: 12.871   noise: 1.976\n",
      "Iter 271/300 - Loss: 5.137   lengthscale: 12.986   noise: 1.869\n",
      "Iter 281/300 - Loss: 5.136   lengthscale: 13.094   noise: 1.764\n",
      "Iter 291/300 - Loss: 5.135   lengthscale: 13.194   noise: 1.661\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[45  0]\n",
      " [ 0 45]]\n",
      "accuracy: 0.7739, precision: 0.1061, recall: 0.5833, specificity: 0.7823, cm: [[212  59]\n",
      " [  5   7]]\n",
      "\n",
      "NEK2 binding moe SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([2160, 306]), train y: torch.Size([2160]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.847   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.479   lengthscale: 1.319   noise: 1.237\n",
      "Iter 21/300 - Loss: 4.810   lengthscale: 2.171   noise: 1.450\n",
      "Iter 31/300 - Loss: 4.417   lengthscale: 3.128   noise: 1.284\n",
      "Iter 41/300 - Loss: 4.110   lengthscale: 4.067   noise: 0.875\n",
      "Iter 51/300 - Loss: 3.919   lengthscale: 4.853   noise: 0.456\n",
      "Iter 61/300 - Loss: 3.780   lengthscale: 5.460   noise: 0.201\n",
      "Iter 71/300 - Loss: 3.705   lengthscale: 5.940   noise: 0.095\n",
      "Iter 81/300 - Loss: 3.660   lengthscale: 6.339   noise: 0.056\n",
      "Iter 91/300 - Loss: 3.621   lengthscale: 6.685   noise: 0.038\n",
      "Iter 101/300 - Loss: 3.603   lengthscale: 6.991   noise: 0.029\n",
      "Iter 111/300 - Loss: 3.596   lengthscale: 7.268   noise: 0.024\n",
      "Iter 121/300 - Loss: 3.581   lengthscale: 7.521   noise: 0.020\n",
      "Iter 131/300 - Loss: 3.574   lengthscale: 7.757   noise: 0.017\n",
      "Iter 141/300 - Loss: 3.565   lengthscale: 7.978   noise: 0.015\n",
      "Iter 151/300 - Loss: 3.560   lengthscale: 8.186   noise: 0.014\n",
      "Iter 161/300 - Loss: 3.555   lengthscale: 8.384   noise: 0.012\n",
      "Iter 171/300 - Loss: 3.553   lengthscale: 8.571   noise: 0.011\n",
      "Iter 181/300 - Loss: 3.553   lengthscale: 8.750   noise: 0.010\n",
      "Iter 191/300 - Loss: 3.548   lengthscale: 8.922   noise: 0.009\n",
      "Iter 201/300 - Loss: 3.543   lengthscale: 9.088   noise: 0.008\n",
      "Iter 211/300 - Loss: 3.532   lengthscale: 9.247   noise: 0.008\n",
      "Iter 221/300 - Loss: 3.531   lengthscale: 9.400   noise: 0.007\n",
      "Iter 231/300 - Loss: 3.525   lengthscale: 9.549   noise: 0.007\n",
      "Iter 241/300 - Loss: 3.531   lengthscale: 9.695   noise: 0.006\n",
      "Iter 251/300 - Loss: 3.527   lengthscale: 9.835   noise: 0.006\n",
      "Iter 261/300 - Loss: 3.520   lengthscale: 9.971   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.512   lengthscale: 10.104   noise: 0.005\n",
      "Iter 281/300 - Loss: 3.518   lengthscale: 10.233   noise: 0.005\n",
      "Iter 291/300 - Loss: 3.512   lengthscale: 10.360   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9991, recall: 1.0000, specificity: 0.9991, cm: [[1079    1]\n",
      " [   0 1080]]\n",
      "accuracy: 0.9647, precision: 0.7500, recall: 0.2500, specificity: 0.9963, cm: [[270   1]\n",
      " [  9   3]]\n",
      "\n",
      "NEK2 binding moe ADASYN\n",
      "trainX:torch.Size([2158, 306]), train y: torch.Size([2158]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.890   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.538   lengthscale: 1.321   noise: 1.253\n",
      "Iter 21/300 - Loss: 4.850   lengthscale: 2.183   noise: 1.532\n",
      "Iter 31/300 - Loss: 4.445   lengthscale: 3.165   noise: 1.371\n",
      "Iter 41/300 - Loss: 4.142   lengthscale: 4.127   noise: 0.937\n",
      "Iter 51/300 - Loss: 3.935   lengthscale: 4.931   noise: 0.492\n",
      "Iter 61/300 - Loss: 3.815   lengthscale: 5.554   noise: 0.218\n",
      "Iter 71/300 - Loss: 3.737   lengthscale: 6.046   noise: 0.103\n",
      "Iter 81/300 - Loss: 3.687   lengthscale: 6.455   noise: 0.060\n",
      "Iter 91/300 - Loss: 3.652   lengthscale: 6.808   noise: 0.041\n",
      "Iter 101/300 - Loss: 3.624   lengthscale: 7.120   noise: 0.032\n",
      "Iter 111/300 - Loss: 3.618   lengthscale: 7.400   noise: 0.026\n",
      "Iter 121/300 - Loss: 3.613   lengthscale: 7.656   noise: 0.022\n",
      "Iter 131/300 - Loss: 3.597   lengthscale: 7.893   noise: 0.019\n",
      "Iter 141/300 - Loss: 3.587   lengthscale: 8.115   noise: 0.016\n",
      "Iter 151/300 - Loss: 3.580   lengthscale: 8.325   noise: 0.014\n",
      "Iter 161/300 - Loss: 3.582   lengthscale: 8.524   noise: 0.013\n",
      "Iter 171/300 - Loss: 3.575   lengthscale: 8.713   noise: 0.012\n",
      "Iter 181/300 - Loss: 3.568   lengthscale: 8.893   noise: 0.011\n",
      "Iter 191/300 - Loss: 3.558   lengthscale: 9.066   noise: 0.010\n",
      "Iter 201/300 - Loss: 3.553   lengthscale: 9.233   noise: 0.009\n",
      "Iter 211/300 - Loss: 3.550   lengthscale: 9.393   noise: 0.008\n",
      "Iter 221/300 - Loss: 3.545   lengthscale: 9.550   noise: 0.008\n",
      "Iter 231/300 - Loss: 3.546   lengthscale: 9.701   noise: 0.007\n",
      "Iter 241/300 - Loss: 3.549   lengthscale: 9.849   noise: 0.007\n",
      "Iter 251/300 - Loss: 3.542   lengthscale: 9.991   noise: 0.006\n",
      "Iter 261/300 - Loss: 3.539   lengthscale: 10.130   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.540   lengthscale: 10.264   noise: 0.006\n",
      "Iter 281/300 - Loss: 3.532   lengthscale: 10.395   noise: 0.005\n",
      "Iter 291/300 - Loss: 3.543   lengthscale: 10.522   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9991, recall: 1.0000, specificity: 0.9991, cm: [[1079    1]\n",
      " [   0 1078]]\n",
      "accuracy: 0.9682, precision: 1.0000, recall: 0.2500, specificity: 1.0000, cm: [[271   0]\n",
      " [  9   3]]\n",
      "\n",
      "NEK2 binding mfp scaled\n",
      "trainX:torch.Size([1125, 2048]), train y: torch.Size([1125]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.093   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.102   lengthscale: 1.270   noise: 0.806\n",
      "Iter 21/300 - Loss: 3.525   lengthscale: 2.048   noise: 0.978\n",
      "Iter 31/300 - Loss: 3.258   lengthscale: 2.768   noise: 1.018\n",
      "Iter 41/300 - Loss: 3.195   lengthscale: 3.268   noise: 0.968\n",
      "Iter 51/300 - Loss: 3.164   lengthscale: 3.597   noise: 0.878\n",
      "Iter 61/300 - Loss: 3.139   lengthscale: 3.823   noise: 0.771\n",
      "Iter 71/300 - Loss: 3.127   lengthscale: 3.993   noise: 0.663\n",
      "Iter 81/300 - Loss: 3.113   lengthscale: 4.129   noise: 0.562\n",
      "Iter 91/300 - Loss: 3.099   lengthscale: 4.247   noise: 0.475\n",
      "Iter 101/300 - Loss: 3.092   lengthscale: 4.352   noise: 0.403\n",
      "Iter 111/300 - Loss: 3.090   lengthscale: 4.444   noise: 0.346\n",
      "Iter 121/300 - Loss: 3.087   lengthscale: 4.530   noise: 0.301\n",
      "Iter 131/300 - Loss: 3.078   lengthscale: 4.610   noise: 0.266\n",
      "Iter 141/300 - Loss: 3.068   lengthscale: 4.682   noise: 0.239\n",
      "Iter 151/300 - Loss: 3.072   lengthscale: 4.748   noise: 0.217\n",
      "Iter 161/300 - Loss: 3.072   lengthscale: 4.809   noise: 0.199\n",
      "Iter 171/300 - Loss: 3.065   lengthscale: 4.867   noise: 0.184\n",
      "Iter 181/300 - Loss: 3.064   lengthscale: 4.924   noise: 0.171\n",
      "Iter 191/300 - Loss: 3.062   lengthscale: 4.974   noise: 0.160\n",
      "Iter 201/300 - Loss: 3.060   lengthscale: 5.021   noise: 0.150\n",
      "Iter 211/300 - Loss: 3.056   lengthscale: 5.064   noise: 0.141\n",
      "Iter 221/300 - Loss: 3.059   lengthscale: 5.105   noise: 0.133\n",
      "Iter 231/300 - Loss: 3.062   lengthscale: 5.147   noise: 0.126\n",
      "Iter 241/300 - Loss: 3.056   lengthscale: 5.185   noise: 0.119\n",
      "Iter 251/300 - Loss: 3.058   lengthscale: 5.218   noise: 0.113\n",
      "Iter 261/300 - Loss: 3.053   lengthscale: 5.252   noise: 0.108\n",
      "Iter 271/300 - Loss: 3.048   lengthscale: 5.286   noise: 0.103\n",
      "Iter 281/300 - Loss: 3.055   lengthscale: 5.318   noise: 0.098\n",
      "Iter 291/300 - Loss: 3.045   lengthscale: 5.350   noise: 0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9600, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1080    0]\n",
      " [  45    0]]\n",
      "accuracy: 0.9576, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[271   0]\n",
      " [ 12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 binding mfp UNDER\n",
      "trainX:torch.Size([90, 2048]), train y: torch.Size([90]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.922   lengthscale: 1.294   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.419   lengthscale: 2.156   noise: 1.983\n",
      "Iter 31/300 - Loss: 5.285   lengthscale: 2.930   noise: 2.605\n",
      "Iter 41/300 - Loss: 5.247   lengthscale: 3.127   noise: 3.113\n",
      "Iter 51/300 - Loss: 5.231   lengthscale: 2.952   noise: 3.489\n",
      "Iter 61/300 - Loss: 5.222   lengthscale: 2.618   noise: 3.746\n",
      "Iter 71/300 - Loss: 5.216   lengthscale: 2.232   noise: 3.909\n",
      "Iter 81/300 - Loss: 5.212   lengthscale: 1.868   noise: 4.007\n",
      "Iter 91/300 - Loss: 5.209   lengthscale: 1.571   noise: 4.062\n",
      "Iter 101/300 - Loss: 5.207   lengthscale: 1.337   noise: 4.092\n",
      "Iter 111/300 - Loss: 5.206   lengthscale: 1.148   noise: 4.108\n",
      "Iter 121/300 - Loss: 5.205   lengthscale: 0.994   noise: 4.117\n",
      "Iter 131/300 - Loss: 5.204   lengthscale: 0.870   noise: 4.123\n",
      "Iter 141/300 - Loss: 5.203   lengthscale: 0.770   noise: 4.129\n",
      "Iter 151/300 - Loss: 5.203   lengthscale: 0.689   noise: 4.134\n",
      "Iter 161/300 - Loss: 5.203   lengthscale: 0.622   noise: 4.138\n",
      "Iter 171/300 - Loss: 5.203   lengthscale: 0.567   noise: 4.141\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.520   noise: 4.143\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.481   noise: 4.145\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.448   noise: 4.146\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.420   noise: 4.147\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.396   noise: 4.148\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.376   noise: 4.149\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.358   noise: 4.149\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.343   noise: 4.150\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.330   noise: 4.150\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.319   noise: 4.151\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.309   noise: 4.151\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.300   noise: 4.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[45  0]\n",
      " [ 0 45]]\n",
      "accuracy: 0.0565, precision: 0.0430, recall: 1.0000, specificity: 0.0148, cm: [[  4 267]\n",
      " [  0  12]]\n",
      "\n",
      "NEK2 binding mfp SMOTE\n",
      "trainX:torch.Size([2160, 2048]), train y: torch.Size([2160]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 5.986   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.619   lengthscale: 1.297   noise: 0.786\n",
      "Iter 21/300 - Loss: 3.852   lengthscale: 2.016   noise: 0.668\n",
      "Iter 31/300 - Loss: 3.576   lengthscale: 2.629   noise: 0.352\n",
      "Iter 41/300 - Loss: 3.449   lengthscale: 3.034   noise: 0.153\n",
      "Iter 51/300 - Loss: 3.377   lengthscale: 3.302   noise: 0.072\n",
      "Iter 61/300 - Loss: 3.350   lengthscale: 3.499   noise: 0.042\n",
      "Iter 71/300 - Loss: 3.326   lengthscale: 3.658   noise: 0.029\n",
      "Iter 81/300 - Loss: 3.328   lengthscale: 3.797   noise: 0.022\n",
      "Iter 91/300 - Loss: 3.305   lengthscale: 3.923   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.302   lengthscale: 4.039   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.299   lengthscale: 4.149   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.302   lengthscale: 4.254   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.282   lengthscale: 4.355   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.286   lengthscale: 4.451   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.282   lengthscale: 4.543   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.283   lengthscale: 4.632   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.281   lengthscale: 4.718   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.274   lengthscale: 4.802   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.275   lengthscale: 4.883   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.272   lengthscale: 4.963   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.269   lengthscale: 5.040   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.270   lengthscale: 5.115   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.280   lengthscale: 5.187   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.273   lengthscale: 5.259   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.263   lengthscale: 5.328   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.268   lengthscale: 5.395   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.271   lengthscale: 5.461   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.262   lengthscale: 5.526   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.261   lengthscale: 5.589   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9954, precision: 0.9991, recall: 0.9917, specificity: 0.9991, cm: [[1079    1]\n",
      " [   9 1071]]\n",
      "accuracy: 0.9647, precision: 1.0000, recall: 0.1667, specificity: 1.0000, cm: [[271   0]\n",
      " [ 10   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 binding mfp ADASYN\n",
      "trainX:torch.Size([2168, 2048]), train y: torch.Size([2168]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.020   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.624   lengthscale: 1.296   noise: 0.785\n",
      "Iter 21/300 - Loss: 3.864   lengthscale: 2.007   noise: 0.659\n",
      "Iter 31/300 - Loss: 3.578   lengthscale: 2.610   noise: 0.343\n",
      "Iter 41/300 - Loss: 3.448   lengthscale: 3.007   noise: 0.149\n",
      "Iter 51/300 - Loss: 3.389   lengthscale: 3.270   noise: 0.070\n",
      "Iter 61/300 - Loss: 3.350   lengthscale: 3.462   noise: 0.041\n",
      "Iter 71/300 - Loss: 3.334   lengthscale: 3.617   noise: 0.029\n",
      "Iter 81/300 - Loss: 3.323   lengthscale: 3.753   noise: 0.022\n",
      "Iter 91/300 - Loss: 3.314   lengthscale: 3.875   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.322   lengthscale: 3.989   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.309   lengthscale: 4.097   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.305   lengthscale: 4.200   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.302   lengthscale: 4.299   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.293   lengthscale: 4.394   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.295   lengthscale: 4.485   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.294   lengthscale: 4.574   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.284   lengthscale: 4.659   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.291   lengthscale: 4.741   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.283   lengthscale: 4.822   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.286   lengthscale: 4.900   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.272   lengthscale: 4.976   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.285   lengthscale: 5.049   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.283   lengthscale: 5.121   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.274   lengthscale: 5.191   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.276   lengthscale: 5.259   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.272   lengthscale: 5.326   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.273   lengthscale: 5.392   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.272   lengthscale: 5.455   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.270   lengthscale: 5.517   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9954, precision: 0.9991, recall: 0.9917, specificity: 0.9991, cm: [[1079    1]\n",
      " [   9 1079]]\n",
      "accuracy: 0.9647, precision: 1.0000, recall: 0.1667, specificity: 1.0000, cm: [[271   0]\n",
      " [ 10   2]]\n",
      "\n",
      "NEK2 inhibition moe scaled\n",
      "trainX:torch.Size([1635, 306]), train y: torch.Size([1635]), testX: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.102   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.534   lengthscale: 1.286   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.523   lengthscale: 2.111   noise: 1.070\n",
      "Iter 31/300 - Loss: 3.813   lengthscale: 3.224   noise: 1.298\n",
      "Iter 41/300 - Loss: 3.524   lengthscale: 4.419   noise: 1.387\n",
      "Iter 51/300 - Loss: 3.447   lengthscale: 5.378   noise: 1.365\n",
      "Iter 61/300 - Loss: 3.410   lengthscale: 6.082   noise: 1.285\n",
      "Iter 71/300 - Loss: 3.379   lengthscale: 6.613   noise: 1.174\n",
      "Iter 81/300 - Loss: 3.362   lengthscale: 7.036   noise: 1.050\n",
      "Iter 91/300 - Loss: 3.345   lengthscale: 7.387   noise: 0.922\n",
      "Iter 101/300 - Loss: 3.321   lengthscale: 7.686   noise: 0.796\n",
      "Iter 111/300 - Loss: 3.311   lengthscale: 7.961   noise: 0.680\n",
      "Iter 121/300 - Loss: 3.297   lengthscale: 8.211   noise: 0.576\n",
      "Iter 131/300 - Loss: 3.288   lengthscale: 8.443   noise: 0.488\n",
      "Iter 141/300 - Loss: 3.280   lengthscale: 8.660   noise: 0.416\n",
      "Iter 151/300 - Loss: 3.278   lengthscale: 8.859   noise: 0.359\n",
      "Iter 161/300 - Loss: 3.265   lengthscale: 9.047   noise: 0.312\n",
      "Iter 171/300 - Loss: 3.269   lengthscale: 9.223   noise: 0.274\n",
      "Iter 181/300 - Loss: 3.260   lengthscale: 9.390   noise: 0.243\n",
      "Iter 191/300 - Loss: 3.259   lengthscale: 9.547   noise: 0.218\n",
      "Iter 201/300 - Loss: 3.254   lengthscale: 9.695   noise: 0.197\n",
      "Iter 211/300 - Loss: 3.255   lengthscale: 9.836   noise: 0.179\n",
      "Iter 221/300 - Loss: 3.250   lengthscale: 9.970   noise: 0.163\n",
      "Iter 231/300 - Loss: 3.247   lengthscale: 10.098   noise: 0.149\n",
      "Iter 241/300 - Loss: 3.243   lengthscale: 10.219   noise: 0.137\n",
      "Iter 251/300 - Loss: 3.246   lengthscale: 10.337   noise: 0.126\n",
      "Iter 261/300 - Loss: 3.239   lengthscale: 10.448   noise: 0.117\n",
      "Iter 271/300 - Loss: 3.242   lengthscale: 10.557   noise: 0.109\n",
      "Iter 281/300 - Loss: 3.238   lengthscale: 10.659   noise: 0.101\n",
      "Iter 291/300 - Loss: 3.238   lengthscale: 10.756   noise: 0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9315, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1523    0]\n",
      " [ 112    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9315, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[381   0]\n",
      " [ 28   0]]\n",
      "\n",
      "NEK2 inhibition moe UNDER\n",
      "trainX:torch.Size([224, 306]), train y: torch.Size([224]), testX: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.930   lengthscale: 1.287   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.428   lengthscale: 2.098   noise: 1.980\n",
      "Iter 31/300 - Loss: 5.207   lengthscale: 3.203   noise: 2.552\n",
      "Iter 41/300 - Loss: 5.074   lengthscale: 4.519   noise: 2.888\n",
      "Iter 51/300 - Loss: 4.989   lengthscale: 5.815   noise: 2.947\n",
      "Iter 61/300 - Loss: 4.934   lengthscale: 6.931   noise: 2.771\n",
      "Iter 71/300 - Loss: 4.892   lengthscale: 7.848   noise: 2.440\n",
      "Iter 81/300 - Loss: 4.856   lengthscale: 8.610   noise: 2.031\n",
      "Iter 91/300 - Loss: 4.825   lengthscale: 9.264   noise: 1.607\n",
      "Iter 101/300 - Loss: 4.798   lengthscale: 9.844   noise: 1.218\n",
      "Iter 111/300 - Loss: 4.776   lengthscale: 10.368   noise: 0.899\n",
      "Iter 121/300 - Loss: 4.758   lengthscale: 10.849   noise: 0.660\n",
      "Iter 131/300 - Loss: 4.744   lengthscale: 11.295   noise: 0.491\n",
      "Iter 141/300 - Loss: 4.733   lengthscale: 11.713   noise: 0.374\n",
      "Iter 151/300 - Loss: 4.725   lengthscale: 12.108   noise: 0.294\n",
      "Iter 161/300 - Loss: 4.718   lengthscale: 12.483   noise: 0.237\n",
      "Iter 171/300 - Loss: 4.712   lengthscale: 12.842   noise: 0.196\n",
      "Iter 181/300 - Loss: 4.707   lengthscale: 13.187   noise: 0.166\n",
      "Iter 191/300 - Loss: 4.703   lengthscale: 13.519   noise: 0.143\n",
      "Iter 201/300 - Loss: 4.699   lengthscale: 13.839   noise: 0.125\n",
      "Iter 211/300 - Loss: 4.696   lengthscale: 14.149   noise: 0.110\n",
      "Iter 221/300 - Loss: 4.693   lengthscale: 14.449   noise: 0.098\n",
      "Iter 231/300 - Loss: 4.691   lengthscale: 14.740   noise: 0.088\n",
      "Iter 241/300 - Loss: 4.688   lengthscale: 15.023   noise: 0.080\n",
      "Iter 251/300 - Loss: 4.686   lengthscale: 15.298   noise: 0.073\n",
      "Iter 261/300 - Loss: 4.684   lengthscale: 15.565   noise: 0.067\n",
      "Iter 271/300 - Loss: 4.683   lengthscale: 15.826   noise: 0.062\n",
      "Iter 281/300 - Loss: 4.681   lengthscale: 16.081   noise: 0.058\n",
      "Iter 291/300 - Loss: 4.679   lengthscale: 16.331   noise: 0.054\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[112   0]\n",
      " [  0 112]]\n",
      "accuracy: 0.8631, precision: 0.3056, recall: 0.7857, specificity: 0.8688, cm: [[331  50]\n",
      " [  6  22]]\n",
      "\n",
      "NEK2 inhibition moe SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([3046, 306]), train y: torch.Size([3046]), testX: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.910   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.563   lengthscale: 1.320   noise: 1.261\n",
      "Iter 21/300 - Loss: 4.840   lengthscale: 2.176   noise: 1.573\n",
      "Iter 31/300 - Loss: 4.387   lengthscale: 3.171   noise: 1.382\n",
      "Iter 41/300 - Loss: 4.105   lengthscale: 4.105   noise: 0.904\n",
      "Iter 51/300 - Loss: 3.928   lengthscale: 4.844   noise: 0.464\n",
      "Iter 61/300 - Loss: 3.810   lengthscale: 5.412   noise: 0.209\n",
      "Iter 71/300 - Loss: 3.725   lengthscale: 5.872   noise: 0.103\n",
      "Iter 81/300 - Loss: 3.675   lengthscale: 6.265   noise: 0.062\n",
      "Iter 91/300 - Loss: 3.646   lengthscale: 6.612   noise: 0.043\n",
      "Iter 101/300 - Loss: 3.625   lengthscale: 6.926   noise: 0.033\n",
      "Iter 111/300 - Loss: 3.610   lengthscale: 7.214   noise: 0.027\n",
      "Iter 121/300 - Loss: 3.596   lengthscale: 7.480   noise: 0.023\n",
      "Iter 131/300 - Loss: 3.586   lengthscale: 7.729   noise: 0.019\n",
      "Iter 141/300 - Loss: 3.577   lengthscale: 7.964   noise: 0.017\n",
      "Iter 151/300 - Loss: 3.565   lengthscale: 8.187   noise: 0.015\n",
      "Iter 161/300 - Loss: 3.565   lengthscale: 8.400   noise: 0.014\n",
      "Iter 171/300 - Loss: 3.555   lengthscale: 8.604   noise: 0.012\n",
      "Iter 181/300 - Loss: 3.556   lengthscale: 8.799   noise: 0.011\n",
      "Iter 191/300 - Loss: 3.547   lengthscale: 8.988   noise: 0.010\n",
      "Iter 201/300 - Loss: 3.541   lengthscale: 9.170   noise: 0.009\n",
      "Iter 211/300 - Loss: 3.541   lengthscale: 9.346   noise: 0.009\n",
      "Iter 221/300 - Loss: 3.539   lengthscale: 9.518   noise: 0.008\n",
      "Iter 231/300 - Loss: 3.533   lengthscale: 9.685   noise: 0.007\n",
      "Iter 241/300 - Loss: 3.533   lengthscale: 9.847   noise: 0.007\n",
      "Iter 251/300 - Loss: 3.528   lengthscale: 10.006   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.531   lengthscale: 10.161   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.522   lengthscale: 10.312   noise: 0.006\n",
      "Iter 281/300 - Loss: 3.524   lengthscale: 10.460   noise: 0.005\n",
      "Iter 291/300 - Loss: 3.522   lengthscale: 10.605   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1523    0]\n",
      " [   0 1523]]\n",
      "accuracy: 0.9633, precision: 0.8421, recall: 0.5714, specificity: 0.9921, cm: [[378   3]\n",
      " [ 12  16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 inhibition moe ADASYN\n",
      "trainX:torch.Size([3037, 306]), train y: torch.Size([3037]), testX: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.922   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.587   lengthscale: 1.320   noise: 1.264\n",
      "Iter 21/300 - Loss: 4.878   lengthscale: 2.175   noise: 1.605\n",
      "Iter 31/300 - Loss: 4.431   lengthscale: 3.176   noise: 1.433\n",
      "Iter 41/300 - Loss: 4.142   lengthscale: 4.125   noise: 0.952\n",
      "Iter 51/300 - Loss: 3.967   lengthscale: 4.886   noise: 0.496\n",
      "Iter 61/300 - Loss: 3.835   lengthscale: 5.476   noise: 0.224\n",
      "Iter 71/300 - Loss: 3.758   lengthscale: 5.954   noise: 0.110\n",
      "Iter 81/300 - Loss: 3.709   lengthscale: 6.361   noise: 0.065\n",
      "Iter 91/300 - Loss: 3.683   lengthscale: 6.720   noise: 0.045\n",
      "Iter 101/300 - Loss: 3.661   lengthscale: 7.045   noise: 0.034\n",
      "Iter 111/300 - Loss: 3.639   lengthscale: 7.342   noise: 0.028\n",
      "Iter 121/300 - Loss: 3.631   lengthscale: 7.615   noise: 0.023\n",
      "Iter 131/300 - Loss: 3.618   lengthscale: 7.871   noise: 0.020\n",
      "Iter 141/300 - Loss: 3.607   lengthscale: 8.111   noise: 0.018\n",
      "Iter 151/300 - Loss: 3.602   lengthscale: 8.339   noise: 0.016\n",
      "Iter 161/300 - Loss: 3.597   lengthscale: 8.557   noise: 0.014\n",
      "Iter 171/300 - Loss: 3.594   lengthscale: 8.765   noise: 0.013\n",
      "Iter 181/300 - Loss: 3.583   lengthscale: 8.966   noise: 0.011\n",
      "Iter 191/300 - Loss: 3.581   lengthscale: 9.159   noise: 0.010\n",
      "Iter 201/300 - Loss: 3.578   lengthscale: 9.346   noise: 0.010\n",
      "Iter 211/300 - Loss: 3.574   lengthscale: 9.526   noise: 0.009\n",
      "Iter 221/300 - Loss: 3.569   lengthscale: 9.702   noise: 0.008\n",
      "Iter 231/300 - Loss: 3.567   lengthscale: 9.872   noise: 0.008\n",
      "Iter 241/300 - Loss: 3.570   lengthscale: 10.039   noise: 0.007\n",
      "Iter 251/300 - Loss: 3.557   lengthscale: 10.200   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.558   lengthscale: 10.359   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.556   lengthscale: 10.513   noise: 0.006\n",
      "Iter 281/300 - Loss: 3.556   lengthscale: 10.665   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.547   lengthscale: 10.813   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1523    0]\n",
      " [   0 1514]]\n",
      "accuracy: 0.9584, precision: 0.7619, recall: 0.5714, specificity: 0.9869, cm: [[376   5]\n",
      " [ 12  16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 inhibition mfp scaled\n",
      "trainX:torch.Size([1635, 2048]), train y: torch.Size([1635]), testX: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.078   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.885   lengthscale: 1.296   noise: 0.802\n",
      "Iter 21/300 - Loss: 3.573   lengthscale: 2.100   noise: 0.936\n",
      "Iter 31/300 - Loss: 3.392   lengthscale: 2.755   noise: 0.947\n",
      "Iter 41/300 - Loss: 3.339   lengthscale: 3.189   noise: 0.880\n",
      "Iter 51/300 - Loss: 3.301   lengthscale: 3.472   noise: 0.776\n",
      "Iter 61/300 - Loss: 3.285   lengthscale: 3.669   noise: 0.661\n",
      "Iter 71/300 - Loss: 3.275   lengthscale: 3.816   noise: 0.551\n",
      "Iter 81/300 - Loss: 3.261   lengthscale: 3.935   noise: 0.453\n",
      "Iter 91/300 - Loss: 3.248   lengthscale: 4.039   noise: 0.372\n",
      "Iter 101/300 - Loss: 3.240   lengthscale: 4.133   noise: 0.308\n",
      "Iter 111/300 - Loss: 3.233   lengthscale: 4.219   noise: 0.258\n",
      "Iter 121/300 - Loss: 3.228   lengthscale: 4.300   noise: 0.220\n",
      "Iter 131/300 - Loss: 3.232   lengthscale: 4.377   noise: 0.190\n",
      "Iter 141/300 - Loss: 3.224   lengthscale: 4.450   noise: 0.166\n",
      "Iter 151/300 - Loss: 3.219   lengthscale: 4.519   noise: 0.147\n",
      "Iter 161/300 - Loss: 3.214   lengthscale: 4.585   noise: 0.132\n",
      "Iter 171/300 - Loss: 3.211   lengthscale: 4.647   noise: 0.119\n",
      "Iter 181/300 - Loss: 3.212   lengthscale: 4.707   noise: 0.108\n",
      "Iter 191/300 - Loss: 3.209   lengthscale: 4.764   noise: 0.099\n",
      "Iter 201/300 - Loss: 3.205   lengthscale: 4.819   noise: 0.091\n",
      "Iter 211/300 - Loss: 3.203   lengthscale: 4.873   noise: 0.084\n",
      "Iter 221/300 - Loss: 3.199   lengthscale: 4.926   noise: 0.077\n",
      "Iter 231/300 - Loss: 3.203   lengthscale: 4.976   noise: 0.072\n",
      "Iter 241/300 - Loss: 3.200   lengthscale: 5.025   noise: 0.067\n",
      "Iter 251/300 - Loss: 3.199   lengthscale: 5.072   noise: 0.063\n",
      "Iter 261/300 - Loss: 3.199   lengthscale: 5.118   noise: 0.059\n",
      "Iter 271/300 - Loss: 3.197   lengthscale: 5.162   noise: 0.056\n",
      "Iter 281/300 - Loss: 3.201   lengthscale: 5.206   noise: 0.052\n",
      "Iter 291/300 - Loss: 3.200   lengthscale: 5.249   noise: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9339, precision: 1.0000, recall: 0.0357, specificity: 1.0000, cm: [[1523    0]\n",
      " [ 108    4]]\n",
      "accuracy: 0.9340, precision: 1.0000, recall: 0.0357, specificity: 1.0000, cm: [[381   0]\n",
      " [ 27   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 inhibition mfp UNDER\n",
      "trainX:torch.Size([224, 2048]), train y: torch.Size([224]), testX: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.892   lengthscale: 1.291   noise: 1.296\n",
      "Iter 21/300 - Loss: 5.388   lengthscale: 2.134   noise: 1.978\n",
      "Iter 31/300 - Loss: 5.277   lengthscale: 2.763   noise: 2.611\n",
      "Iter 41/300 - Loss: 5.244   lengthscale: 2.972   noise: 3.126\n",
      "Iter 51/300 - Loss: 5.231   lengthscale: 2.962   noise: 3.502\n",
      "Iter 61/300 - Loss: 5.225   lengthscale: 2.863   noise: 3.759\n",
      "Iter 71/300 - Loss: 5.222   lengthscale: 2.732   noise: 3.928\n",
      "Iter 81/300 - Loss: 5.220   lengthscale: 2.587   noise: 4.035\n",
      "Iter 91/300 - Loss: 5.218   lengthscale: 2.434   noise: 4.100\n",
      "Iter 101/300 - Loss: 5.215   lengthscale: 2.271   noise: 4.138\n",
      "Iter 111/300 - Loss: 5.213   lengthscale: 2.098   noise: 4.158\n",
      "Iter 121/300 - Loss: 5.211   lengthscale: 1.915   noise: 4.167\n",
      "Iter 131/300 - Loss: 5.208   lengthscale: 1.727   noise: 4.170\n",
      "Iter 141/300 - Loss: 5.206   lengthscale: 1.545   noise: 4.170\n",
      "Iter 151/300 - Loss: 5.205   lengthscale: 1.382   noise: 4.172\n",
      "Iter 161/300 - Loss: 5.204   lengthscale: 1.245   noise: 4.175\n",
      "Iter 171/300 - Loss: 5.203   lengthscale: 1.137   noise: 4.181\n",
      "Iter 181/300 - Loss: 5.203   lengthscale: 1.053   noise: 4.186\n",
      "Iter 191/300 - Loss: 5.203   lengthscale: 0.989   noise: 4.191\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.938   noise: 4.194\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.897   noise: 4.195\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.863   noise: 4.196\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.834   noise: 4.196\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.809   noise: 4.197\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.787   noise: 4.198\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.768   noise: 4.199\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.750   noise: 4.200\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.734   noise: 4.201\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.719   noise: 4.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[112   0]\n",
      " [  0 112]]\n",
      "accuracy: 0.3007, precision: 0.0757, recall: 0.8214, specificity: 0.2625, cm: [[100 281]\n",
      " [  5  23]]\n",
      "\n",
      "NEK2 inhibition mfp SMOTE\n",
      "trainX:torch.Size([3046, 2048]), train y: torch.Size([3046]), testX: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.187   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.573   lengthscale: 1.302   noise: 0.774\n",
      "Iter 21/300 - Loss: 3.825   lengthscale: 2.023   noise: 0.597\n",
      "Iter 31/300 - Loss: 3.595   lengthscale: 2.588   noise: 0.302\n",
      "Iter 41/300 - Loss: 3.484   lengthscale: 2.959   noise: 0.133\n",
      "Iter 51/300 - Loss: 3.427   lengthscale: 3.216   noise: 0.065\n",
      "Iter 61/300 - Loss: 3.392   lengthscale: 3.414   noise: 0.039\n",
      "Iter 71/300 - Loss: 3.376   lengthscale: 3.583   noise: 0.028\n",
      "Iter 81/300 - Loss: 3.368   lengthscale: 3.736   noise: 0.021\n",
      "Iter 91/300 - Loss: 3.361   lengthscale: 3.877   noise: 0.017\n",
      "Iter 101/300 - Loss: 3.358   lengthscale: 4.011   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.347   lengthscale: 4.138   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.343   lengthscale: 4.260   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.329   lengthscale: 4.378   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.327   lengthscale: 4.490   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.321   lengthscale: 4.599   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.325   lengthscale: 4.703   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.320   lengthscale: 4.805   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.316   lengthscale: 4.903   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.316   lengthscale: 4.998   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.306   lengthscale: 5.092   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.310   lengthscale: 5.182   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.310   lengthscale: 5.270   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.301   lengthscale: 5.356   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.300   lengthscale: 5.441   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.295   lengthscale: 5.523   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.301   lengthscale: 5.604   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.293   lengthscale: 5.684   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.299   lengthscale: 5.763   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.296   lengthscale: 5.840   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9961, precision: 0.9974, recall: 0.9947, specificity: 0.9974, cm: [[1519    4]\n",
      " [   8 1515]]\n",
      "accuracy: 0.9633, precision: 0.8824, recall: 0.5357, specificity: 0.9948, cm: [[379   2]\n",
      " [ 13  15]]\n",
      "\n",
      "NEK2 inhibition mfp ADASYN\n",
      "trainX:torch.Size([3027, 2048]), train y: torch.Size([3027]), testX: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.062   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.545   lengthscale: 1.297   noise: 0.772\n",
      "Iter 21/300 - Loss: 3.816   lengthscale: 2.002   noise: 0.585\n",
      "Iter 31/300 - Loss: 3.586   lengthscale: 2.558   noise: 0.293\n",
      "Iter 41/300 - Loss: 3.473   lengthscale: 2.926   noise: 0.129\n",
      "Iter 51/300 - Loss: 3.420   lengthscale: 3.182   noise: 0.064\n",
      "Iter 61/300 - Loss: 3.385   lengthscale: 3.379   noise: 0.039\n",
      "Iter 71/300 - Loss: 3.367   lengthscale: 3.545   noise: 0.028\n",
      "Iter 81/300 - Loss: 3.366   lengthscale: 3.693   noise: 0.022\n",
      "Iter 91/300 - Loss: 3.351   lengthscale: 3.830   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.343   lengthscale: 3.958   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.341   lengthscale: 4.080   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.336   lengthscale: 4.196   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.332   lengthscale: 4.309   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.325   lengthscale: 4.417   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.318   lengthscale: 4.522   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.324   lengthscale: 4.623   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.315   lengthscale: 4.721   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.311   lengthscale: 4.817   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.315   lengthscale: 4.909   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.307   lengthscale: 4.998   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.305   lengthscale: 5.086   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.310   lengthscale: 5.171   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.297   lengthscale: 5.255   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.304   lengthscale: 5.336   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.296   lengthscale: 5.416   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.300   lengthscale: 5.495   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.301   lengthscale: 5.572   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.304   lengthscale: 5.648   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.299   lengthscale: 5.722   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9967, precision: 0.9973, recall: 0.9960, specificity: 0.9974, cm: [[1519    4]\n",
      " [   6 1498]]\n",
      "accuracy: 0.9633, precision: 0.8824, recall: 0.5357, specificity: 0.9948, cm: [[379   2]\n",
      " [ 13  15]]\n",
      "\n",
      "NEK3\n",
      "NEK3 binding moe scaled\n",
      "trainX:torch.Size([1122, 306]), train y: torch.Size([1122]), testX: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.518   lengthscale: 1.062   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.522   lengthscale: 1.602   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.856   lengthscale: 2.323   noise: 1.317\n",
      "Iter 41/300 - Loss: 3.515   lengthscale: 3.159   noise: 1.432\n",
      "Iter 51/300 - Loss: 3.408   lengthscale: 3.899   noise: 1.435\n",
      "Iter 61/300 - Loss: 3.374   lengthscale: 4.490   noise: 1.377\n",
      "Iter 71/300 - Loss: 3.356   lengthscale: 5.185   noise: 1.291\n",
      "Iter 81/300 - Loss: 3.341   lengthscale: 5.912   noise: 1.192\n",
      "Iter 91/300 - Loss: 3.319   lengthscale: 6.673   noise: 1.089\n",
      "Iter 101/300 - Loss: 3.311   lengthscale: 7.434   noise: 0.987\n",
      "Iter 111/300 - Loss: 3.296   lengthscale: 8.286   noise: 0.894\n",
      "Iter 121/300 - Loss: 3.302   lengthscale: 9.098   noise: 0.809\n",
      "Iter 131/300 - Loss: 3.285   lengthscale: 9.795   noise: 0.734\n",
      "Iter 141/300 - Loss: 3.279   lengthscale: 10.398   noise: 0.672\n",
      "Iter 151/300 - Loss: 3.281   lengthscale: 10.909   noise: 0.621\n",
      "Iter 161/300 - Loss: 3.272   lengthscale: 11.313   noise: 0.580\n",
      "Iter 171/300 - Loss: 3.266   lengthscale: 11.733   noise: 0.548\n",
      "Iter 181/300 - Loss: 3.263   lengthscale: 12.115   noise: 0.523\n",
      "Iter 191/300 - Loss: 3.265   lengthscale: 12.470   noise: 0.503\n",
      "Iter 201/300 - Loss: 3.265   lengthscale: 12.787   noise: 0.485\n",
      "Iter 211/300 - Loss: 3.254   lengthscale: 13.085   noise: 0.470\n",
      "Iter 221/300 - Loss: 3.261   lengthscale: 13.353   noise: 0.456\n",
      "Iter 231/300 - Loss: 3.254   lengthscale: 13.607   noise: 0.444\n",
      "Iter 241/300 - Loss: 3.265   lengthscale: 13.884   noise: 0.433\n",
      "Iter 251/300 - Loss: 3.263   lengthscale: 14.134   noise: 0.424\n",
      "Iter 261/300 - Loss: 3.258   lengthscale: 14.355   noise: 0.414\n",
      "Iter 271/300 - Loss: 3.258   lengthscale: 14.547   noise: 0.404\n",
      "Iter 281/300 - Loss: 3.251   lengthscale: 14.740   noise: 0.396\n",
      "Iter 291/300 - Loss: 3.250   lengthscale: 14.896   noise: 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9430, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [  64    0]]\n",
      "accuracy: 0.9397, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[265   0]\n",
      " [ 17   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK3 binding moe UNDER\n",
      "trainX:torch.Size([128, 306]), train y: torch.Size([128]), testX: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.259   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.439   lengthscale: 2.052   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.263   lengthscale: 3.154   noise: 2.573\n",
      "Iter 41/300 - Loss: 5.206   lengthscale: 4.437   noise: 3.009\n",
      "Iter 51/300 - Loss: 5.188   lengthscale: 5.570   noise: 3.302\n",
      "Iter 61/300 - Loss: 5.182   lengthscale: 6.404   noise: 3.483\n",
      "Iter 71/300 - Loss: 5.180   lengthscale: 6.993   noise: 3.582\n",
      "Iter 81/300 - Loss: 5.178   lengthscale: 7.424   noise: 3.625\n",
      "Iter 91/300 - Loss: 5.177   lengthscale: 7.759   noise: 3.630\n",
      "Iter 101/300 - Loss: 5.177   lengthscale: 8.032   noise: 3.611\n",
      "Iter 111/300 - Loss: 5.176   lengthscale: 8.263   noise: 3.576\n",
      "Iter 121/300 - Loss: 5.176   lengthscale: 8.462   noise: 3.531\n",
      "Iter 131/300 - Loss: 5.175   lengthscale: 8.634   noise: 3.478\n",
      "Iter 141/300 - Loss: 5.175   lengthscale: 8.783   noise: 3.421\n",
      "Iter 151/300 - Loss: 5.174   lengthscale: 8.913   noise: 3.360\n",
      "Iter 161/300 - Loss: 5.174   lengthscale: 9.026   noise: 3.296\n",
      "Iter 171/300 - Loss: 5.173   lengthscale: 9.125   noise: 3.229\n",
      "Iter 181/300 - Loss: 5.173   lengthscale: 9.212   noise: 3.159\n",
      "Iter 191/300 - Loss: 5.172   lengthscale: 9.288   noise: 3.087\n",
      "Iter 201/300 - Loss: 5.171   lengthscale: 9.356   noise: 3.013\n",
      "Iter 211/300 - Loss: 5.171   lengthscale: 9.416   noise: 2.937\n",
      "Iter 221/300 - Loss: 5.170   lengthscale: 9.470   noise: 2.858\n",
      "Iter 231/300 - Loss: 5.170   lengthscale: 9.517   noise: 2.778\n",
      "Iter 241/300 - Loss: 5.169   lengthscale: 9.560   noise: 2.697\n",
      "Iter 251/300 - Loss: 5.169   lengthscale: 9.597   noise: 2.614\n",
      "Iter 261/300 - Loss: 5.168   lengthscale: 9.631   noise: 2.530\n",
      "Iter 271/300 - Loss: 5.168   lengthscale: 9.662   noise: 2.445\n",
      "Iter 281/300 - Loss: 5.167   lengthscale: 9.689   noise: 2.360\n",
      "Iter 291/300 - Loss: 5.167   lengthscale: 9.713   noise: 2.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[64  0]\n",
      " [ 0 64]]\n",
      "accuracy: 0.6064, precision: 0.1017, recall: 0.7059, specificity: 0.6000, cm: [[159 106]\n",
      " [  5  12]]\n",
      "\n",
      "NEK3 binding moe SMOTE\n",
      "trainX:torch.Size([2116, 306]), train y: torch.Size([2116]), testX: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.937   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.616   lengthscale: 1.319   noise: 1.270\n",
      "Iter 21/300 - Loss: 4.951   lengthscale: 2.186   noise: 1.660\n",
      "Iter 31/300 - Loss: 4.580   lengthscale: 3.182   noise: 1.575\n",
      "Iter 41/300 - Loss: 4.318   lengthscale: 4.161   noise: 1.138\n",
      "Iter 51/300 - Loss: 4.118   lengthscale: 4.998   noise: 0.637\n",
      "Iter 61/300 - Loss: 3.983   lengthscale: 5.667   noise: 0.295\n",
      "Iter 71/300 - Loss: 3.906   lengthscale: 6.207   noise: 0.138\n",
      "Iter 81/300 - Loss: 3.864   lengthscale: 6.660   noise: 0.077\n",
      "Iter 91/300 - Loss: 3.828   lengthscale: 7.052   noise: 0.052\n",
      "Iter 101/300 - Loss: 3.820   lengthscale: 7.400   noise: 0.039\n",
      "Iter 111/300 - Loss: 3.802   lengthscale: 7.713   noise: 0.031\n",
      "Iter 121/300 - Loss: 3.779   lengthscale: 7.999   noise: 0.026\n",
      "Iter 131/300 - Loss: 3.768   lengthscale: 8.264   noise: 0.022\n",
      "Iter 141/300 - Loss: 3.759   lengthscale: 8.511   noise: 0.019\n",
      "Iter 151/300 - Loss: 3.762   lengthscale: 8.744   noise: 0.017\n",
      "Iter 161/300 - Loss: 3.755   lengthscale: 8.965   noise: 0.015\n",
      "Iter 171/300 - Loss: 3.747   lengthscale: 9.177   noise: 0.014\n",
      "Iter 181/300 - Loss: 3.746   lengthscale: 9.380   noise: 0.013\n",
      "Iter 191/300 - Loss: 3.745   lengthscale: 9.573   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.732   lengthscale: 9.760   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.724   lengthscale: 9.941   noise: 0.010\n",
      "Iter 221/300 - Loss: 3.723   lengthscale: 10.116   noise: 0.009\n",
      "Iter 231/300 - Loss: 3.726   lengthscale: 10.285   noise: 0.008\n",
      "Iter 241/300 - Loss: 3.719   lengthscale: 10.450   noise: 0.008\n",
      "Iter 251/300 - Loss: 3.719   lengthscale: 10.611   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.725   lengthscale: 10.768   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.714   lengthscale: 10.920   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.712   lengthscale: 11.069   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.700   lengthscale: 11.215   noise: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [   0 1058]]\n",
      "accuracy: 0.9255, precision: 0.2500, recall: 0.1176, specificity: 0.9774, cm: [[259   6]\n",
      " [ 15   2]]\n",
      "\n",
      "NEK3 binding moe ADASYN\n",
      "trainX:torch.Size([2113, 306]), train y: torch.Size([2113]), testX: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.942   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.620   lengthscale: 1.321   noise: 1.270\n",
      "Iter 21/300 - Loss: 4.958   lengthscale: 2.186   noise: 1.661\n",
      "Iter 31/300 - Loss: 4.592   lengthscale: 3.181   noise: 1.578\n",
      "Iter 41/300 - Loss: 4.318   lengthscale: 4.160   noise: 1.144\n",
      "Iter 51/300 - Loss: 4.129   lengthscale: 5.001   noise: 0.641\n",
      "Iter 61/300 - Loss: 4.001   lengthscale: 5.674   noise: 0.297\n",
      "Iter 71/300 - Loss: 3.920   lengthscale: 6.219   noise: 0.139\n",
      "Iter 81/300 - Loss: 3.875   lengthscale: 6.677   noise: 0.078\n",
      "Iter 91/300 - Loss: 3.831   lengthscale: 7.074   noise: 0.052\n",
      "Iter 101/300 - Loss: 3.812   lengthscale: 7.427   noise: 0.039\n",
      "Iter 111/300 - Loss: 3.804   lengthscale: 7.743   noise: 0.031\n",
      "Iter 121/300 - Loss: 3.789   lengthscale: 8.031   noise: 0.026\n",
      "Iter 131/300 - Loss: 3.783   lengthscale: 8.297   noise: 0.022\n",
      "Iter 141/300 - Loss: 3.773   lengthscale: 8.546   noise: 0.020\n",
      "Iter 151/300 - Loss: 3.767   lengthscale: 8.782   noise: 0.017\n",
      "Iter 161/300 - Loss: 3.766   lengthscale: 9.006   noise: 0.015\n",
      "Iter 171/300 - Loss: 3.752   lengthscale: 9.219   noise: 0.014\n",
      "Iter 181/300 - Loss: 3.744   lengthscale: 9.423   noise: 0.013\n",
      "Iter 191/300 - Loss: 3.743   lengthscale: 9.619   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.751   lengthscale: 9.808   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.735   lengthscale: 9.990   noise: 0.010\n",
      "Iter 221/300 - Loss: 3.732   lengthscale: 10.165   noise: 0.009\n",
      "Iter 231/300 - Loss: 3.733   lengthscale: 10.337   noise: 0.008\n",
      "Iter 241/300 - Loss: 3.727   lengthscale: 10.504   noise: 0.008\n",
      "Iter 251/300 - Loss: 3.732   lengthscale: 10.667   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.721   lengthscale: 10.824   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.719   lengthscale: 10.979   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.725   lengthscale: 11.129   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.716   lengthscale: 11.276   noise: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [   0 1055]]\n",
      "accuracy: 0.9184, precision: 0.2000, recall: 0.1176, specificity: 0.9698, cm: [[257   8]\n",
      " [ 15   2]]\n",
      "\n",
      "NEK3 binding mfp scaled\n",
      "trainX:torch.Size([1122, 2048]), train y: torch.Size([1122]), testX: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.086   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.163   lengthscale: 1.266   noise: 0.806\n",
      "Iter 21/300 - Loss: 3.675   lengthscale: 2.041   noise: 0.988\n",
      "Iter 31/300 - Loss: 3.417   lengthscale: 2.777   noise: 1.054\n",
      "Iter 41/300 - Loss: 3.348   lengthscale: 3.288   noise: 1.036\n",
      "Iter 51/300 - Loss: 3.324   lengthscale: 3.628   noise: 0.974\n",
      "Iter 61/300 - Loss: 3.310   lengthscale: 3.862   noise: 0.894\n",
      "Iter 71/300 - Loss: 3.296   lengthscale: 4.032   noise: 0.808\n",
      "Iter 81/300 - Loss: 3.287   lengthscale: 4.172   noise: 0.725\n",
      "Iter 91/300 - Loss: 3.278   lengthscale: 4.288   noise: 0.649\n",
      "Iter 101/300 - Loss: 3.273   lengthscale: 4.388   noise: 0.584\n",
      "Iter 111/300 - Loss: 3.272   lengthscale: 4.480   noise: 0.529\n",
      "Iter 121/300 - Loss: 3.261   lengthscale: 4.558   noise: 0.483\n",
      "Iter 131/300 - Loss: 3.257   lengthscale: 4.630   noise: 0.444\n",
      "Iter 141/300 - Loss: 3.261   lengthscale: 4.700   noise: 0.412\n",
      "Iter 151/300 - Loss: 3.250   lengthscale: 4.766   noise: 0.385\n",
      "Iter 161/300 - Loss: 3.253   lengthscale: 4.829   noise: 0.363\n",
      "Iter 171/300 - Loss: 3.250   lengthscale: 4.887   noise: 0.343\n",
      "Iter 181/300 - Loss: 3.244   lengthscale: 4.942   noise: 0.326\n",
      "Iter 191/300 - Loss: 3.250   lengthscale: 4.993   noise: 0.311\n",
      "Iter 201/300 - Loss: 3.243   lengthscale: 5.044   noise: 0.297\n",
      "Iter 211/300 - Loss: 3.243   lengthscale: 5.090   noise: 0.285\n",
      "Iter 221/300 - Loss: 3.246   lengthscale: 5.131   noise: 0.273\n",
      "Iter 231/300 - Loss: 3.240   lengthscale: 5.168   noise: 0.262\n",
      "Iter 241/300 - Loss: 3.239   lengthscale: 5.204   noise: 0.252\n",
      "Iter 251/300 - Loss: 3.237   lengthscale: 5.241   noise: 0.243\n",
      "Iter 261/300 - Loss: 3.242   lengthscale: 5.275   noise: 0.235\n",
      "Iter 271/300 - Loss: 3.242   lengthscale: 5.305   noise: 0.227\n",
      "Iter 281/300 - Loss: 3.236   lengthscale: 5.337   noise: 0.219\n",
      "Iter 291/300 - Loss: 3.233   lengthscale: 5.366   noise: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9430, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [  64    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9397, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[265   0]\n",
      " [ 17   0]]\n",
      "\n",
      "NEK3 binding mfp UNDER\n",
      "trainX:torch.Size([128, 2048]), train y: torch.Size([128]), testX: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.914   lengthscale: 1.285   noise: 1.296\n",
      "Iter 21/300 - Loss: 5.395   lengthscale: 2.143   noise: 1.976\n",
      "Iter 31/300 - Loss: 5.261   lengthscale: 2.951   noise: 2.579\n",
      "Iter 41/300 - Loss: 5.226   lengthscale: 3.325   noise: 3.053\n",
      "Iter 51/300 - Loss: 5.213   lengthscale: 3.419   noise: 3.388\n",
      "Iter 61/300 - Loss: 5.209   lengthscale: 3.394   noise: 3.608\n",
      "Iter 71/300 - Loss: 5.207   lengthscale: 3.328   noise: 3.745\n",
      "Iter 81/300 - Loss: 5.206   lengthscale: 3.248   noise: 3.824\n",
      "Iter 91/300 - Loss: 5.205   lengthscale: 3.163   noise: 3.867\n",
      "Iter 101/300 - Loss: 5.205   lengthscale: 3.074   noise: 3.886\n",
      "Iter 111/300 - Loss: 5.204   lengthscale: 2.980   noise: 3.891\n",
      "Iter 121/300 - Loss: 5.204   lengthscale: 2.879   noise: 3.887\n",
      "Iter 131/300 - Loss: 5.203   lengthscale: 2.772   noise: 3.879\n",
      "Iter 141/300 - Loss: 5.203   lengthscale: 2.659   noise: 3.869\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 2.542   noise: 3.858\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 2.424   noise: 3.847\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 2.306   noise: 3.837\n",
      "Iter 181/300 - Loss: 5.201   lengthscale: 2.194   noise: 3.827\n",
      "Iter 191/300 - Loss: 5.201   lengthscale: 2.089   noise: 3.818\n",
      "Iter 201/300 - Loss: 5.201   lengthscale: 1.994   noise: 3.810\n",
      "Iter 211/300 - Loss: 5.201   lengthscale: 1.910   noise: 3.801\n",
      "Iter 221/300 - Loss: 5.201   lengthscale: 1.839   noise: 3.794\n",
      "Iter 231/300 - Loss: 5.201   lengthscale: 1.780   noise: 3.786\n",
      "Iter 241/300 - Loss: 5.200   lengthscale: 1.732   noise: 3.779\n",
      "Iter 251/300 - Loss: 5.200   lengthscale: 1.694   noise: 3.772\n",
      "Iter 261/300 - Loss: 5.200   lengthscale: 1.666   noise: 3.766\n",
      "Iter 271/300 - Loss: 5.200   lengthscale: 1.644   noise: 3.760\n",
      "Iter 281/300 - Loss: 5.200   lengthscale: 1.629   noise: 3.754\n",
      "Iter 291/300 - Loss: 5.200   lengthscale: 1.617   noise: 3.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[64  0]\n",
      " [ 0 64]]\n",
      "accuracy: 0.4929, precision: 0.0909, recall: 0.8235, specificity: 0.4717, cm: [[125 140]\n",
      " [  3  14]]\n",
      "\n",
      "NEK3 binding mfp SMOTE\n",
      "trainX:torch.Size([2116, 2048]), train y: torch.Size([2116]), testX: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.221   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.724   lengthscale: 1.299   noise: 0.790\n",
      "Iter 21/300 - Loss: 3.990   lengthscale: 2.019   noise: 0.717\n",
      "Iter 31/300 - Loss: 3.719   lengthscale: 2.634   noise: 0.403\n",
      "Iter 41/300 - Loss: 3.583   lengthscale: 3.043   noise: 0.179\n",
      "Iter 51/300 - Loss: 3.521   lengthscale: 3.314   noise: 0.081\n",
      "Iter 61/300 - Loss: 3.490   lengthscale: 3.513   noise: 0.045\n",
      "Iter 71/300 - Loss: 3.459   lengthscale: 3.673   noise: 0.030\n",
      "Iter 81/300 - Loss: 3.446   lengthscale: 3.814   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.444   lengthscale: 3.941   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.438   lengthscale: 4.060   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.425   lengthscale: 4.172   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.415   lengthscale: 4.279   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.413   lengthscale: 4.381   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.406   lengthscale: 4.478   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.410   lengthscale: 4.572   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.401   lengthscale: 4.664   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.403   lengthscale: 4.752   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.404   lengthscale: 4.838   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.402   lengthscale: 4.922   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.398   lengthscale: 5.003   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.403   lengthscale: 5.082   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.395   lengthscale: 5.159   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.395   lengthscale: 5.233   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.391   lengthscale: 5.306   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.393   lengthscale: 5.377   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.385   lengthscale: 5.446   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.383   lengthscale: 5.514   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.386   lengthscale: 5.580   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.381   lengthscale: 5.644   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9981, precision: 1.0000, recall: 0.9962, specificity: 1.0000, cm: [[1058    0]\n",
      " [   4 1054]]\n",
      "accuracy: 0.9574, precision: 0.8571, recall: 0.3529, specificity: 0.9962, cm: [[264   1]\n",
      " [ 11   6]]\n",
      "\n",
      "NEK3 binding mfp ADASYN\n",
      "trainX:torch.Size([2130, 2048]), train y: torch.Size([2130]), testX: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.194   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.720   lengthscale: 1.297   noise: 0.788\n",
      "Iter 21/300 - Loss: 3.990   lengthscale: 2.006   noise: 0.709\n",
      "Iter 31/300 - Loss: 3.712   lengthscale: 2.613   noise: 0.394\n",
      "Iter 41/300 - Loss: 3.581   lengthscale: 3.016   noise: 0.173\n",
      "Iter 51/300 - Loss: 3.515   lengthscale: 3.283   noise: 0.079\n",
      "Iter 61/300 - Loss: 3.474   lengthscale: 3.479   noise: 0.044\n",
      "Iter 71/300 - Loss: 3.460   lengthscale: 3.636   noise: 0.030\n",
      "Iter 81/300 - Loss: 3.443   lengthscale: 3.774   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.429   lengthscale: 3.900   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.431   lengthscale: 4.016   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.423   lengthscale: 4.126   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.421   lengthscale: 4.229   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.409   lengthscale: 4.329   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.407   lengthscale: 4.425   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.412   lengthscale: 4.518   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.411   lengthscale: 4.608   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.399   lengthscale: 4.695   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.406   lengthscale: 4.779   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.399   lengthscale: 4.861   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.396   lengthscale: 4.941   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.399   lengthscale: 5.018   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.389   lengthscale: 5.094   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.396   lengthscale: 5.166   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.391   lengthscale: 5.238   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.387   lengthscale: 5.307   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.393   lengthscale: 5.375   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.389   lengthscale: 5.442   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.384   lengthscale: 5.507   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.389   lengthscale: 5.572   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9981, precision: 1.0000, recall: 0.9963, specificity: 1.0000, cm: [[1058    0]\n",
      " [   4 1068]]\n",
      "accuracy: 0.9539, precision: 0.8333, recall: 0.2941, specificity: 0.9962, cm: [[264   1]\n",
      " [ 12   5]]\n",
      "\n",
      "NEK5\n",
      "NEK5 binding moe scaled\n",
      "trainX:torch.Size([989, 306]), train y: torch.Size([989]), testX: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.561   lengthscale: 1.284   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.609   lengthscale: 2.118   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.972   lengthscale: 3.221   noise: 1.317\n",
      "Iter 41/300 - Loss: 3.640   lengthscale: 4.467   noise: 1.437\n",
      "Iter 51/300 - Loss: 3.546   lengthscale: 5.522   noise: 1.445\n",
      "Iter 61/300 - Loss: 3.502   lengthscale: 6.294   noise: 1.391\n",
      "Iter 71/300 - Loss: 3.490   lengthscale: 6.858   noise: 1.307\n",
      "Iter 81/300 - Loss: 3.471   lengthscale: 7.301   noise: 1.210\n",
      "Iter 91/300 - Loss: 3.455   lengthscale: 7.669   noise: 1.109\n",
      "Iter 101/300 - Loss: 3.453   lengthscale: 7.995   noise: 1.010\n",
      "Iter 111/300 - Loss: 3.439   lengthscale: 8.280   noise: 0.916\n",
      "Iter 121/300 - Loss: 3.430   lengthscale: 8.527   noise: 0.830\n",
      "Iter 131/300 - Loss: 3.430   lengthscale: 8.749   noise: 0.755\n",
      "Iter 141/300 - Loss: 3.423   lengthscale: 8.955   noise: 0.690\n",
      "Iter 151/300 - Loss: 3.429   lengthscale: 9.155   noise: 0.635\n",
      "Iter 161/300 - Loss: 3.413   lengthscale: 9.331   noise: 0.589\n",
      "Iter 171/300 - Loss: 3.412   lengthscale: 9.490   noise: 0.551\n",
      "Iter 181/300 - Loss: 3.411   lengthscale: 9.634   noise: 0.518\n",
      "Iter 191/300 - Loss: 3.411   lengthscale: 9.774   noise: 0.489\n",
      "Iter 201/300 - Loss: 3.405   lengthscale: 9.902   noise: 0.463\n",
      "Iter 211/300 - Loss: 3.405   lengthscale: 10.013   noise: 0.440\n",
      "Iter 221/300 - Loss: 3.407   lengthscale: 10.118   noise: 0.419\n",
      "Iter 231/300 - Loss: 3.400   lengthscale: 10.218   noise: 0.401\n",
      "Iter 241/300 - Loss: 3.399   lengthscale: 10.320   noise: 0.384\n",
      "Iter 251/300 - Loss: 3.401   lengthscale: 10.423   noise: 0.368\n",
      "Iter 261/300 - Loss: 3.401   lengthscale: 10.518   noise: 0.351\n",
      "Iter 271/300 - Loss: 3.402   lengthscale: 10.600   noise: 0.335\n",
      "Iter 281/300 - Loss: 3.404   lengthscale: 10.683   noise: 0.320\n",
      "Iter 291/300 - Loss: 3.399   lengthscale: 10.763   noise: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9221, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[912   0]\n",
      " [ 77   0]]\n",
      "accuracy: 0.9194, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[228   0]\n",
      " [ 20   0]]\n",
      "\n",
      "NEK5 binding moe UNDER\n",
      "trainX:torch.Size([154, 306]), train y: torch.Size([154]), testX: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.264   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.063   noise: 1.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 31/300 - Loss: 5.251   lengthscale: 3.161   noise: 2.569\n",
      "Iter 41/300 - Loss: 5.168   lengthscale: 4.490   noise: 2.979\n",
      "Iter 51/300 - Loss: 5.123   lengthscale: 5.840   noise: 3.202\n",
      "Iter 61/300 - Loss: 5.099   lengthscale: 7.022   noise: 3.262\n",
      "Iter 71/300 - Loss: 5.083   lengthscale: 7.984   noise: 3.208\n",
      "Iter 81/300 - Loss: 5.072   lengthscale: 8.761   noise: 3.080\n",
      "Iter 91/300 - Loss: 5.064   lengthscale: 9.402   noise: 2.913\n",
      "Iter 101/300 - Loss: 5.057   lengthscale: 9.946   noise: 2.727\n",
      "Iter 111/300 - Loss: 5.050   lengthscale: 10.420   noise: 2.534\n",
      "Iter 121/300 - Loss: 5.045   lengthscale: 10.841   noise: 2.342\n",
      "Iter 131/300 - Loss: 5.039   lengthscale: 11.219   noise: 2.156\n",
      "Iter 141/300 - Loss: 5.035   lengthscale: 11.561   noise: 1.977\n",
      "Iter 151/300 - Loss: 5.030   lengthscale: 11.874   noise: 1.807\n",
      "Iter 161/300 - Loss: 5.026   lengthscale: 12.161   noise: 1.646\n",
      "Iter 171/300 - Loss: 5.023   lengthscale: 12.427   noise: 1.493\n",
      "Iter 181/300 - Loss: 5.019   lengthscale: 12.674   noise: 1.350\n",
      "Iter 191/300 - Loss: 5.016   lengthscale: 12.905   noise: 1.216\n",
      "Iter 201/300 - Loss: 5.013   lengthscale: 13.121   noise: 1.093\n",
      "Iter 211/300 - Loss: 5.011   lengthscale: 13.326   noise: 0.979\n",
      "Iter 221/300 - Loss: 5.008   lengthscale: 13.521   noise: 0.875\n",
      "Iter 231/300 - Loss: 5.006   lengthscale: 13.708   noise: 0.781\n",
      "Iter 241/300 - Loss: 5.004   lengthscale: 13.888   noise: 0.696\n",
      "Iter 251/300 - Loss: 5.003   lengthscale: 14.063   noise: 0.621\n",
      "Iter 261/300 - Loss: 5.001   lengthscale: 14.233   noise: 0.554\n",
      "Iter 271/300 - Loss: 5.000   lengthscale: 14.399   noise: 0.495\n",
      "Iter 281/300 - Loss: 4.998   lengthscale: 14.563   noise: 0.443\n",
      "Iter 291/300 - Loss: 4.997   lengthscale: 14.725   noise: 0.397\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[77  0]\n",
      " [ 0 77]]\n",
      "accuracy: 0.7379, precision: 0.2078, recall: 0.8000, specificity: 0.7325, cm: [[167  61]\n",
      " [  4  16]]\n",
      "\n",
      "NEK5 binding moe SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([1824, 306]), train y: torch.Size([1824]), testX: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.965   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.647   lengthscale: 1.320   noise: 1.273\n",
      "Iter 21/300 - Loss: 4.995   lengthscale: 2.184   noise: 1.699\n",
      "Iter 31/300 - Loss: 4.625   lengthscale: 3.191   noise: 1.658\n",
      "Iter 41/300 - Loss: 4.367   lengthscale: 4.186   noise: 1.231\n",
      "Iter 51/300 - Loss: 4.181   lengthscale: 5.032   noise: 0.711\n",
      "Iter 61/300 - Loss: 4.051   lengthscale: 5.708   noise: 0.338\n",
      "Iter 71/300 - Loss: 3.965   lengthscale: 6.257   noise: 0.158\n",
      "Iter 81/300 - Loss: 3.931   lengthscale: 6.719   noise: 0.087\n",
      "Iter 91/300 - Loss: 3.898   lengthscale: 7.122   noise: 0.057\n",
      "Iter 101/300 - Loss: 3.866   lengthscale: 7.479   noise: 0.043\n",
      "Iter 111/300 - Loss: 3.856   lengthscale: 7.802   noise: 0.034\n",
      "Iter 121/300 - Loss: 3.834   lengthscale: 8.097   noise: 0.028\n",
      "Iter 131/300 - Loss: 3.824   lengthscale: 8.370   noise: 0.024\n",
      "Iter 141/300 - Loss: 3.836   lengthscale: 8.626   noise: 0.021\n",
      "Iter 151/300 - Loss: 3.818   lengthscale: 8.867   noise: 0.019\n",
      "Iter 161/300 - Loss: 3.805   lengthscale: 9.096   noise: 0.017\n",
      "Iter 171/300 - Loss: 3.792   lengthscale: 9.314   noise: 0.015\n",
      "Iter 181/300 - Loss: 3.799   lengthscale: 9.525   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.795   lengthscale: 9.727   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.794   lengthscale: 9.923   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.790   lengthscale: 10.112   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.774   lengthscale: 10.293   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.775   lengthscale: 10.470   noise: 0.009\n",
      "Iter 241/300 - Loss: 3.777   lengthscale: 10.642   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.767   lengthscale: 10.810   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.773   lengthscale: 10.975   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.773   lengthscale: 11.135   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.774   lengthscale: 11.291   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.770   lengthscale: 11.443   noise: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9989, recall: 1.0000, specificity: 0.9989, cm: [[911   1]\n",
      " [  0 912]]\n",
      "accuracy: 0.9516, precision: 0.7857, recall: 0.5500, specificity: 0.9868, cm: [[225   3]\n",
      " [  9  11]]\n",
      "\n",
      "NEK5 binding moe ADASYN\n",
      "trainX:torch.Size([1831, 306]), train y: torch.Size([1831]), testX: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.974   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.672   lengthscale: 1.321   noise: 1.278\n",
      "Iter 21/300 - Loss: 5.025   lengthscale: 2.189   noise: 1.738\n",
      "Iter 31/300 - Loss: 4.662   lengthscale: 3.209   noise: 1.738\n",
      "Iter 41/300 - Loss: 4.406   lengthscale: 4.221   noise: 1.317\n",
      "Iter 51/300 - Loss: 4.225   lengthscale: 5.093   noise: 0.766\n",
      "Iter 61/300 - Loss: 4.083   lengthscale: 5.795   noise: 0.365\n",
      "Iter 71/300 - Loss: 3.996   lengthscale: 6.367   noise: 0.171\n",
      "Iter 81/300 - Loss: 3.943   lengthscale: 6.849   noise: 0.094\n",
      "Iter 91/300 - Loss: 3.920   lengthscale: 7.267   noise: 0.062\n",
      "Iter 101/300 - Loss: 3.892   lengthscale: 7.639   noise: 0.046\n",
      "Iter 111/300 - Loss: 3.881   lengthscale: 7.974   noise: 0.036\n",
      "Iter 121/300 - Loss: 3.863   lengthscale: 8.281   noise: 0.030\n",
      "Iter 131/300 - Loss: 3.867   lengthscale: 8.564   noise: 0.026\n",
      "Iter 141/300 - Loss: 3.846   lengthscale: 8.827   noise: 0.022\n",
      "Iter 151/300 - Loss: 3.844   lengthscale: 9.076   noise: 0.020\n",
      "Iter 161/300 - Loss: 3.844   lengthscale: 9.312   noise: 0.018\n",
      "Iter 171/300 - Loss: 3.832   lengthscale: 9.538   noise: 0.016\n",
      "Iter 181/300 - Loss: 3.832   lengthscale: 9.754   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.825   lengthscale: 9.962   noise: 0.013\n",
      "Iter 201/300 - Loss: 3.808   lengthscale: 10.163   noise: 0.012\n",
      "Iter 211/300 - Loss: 3.817   lengthscale: 10.356   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.810   lengthscale: 10.544   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.800   lengthscale: 10.725   noise: 0.010\n",
      "Iter 241/300 - Loss: 3.808   lengthscale: 10.901   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.802   lengthscale: 11.073   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.804   lengthscale: 11.241   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.805   lengthscale: 11.404   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.792   lengthscale: 11.563   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.808   lengthscale: 11.716   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9989, recall: 1.0000, specificity: 0.9989, cm: [[911   1]\n",
      " [  0 919]]\n",
      "accuracy: 0.9435, precision: 0.7143, recall: 0.5000, specificity: 0.9825, cm: [[224   4]\n",
      " [ 10  10]]\n",
      "\n",
      "NEK5 binding mfp scaled\n",
      "trainX:torch.Size([989, 2048]), train y: torch.Size([989]), testX: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.091   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.223   lengthscale: 1.291   noise: 0.806\n",
      "Iter 21/300 - Loss: 3.783   lengthscale: 2.103   noise: 0.988\n",
      "Iter 31/300 - Loss: 3.526   lengthscale: 2.808   noise: 1.052\n",
      "Iter 41/300 - Loss: 3.468   lengthscale: 3.279   noise: 1.029\n",
      "Iter 51/300 - Loss: 3.449   lengthscale: 3.578   noise: 0.960\n",
      "Iter 61/300 - Loss: 3.429   lengthscale: 3.772   noise: 0.872\n",
      "Iter 71/300 - Loss: 3.419   lengthscale: 3.913   noise: 0.778\n",
      "Iter 81/300 - Loss: 3.405   lengthscale: 4.021   noise: 0.686\n",
      "Iter 91/300 - Loss: 3.400   lengthscale: 4.112   noise: 0.602\n",
      "Iter 101/300 - Loss: 3.386   lengthscale: 4.191   noise: 0.528\n",
      "Iter 111/300 - Loss: 3.388   lengthscale: 4.266   noise: 0.465\n",
      "Iter 121/300 - Loss: 3.383   lengthscale: 4.336   noise: 0.411\n",
      "Iter 131/300 - Loss: 3.383   lengthscale: 4.400   noise: 0.366\n",
      "Iter 141/300 - Loss: 3.377   lengthscale: 4.459   noise: 0.328\n",
      "Iter 151/300 - Loss: 3.376   lengthscale: 4.516   noise: 0.296\n",
      "Iter 161/300 - Loss: 3.369   lengthscale: 4.568   noise: 0.269\n",
      "Iter 171/300 - Loss: 3.371   lengthscale: 4.617   noise: 0.245\n",
      "Iter 181/300 - Loss: 3.362   lengthscale: 4.665   noise: 0.224\n",
      "Iter 191/300 - Loss: 3.362   lengthscale: 4.711   noise: 0.206\n",
      "Iter 201/300 - Loss: 3.365   lengthscale: 4.757   noise: 0.190\n",
      "Iter 211/300 - Loss: 3.358   lengthscale: 4.799   noise: 0.175\n",
      "Iter 221/300 - Loss: 3.356   lengthscale: 4.839   noise: 0.162\n",
      "Iter 231/300 - Loss: 3.364   lengthscale: 4.878   noise: 0.151\n",
      "Iter 241/300 - Loss: 3.358   lengthscale: 4.916   noise: 0.141\n",
      "Iter 251/300 - Loss: 3.356   lengthscale: 4.953   noise: 0.131\n",
      "Iter 261/300 - Loss: 3.356   lengthscale: 4.987   noise: 0.123\n",
      "Iter 271/300 - Loss: 3.358   lengthscale: 5.021   noise: 0.115\n",
      "Iter 281/300 - Loss: 3.356   lengthscale: 5.053   noise: 0.108\n",
      "Iter 291/300 - Loss: 3.354   lengthscale: 5.087   noise: 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9221, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[912   0]\n",
      " [ 77   0]]\n",
      "accuracy: 0.9194, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[228   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK5 binding mfp UNDER\n",
      "trainX:torch.Size([154, 2048]), train y: torch.Size([154]), testX: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.907   lengthscale: 1.287   noise: 1.296\n",
      "Iter 21/300 - Loss: 5.385   lengthscale: 2.144   noise: 1.974\n",
      "Iter 31/300 - Loss: 5.254   lengthscale: 2.924   noise: 2.573\n",
      "Iter 41/300 - Loss: 5.219   lengthscale: 3.299   noise: 3.038\n",
      "Iter 51/300 - Loss: 5.207   lengthscale: 3.424   noise: 3.360\n",
      "Iter 61/300 - Loss: 5.203   lengthscale: 3.443   noise: 3.567\n",
      "Iter 71/300 - Loss: 5.201   lengthscale: 3.426   noise: 3.690\n",
      "Iter 81/300 - Loss: 5.200   lengthscale: 3.398   noise: 3.757\n",
      "Iter 91/300 - Loss: 5.200   lengthscale: 3.368   noise: 3.788\n",
      "Iter 101/300 - Loss: 5.199   lengthscale: 3.338   noise: 3.796\n",
      "Iter 111/300 - Loss: 5.199   lengthscale: 3.306   noise: 3.791\n",
      "Iter 121/300 - Loss: 5.199   lengthscale: 3.272   noise: 3.777\n",
      "Iter 131/300 - Loss: 5.199   lengthscale: 3.235   noise: 3.758\n",
      "Iter 141/300 - Loss: 5.198   lengthscale: 3.196   noise: 3.737\n",
      "Iter 151/300 - Loss: 5.198   lengthscale: 3.153   noise: 3.714\n",
      "Iter 161/300 - Loss: 5.198   lengthscale: 3.109   noise: 3.690\n",
      "Iter 171/300 - Loss: 5.198   lengthscale: 3.063   noise: 3.666\n",
      "Iter 181/300 - Loss: 5.198   lengthscale: 3.017   noise: 3.641\n",
      "Iter 191/300 - Loss: 5.198   lengthscale: 2.969   noise: 3.615\n",
      "Iter 201/300 - Loss: 5.198   lengthscale: 2.922   noise: 3.589\n",
      "Iter 211/300 - Loss: 5.197   lengthscale: 2.876   noise: 3.563\n",
      "Iter 221/300 - Loss: 5.197   lengthscale: 2.830   noise: 3.536\n",
      "Iter 231/300 - Loss: 5.197   lengthscale: 2.786   noise: 3.509\n",
      "Iter 241/300 - Loss: 5.197   lengthscale: 2.743   noise: 3.481\n",
      "Iter 251/300 - Loss: 5.197   lengthscale: 2.702   noise: 3.453\n",
      "Iter 261/300 - Loss: 5.197   lengthscale: 2.662   noise: 3.425\n",
      "Iter 271/300 - Loss: 5.197   lengthscale: 2.625   noise: 3.397\n",
      "Iter 281/300 - Loss: 5.197   lengthscale: 2.589   noise: 3.368\n",
      "Iter 291/300 - Loss: 5.197   lengthscale: 2.556   noise: 3.340\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[77  0]\n",
      " [ 0 77]]\n",
      "accuracy: 0.5242, precision: 0.0984, recall: 0.6000, specificity: 0.5175, cm: [[118 110]\n",
      " [  8  12]]\n",
      "\n",
      "NEK5 binding mfp SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([1824, 2048]), train y: torch.Size([1824]), testX: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.302   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.800   lengthscale: 1.302   noise: 0.792\n",
      "Iter 21/300 - Loss: 4.059   lengthscale: 2.040   noise: 0.740\n",
      "Iter 31/300 - Loss: 3.782   lengthscale: 2.678   noise: 0.430\n",
      "Iter 41/300 - Loss: 3.654   lengthscale: 3.108   noise: 0.194\n",
      "Iter 51/300 - Loss: 3.584   lengthscale: 3.400   noise: 0.088\n",
      "Iter 61/300 - Loss: 3.554   lengthscale: 3.617   noise: 0.048\n",
      "Iter 71/300 - Loss: 3.518   lengthscale: 3.797   noise: 0.031\n",
      "Iter 81/300 - Loss: 3.513   lengthscale: 3.956   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.514   lengthscale: 4.102   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.505   lengthscale: 4.237   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.492   lengthscale: 4.365   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.487   lengthscale: 4.485   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.484   lengthscale: 4.601   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.469   lengthscale: 4.711   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.472   lengthscale: 4.817   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.470   lengthscale: 4.920   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.478   lengthscale: 5.019   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.488   lengthscale: 5.115   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.467   lengthscale: 5.208   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.461   lengthscale: 5.298   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.465   lengthscale: 5.386   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.452   lengthscale: 5.472   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.447   lengthscale: 5.555   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.461   lengthscale: 5.637   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.455   lengthscale: 5.717   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.450   lengthscale: 5.795   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.444   lengthscale: 5.872   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.455   lengthscale: 5.948   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.458   lengthscale: 6.023   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9984, precision: 0.9989, recall: 0.9978, specificity: 0.9989, cm: [[911   1]\n",
      " [  2 910]]\n",
      "accuracy: 0.9556, precision: 0.9091, recall: 0.5000, specificity: 0.9956, cm: [[227   1]\n",
      " [ 10  10]]\n",
      "\n",
      "NEK5 binding mfp ADASYN\n",
      "trainX:torch.Size([1805, 2048]), train y: torch.Size([1805]), testX: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.306   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.794   lengthscale: 1.299   noise: 0.792\n",
      "Iter 21/300 - Loss: 4.064   lengthscale: 2.016   noise: 0.751\n",
      "Iter 31/300 - Loss: 3.794   lengthscale: 2.633   noise: 0.445\n",
      "Iter 41/300 - Loss: 3.662   lengthscale: 3.049   noise: 0.203\n",
      "Iter 51/300 - Loss: 3.582   lengthscale: 3.331   noise: 0.092\n",
      "Iter 61/300 - Loss: 3.547   lengthscale: 3.541   noise: 0.049\n",
      "Iter 71/300 - Loss: 3.537   lengthscale: 3.713   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.511   lengthscale: 3.865   noise: 0.024\n",
      "Iter 91/300 - Loss: 3.494   lengthscale: 4.004   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.515   lengthscale: 4.134   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.499   lengthscale: 4.257   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.495   lengthscale: 4.374   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.501   lengthscale: 4.487   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.486   lengthscale: 4.596   noise: 0.010\n",
      "Iter 151/300 - Loss: 3.489   lengthscale: 4.699   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.497   lengthscale: 4.799   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.466   lengthscale: 4.895   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.485   lengthscale: 4.989   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.477   lengthscale: 5.080   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.477   lengthscale: 5.168   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.471   lengthscale: 5.255   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.464   lengthscale: 5.339   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.471   lengthscale: 5.421   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.461   lengthscale: 5.500   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.473   lengthscale: 5.579   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.465   lengthscale: 5.655   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.454   lengthscale: 5.730   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.453   lengthscale: 5.804   noise: 0.004\n",
      "Iter 291/300 - Loss: 3.452   lengthscale: 5.877   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9983, precision: 0.9989, recall: 0.9978, specificity: 0.9989, cm: [[911   1]\n",
      " [  2 891]]\n",
      "accuracy: 0.9516, precision: 1.0000, recall: 0.4000, specificity: 1.0000, cm: [[228   0]\n",
      " [ 12   8]]\n",
      "\n",
      "NEK9\n",
      "NEK9 binding moe scaled\n",
      "trainX:torch.Size([1126, 306]), train y: torch.Size([1126]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.486   lengthscale: 0.930   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.471   lengthscale: 1.399   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.763   lengthscale: 2.014   noise: 1.314\n",
      "Iter 41/300 - Loss: 3.401   lengthscale: 2.740   noise: 1.422\n",
      "Iter 51/300 - Loss: 3.297   lengthscale: 3.345   noise: 1.410\n",
      "Iter 61/300 - Loss: 3.255   lengthscale: 3.784   noise: 1.336\n",
      "Iter 71/300 - Loss: 3.233   lengthscale: 4.216   noise: 1.232\n",
      "Iter 81/300 - Loss: 3.209   lengthscale: 4.834   noise: 1.115\n",
      "Iter 91/300 - Loss: 3.190   lengthscale: 5.590   noise: 0.994\n",
      "Iter 101/300 - Loss: 3.177   lengthscale: 6.264   noise: 0.876\n",
      "Iter 111/300 - Loss: 3.160   lengthscale: 6.995   noise: 0.765\n",
      "Iter 121/300 - Loss: 3.150   lengthscale: 7.886   noise: 0.667\n",
      "Iter 131/300 - Loss: 3.143   lengthscale: 8.694   noise: 0.585\n",
      "Iter 141/300 - Loss: 3.130   lengthscale: 9.475   noise: 0.518\n",
      "Iter 151/300 - Loss: 3.127   lengthscale: 10.219   noise: 0.465\n",
      "Iter 161/300 - Loss: 3.123   lengthscale: 10.935   noise: 0.424\n",
      "Iter 171/300 - Loss: 3.118   lengthscale: 11.539   noise: 0.392\n",
      "Iter 181/300 - Loss: 3.121   lengthscale: 12.088   noise: 0.368\n",
      "Iter 191/300 - Loss: 3.121   lengthscale: 12.566   noise: 0.348\n",
      "Iter 201/300 - Loss: 3.111   lengthscale: 12.986   noise: 0.332\n",
      "Iter 211/300 - Loss: 3.108   lengthscale: 13.370   noise: 0.319\n",
      "Iter 221/300 - Loss: 3.111   lengthscale: 13.757   noise: 0.306\n",
      "Iter 231/300 - Loss: 3.107   lengthscale: 14.082   noise: 0.295\n",
      "Iter 241/300 - Loss: 3.108   lengthscale: 14.391   noise: 0.285\n",
      "Iter 251/300 - Loss: 3.105   lengthscale: 14.683   noise: 0.275\n",
      "Iter 261/300 - Loss: 3.107   lengthscale: 14.953   noise: 0.266\n",
      "Iter 271/300 - Loss: 3.103   lengthscale: 15.193   noise: 0.258\n",
      "Iter 281/300 - Loss: 3.103   lengthscale: 15.423   noise: 0.250\n",
      "Iter 291/300 - Loss: 3.109   lengthscale: 15.609   noise: 0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9574, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [  48    0]]\n",
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK9 binding moe UNDER\n",
      "trainX:torch.Size([96, 306]), train y: torch.Size([96]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.929   lengthscale: 1.303   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.434   lengthscale: 2.161   noise: 1.980\n",
      "Iter 31/300 - Loss: 5.253   lengthscale: 3.292   noise: 2.565\n",
      "Iter 41/300 - Loss: 5.186   lengthscale: 4.597   noise: 2.981\n",
      "Iter 51/300 - Loss: 5.156   lengthscale: 5.902   noise: 3.233\n",
      "Iter 61/300 - Loss: 5.138   lengthscale: 7.081   noise: 3.347\n",
      "Iter 71/300 - Loss: 5.127   lengthscale: 8.093   noise: 3.358\n",
      "Iter 81/300 - Loss: 5.118   lengthscale: 8.951   noise: 3.298\n",
      "Iter 91/300 - Loss: 5.112   lengthscale: 9.683   noise: 3.195\n",
      "Iter 101/300 - Loss: 5.106   lengthscale: 10.318   noise: 3.066\n",
      "Iter 111/300 - Loss: 5.101   lengthscale: 10.877   noise: 2.923\n",
      "Iter 121/300 - Loss: 5.097   lengthscale: 11.376   noise: 2.773\n",
      "Iter 131/300 - Loss: 5.093   lengthscale: 11.825   noise: 2.622\n",
      "Iter 141/300 - Loss: 5.089   lengthscale: 12.233   noise: 2.472\n",
      "Iter 151/300 - Loss: 5.086   lengthscale: 12.604   noise: 2.323\n",
      "Iter 161/300 - Loss: 5.083   lengthscale: 12.944   noise: 2.178\n",
      "Iter 171/300 - Loss: 5.080   lengthscale: 13.256   noise: 2.035\n",
      "Iter 181/300 - Loss: 5.077   lengthscale: 13.544   noise: 1.896\n",
      "Iter 191/300 - Loss: 5.074   lengthscale: 13.809   noise: 1.761\n",
      "Iter 201/300 - Loss: 5.071   lengthscale: 14.054   noise: 1.631\n",
      "Iter 211/300 - Loss: 5.069   lengthscale: 14.282   noise: 1.505\n",
      "Iter 221/300 - Loss: 5.067   lengthscale: 14.493   noise: 1.385\n",
      "Iter 231/300 - Loss: 5.065   lengthscale: 14.690   noise: 1.270\n",
      "Iter 241/300 - Loss: 5.063   lengthscale: 14.875   noise: 1.161\n",
      "Iter 251/300 - Loss: 5.061   lengthscale: 15.049   noise: 1.059\n",
      "Iter 261/300 - Loss: 5.059   lengthscale: 15.213   noise: 0.963\n",
      "Iter 271/300 - Loss: 5.058   lengthscale: 15.369   noise: 0.873\n",
      "Iter 281/300 - Loss: 5.056   lengthscale: 15.519   noise: 0.791\n",
      "Iter 291/300 - Loss: 5.055   lengthscale: 15.664   noise: 0.715\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[48  0]\n",
      " [ 0 48]]\n",
      "accuracy: 0.6643, precision: 0.0816, recall: 0.6154, specificity: 0.6667, cm: [[180  90]\n",
      " [  5   8]]\n",
      "\n",
      "NEK9 binding moe SMOTE\n",
      "trainX:torch.Size([2156, 306]), train y: torch.Size([2156]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/300 - Loss: 6.889   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.537   lengthscale: 1.319   noise: 1.252\n",
      "Iter 21/300 - Loss: 4.859   lengthscale: 2.177   noise: 1.529\n",
      "Iter 31/300 - Loss: 4.458   lengthscale: 3.154   noise: 1.372\n",
      "Iter 41/300 - Loss: 4.166   lengthscale: 4.114   noise: 0.940\n",
      "Iter 51/300 - Loss: 3.970   lengthscale: 4.922   noise: 0.496\n",
      "Iter 61/300 - Loss: 3.853   lengthscale: 5.552   noise: 0.220\n",
      "Iter 71/300 - Loss: 3.763   lengthscale: 6.055   noise: 0.104\n",
      "Iter 81/300 - Loss: 3.726   lengthscale: 6.475   noise: 0.061\n",
      "Iter 91/300 - Loss: 3.684   lengthscale: 6.839   noise: 0.042\n",
      "Iter 101/300 - Loss: 3.669   lengthscale: 7.162   noise: 0.032\n",
      "Iter 111/300 - Loss: 3.645   lengthscale: 7.454   noise: 0.026\n",
      "Iter 121/300 - Loss: 3.641   lengthscale: 7.721   noise: 0.022\n",
      "Iter 131/300 - Loss: 3.626   lengthscale: 7.968   noise: 0.019\n",
      "Iter 141/300 - Loss: 3.616   lengthscale: 8.200   noise: 0.016\n",
      "Iter 151/300 - Loss: 3.612   lengthscale: 8.419   noise: 0.014\n",
      "Iter 161/300 - Loss: 3.618   lengthscale: 8.628   noise: 0.013\n",
      "Iter 171/300 - Loss: 3.603   lengthscale: 8.826   noise: 0.012\n",
      "Iter 181/300 - Loss: 3.593   lengthscale: 9.017   noise: 0.011\n",
      "Iter 191/300 - Loss: 3.604   lengthscale: 9.200   noise: 0.010\n",
      "Iter 201/300 - Loss: 3.602   lengthscale: 9.378   noise: 0.009\n",
      "Iter 211/300 - Loss: 3.585   lengthscale: 9.548   noise: 0.008\n",
      "Iter 221/300 - Loss: 3.594   lengthscale: 9.714   noise: 0.008\n",
      "Iter 231/300 - Loss: 3.573   lengthscale: 9.875   noise: 0.007\n",
      "Iter 241/300 - Loss: 3.579   lengthscale: 10.031   noise: 0.007\n",
      "Iter 251/300 - Loss: 3.584   lengthscale: 10.183   noise: 0.006\n",
      "Iter 261/300 - Loss: 3.571   lengthscale: 10.331   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.574   lengthscale: 10.475   noise: 0.006\n",
      "Iter 281/300 - Loss: 3.578   lengthscale: 10.617   noise: 0.005\n",
      "Iter 291/300 - Loss: 3.579   lengthscale: 10.756   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [   0 1078]]\n",
      "accuracy: 0.9470, precision: 0.0000, recall: 0.0000, specificity: 0.9926, cm: [[268   2]\n",
      " [ 13   0]]\n",
      "\n",
      "NEK9 binding moe ADASYN\n",
      "trainX:torch.Size([2164, 306]), train y: torch.Size([2164]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.896   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.552   lengthscale: 1.320   noise: 1.256\n",
      "Iter 21/300 - Loss: 4.880   lengthscale: 2.178   noise: 1.557\n",
      "Iter 31/300 - Loss: 4.485   lengthscale: 3.160   noise: 1.404\n",
      "Iter 41/300 - Loss: 4.188   lengthscale: 4.128   noise: 0.960\n",
      "Iter 51/300 - Loss: 3.996   lengthscale: 4.946   noise: 0.504\n",
      "Iter 61/300 - Loss: 3.865   lengthscale: 5.587   noise: 0.224\n",
      "Iter 71/300 - Loss: 3.778   lengthscale: 6.100   noise: 0.106\n",
      "Iter 81/300 - Loss: 3.732   lengthscale: 6.529   noise: 0.062\n",
      "Iter 91/300 - Loss: 3.700   lengthscale: 6.900   noise: 0.042\n",
      "Iter 101/300 - Loss: 3.680   lengthscale: 7.230   noise: 0.032\n",
      "Iter 111/300 - Loss: 3.669   lengthscale: 7.528   noise: 0.026\n",
      "Iter 121/300 - Loss: 3.643   lengthscale: 7.800   noise: 0.022\n",
      "Iter 131/300 - Loss: 3.636   lengthscale: 8.052   noise: 0.019\n",
      "Iter 141/300 - Loss: 3.630   lengthscale: 8.289   noise: 0.017\n",
      "Iter 151/300 - Loss: 3.619   lengthscale: 8.513   noise: 0.015\n",
      "Iter 161/300 - Loss: 3.615   lengthscale: 8.726   noise: 0.013\n",
      "Iter 171/300 - Loss: 3.620   lengthscale: 8.929   noise: 0.012\n",
      "Iter 181/300 - Loss: 3.613   lengthscale: 9.123   noise: 0.011\n",
      "Iter 191/300 - Loss: 3.612   lengthscale: 9.310   noise: 0.010\n",
      "Iter 201/300 - Loss: 3.601   lengthscale: 9.491   noise: 0.009\n",
      "Iter 211/300 - Loss: 3.603   lengthscale: 9.664   noise: 0.008\n",
      "Iter 221/300 - Loss: 3.591   lengthscale: 9.832   noise: 0.008\n",
      "Iter 231/300 - Loss: 3.590   lengthscale: 9.995   noise: 0.007\n",
      "Iter 241/300 - Loss: 3.592   lengthscale: 10.155   noise: 0.007\n",
      "Iter 251/300 - Loss: 3.589   lengthscale: 10.310   noise: 0.006\n",
      "Iter 261/300 - Loss: 3.586   lengthscale: 10.460   noise: 0.006\n",
      "Iter 271/300 - Loss: 3.591   lengthscale: 10.607   noise: 0.006\n",
      "Iter 281/300 - Loss: 3.581   lengthscale: 10.750   noise: 0.005\n",
      "Iter 291/300 - Loss: 3.584   lengthscale: 10.890   noise: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [   0 1086]]\n",
      "accuracy: 0.9470, precision: 0.0000, recall: 0.0000, specificity: 0.9926, cm: [[268   2]\n",
      " [ 13   0]]\n",
      "\n",
      "NEK9 binding mfp scaled\n",
      "trainX:torch.Size([1126, 2048]), train y: torch.Size([1126]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.090   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.111   lengthscale: 1.273   noise: 0.806\n",
      "Iter 21/300 - Loss: 3.543   lengthscale: 2.043   noise: 0.979\n",
      "Iter 31/300 - Loss: 3.285   lengthscale: 2.746   noise: 1.023\n",
      "Iter 41/300 - Loss: 3.215   lengthscale: 3.232   noise: 0.979\n",
      "Iter 51/300 - Loss: 3.187   lengthscale: 3.568   noise: 0.893\n",
      "Iter 61/300 - Loss: 3.168   lengthscale: 3.797   noise: 0.790\n",
      "Iter 71/300 - Loss: 3.151   lengthscale: 3.969   noise: 0.686\n",
      "Iter 81/300 - Loss: 3.140   lengthscale: 4.108   noise: 0.589\n",
      "Iter 91/300 - Loss: 3.130   lengthscale: 4.226   noise: 0.504\n",
      "Iter 101/300 - Loss: 3.125   lengthscale: 4.333   noise: 0.433\n",
      "Iter 111/300 - Loss: 3.116   lengthscale: 4.430   noise: 0.376\n",
      "Iter 121/300 - Loss: 3.111   lengthscale: 4.516   noise: 0.330\n",
      "Iter 131/300 - Loss: 3.111   lengthscale: 4.593   noise: 0.294\n",
      "Iter 141/300 - Loss: 3.107   lengthscale: 4.664   noise: 0.266\n",
      "Iter 151/300 - Loss: 3.101   lengthscale: 4.731   noise: 0.243\n",
      "Iter 161/300 - Loss: 3.102   lengthscale: 4.796   noise: 0.224\n",
      "Iter 171/300 - Loss: 3.098   lengthscale: 4.854   noise: 0.209\n",
      "Iter 181/300 - Loss: 3.098   lengthscale: 4.907   noise: 0.195\n",
      "Iter 191/300 - Loss: 3.092   lengthscale: 4.961   noise: 0.183\n",
      "Iter 201/300 - Loss: 3.097   lengthscale: 5.009   noise: 0.172\n",
      "Iter 211/300 - Loss: 3.094   lengthscale: 5.055   noise: 0.163\n",
      "Iter 221/300 - Loss: 3.091   lengthscale: 5.101   noise: 0.154\n",
      "Iter 231/300 - Loss: 3.086   lengthscale: 5.144   noise: 0.146\n",
      "Iter 241/300 - Loss: 3.085   lengthscale: 5.184   noise: 0.139\n",
      "Iter 251/300 - Loss: 3.087   lengthscale: 5.221   noise: 0.133\n",
      "Iter 261/300 - Loss: 3.085   lengthscale: 5.258   noise: 0.126\n",
      "Iter 271/300 - Loss: 3.085   lengthscale: 5.292   noise: 0.121\n",
      "Iter 281/300 - Loss: 3.085   lengthscale: 5.322   noise: 0.115\n",
      "Iter 291/300 - Loss: 3.085   lengthscale: 5.351   noise: 0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9574, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [  48    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n",
      "\n",
      "NEK9 binding mfp UNDER\n",
      "trainX:torch.Size([96, 2048]), train y: torch.Size([96]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.919   lengthscale: 1.280   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.411   lengthscale: 2.137   noise: 1.979\n",
      "Iter 31/300 - Loss: 5.276   lengthscale: 2.927   noise: 2.591\n",
      "Iter 41/300 - Loss: 5.239   lengthscale: 3.192   noise: 3.083\n",
      "Iter 51/300 - Loss: 5.225   lengthscale: 3.113   noise: 3.440\n",
      "Iter 61/300 - Loss: 5.218   lengthscale: 2.885   noise: 3.681\n",
      "Iter 71/300 - Loss: 5.214   lengthscale: 2.599   noise: 3.833\n",
      "Iter 81/300 - Loss: 5.210   lengthscale: 2.293   noise: 3.922\n",
      "Iter 91/300 - Loss: 5.207   lengthscale: 1.992   noise: 3.968\n",
      "Iter 101/300 - Loss: 5.205   lengthscale: 1.723   noise: 3.989\n",
      "Iter 111/300 - Loss: 5.204   lengthscale: 1.506   noise: 3.996\n",
      "Iter 121/300 - Loss: 5.203   lengthscale: 1.341   noise: 3.999\n",
      "Iter 131/300 - Loss: 5.203   lengthscale: 1.220   noise: 4.001\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 1.131   noise: 4.003\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 1.065   noise: 4.005\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 1.013   noise: 4.007\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.971   noise: 4.008\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.936   noise: 4.009\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.905   noise: 4.009\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.878   noise: 4.010\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.854   noise: 4.010\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.832   noise: 4.011\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.812   noise: 4.011\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.793   noise: 4.012\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.775   noise: 4.012\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.759   noise: 4.013\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.744   noise: 4.013\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.730   noise: 4.013\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.716   noise: 4.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[48  0]\n",
      " [ 0 48]]\n",
      "accuracy: 0.7208, precision: 0.0417, recall: 0.2308, specificity: 0.7444, cm: [[201  69]\n",
      " [ 10   3]]\n",
      "\n",
      "NEK9 binding mfp SMOTE\n",
      "trainX:torch.Size([2156, 2048]), train y: torch.Size([2156]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.060   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.661   lengthscale: 1.297   noise: 0.786\n",
      "Iter 21/300 - Loss: 3.902   lengthscale: 2.017   noise: 0.675\n",
      "Iter 31/300 - Loss: 3.620   lengthscale: 2.632   noise: 0.358\n",
      "Iter 41/300 - Loss: 3.483   lengthscale: 3.040   noise: 0.155\n",
      "Iter 51/300 - Loss: 3.425   lengthscale: 3.311   noise: 0.073\n",
      "Iter 61/300 - Loss: 3.390   lengthscale: 3.510   noise: 0.042\n",
      "Iter 71/300 - Loss: 3.373   lengthscale: 3.672   noise: 0.029\n",
      "Iter 81/300 - Loss: 3.361   lengthscale: 3.813   noise: 0.022\n",
      "Iter 91/300 - Loss: 3.357   lengthscale: 3.941   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.355   lengthscale: 4.060   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.349   lengthscale: 4.172   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.347   lengthscale: 4.280   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.337   lengthscale: 4.384   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.328   lengthscale: 4.483   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.335   lengthscale: 4.579   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.333   lengthscale: 4.671   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.324   lengthscale: 4.761   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.321   lengthscale: 4.849   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.320   lengthscale: 4.934   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.321   lengthscale: 5.017   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.321   lengthscale: 5.097   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.315   lengthscale: 5.175   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.316   lengthscale: 5.250   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.312   lengthscale: 5.324   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.313   lengthscale: 5.397   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.314   lengthscale: 5.468   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.309   lengthscale: 5.537   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.311   lengthscale: 5.605   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.306   lengthscale: 5.672   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9981, precision: 0.9991, recall: 0.9972, specificity: 0.9991, cm: [[1077    1]\n",
      " [   3 1075]]\n",
      "accuracy: 0.9505, precision: 0.0000, recall: 0.0000, specificity: 0.9963, cm: [[269   1]\n",
      " [ 13   0]]\n",
      "\n",
      "NEK9 binding mfp ADASYN\n",
      "trainX:torch.Size([2166, 2048]), train y: torch.Size([2166]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.022   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.640   lengthscale: 1.296   noise: 0.785\n",
      "Iter 21/300 - Loss: 3.888   lengthscale: 2.007   noise: 0.665\n",
      "Iter 31/300 - Loss: 3.609   lengthscale: 2.613   noise: 0.348\n",
      "Iter 41/300 - Loss: 3.475   lengthscale: 3.014   noise: 0.151\n",
      "Iter 51/300 - Loss: 3.425   lengthscale: 3.279   noise: 0.071\n",
      "Iter 61/300 - Loss: 3.378   lengthscale: 3.474   noise: 0.042\n",
      "Iter 71/300 - Loss: 3.366   lengthscale: 3.632   noise: 0.029\n",
      "Iter 81/300 - Loss: 3.352   lengthscale: 3.769   noise: 0.022\n",
      "Iter 91/300 - Loss: 3.346   lengthscale: 3.893   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.341   lengthscale: 4.009   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.338   lengthscale: 4.119   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.322   lengthscale: 4.224   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.327   lengthscale: 4.325   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.316   lengthscale: 4.422   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.317   lengthscale: 4.515   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.318   lengthscale: 4.605   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.312   lengthscale: 4.694   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.325   lengthscale: 4.779   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.317   lengthscale: 4.863   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.299   lengthscale: 4.943   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.304   lengthscale: 5.022   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.302   lengthscale: 5.098   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.305   lengthscale: 5.172   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.303   lengthscale: 5.245   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.302   lengthscale: 5.315   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.298   lengthscale: 5.384   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.302   lengthscale: 5.452   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.298   lengthscale: 5.518   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.296   lengthscale: 5.584   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9982, precision: 0.9991, recall: 0.9972, specificity: 0.9991, cm: [[1077    1]\n",
      " [   3 1085]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n",
      "\n",
      "NEK9 inhibition moe scaled\n",
      "trainX:torch.Size([313, 306]), train y: torch.Size([313]), testX: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.616   lengthscale: 1.292   noise: 0.808\n",
      "Iter 21/300 - Loss: 4.727   lengthscale: 2.124   noise: 1.072\n",
      "Iter 31/300 - Loss: 4.210   lengthscale: 3.238   noise: 1.327\n",
      "Iter 41/300 - Loss: 3.893   lengthscale: 4.531   noise: 1.479\n",
      "Iter 51/300 - Loss: 3.750   lengthscale: 5.748   noise: 1.514\n",
      "Iter 61/300 - Loss: 3.690   lengthscale: 6.699   noise: 1.470\n",
      "Iter 71/300 - Loss: 3.659   lengthscale: 7.410   noise: 1.382\n",
      "Iter 81/300 - Loss: 3.637   lengthscale: 7.952   noise: 1.269\n",
      "Iter 91/300 - Loss: 3.619   lengthscale: 8.388   noise: 1.146\n",
      "Iter 101/300 - Loss: 3.604   lengthscale: 8.755   noise: 1.018\n",
      "Iter 111/300 - Loss: 3.590   lengthscale: 9.076   noise: 0.891\n",
      "Iter 121/300 - Loss: 3.578   lengthscale: 9.364   noise: 0.771\n",
      "Iter 131/300 - Loss: 3.567   lengthscale: 9.626   noise: 0.662\n",
      "Iter 141/300 - Loss: 3.558   lengthscale: 9.868   noise: 0.565\n",
      "Iter 151/300 - Loss: 3.550   lengthscale: 10.093   noise: 0.482\n",
      "Iter 161/300 - Loss: 3.544   lengthscale: 10.302   noise: 0.412\n",
      "Iter 171/300 - Loss: 3.538   lengthscale: 10.498   noise: 0.354\n",
      "Iter 181/300 - Loss: 3.533   lengthscale: 10.683   noise: 0.306\n",
      "Iter 191/300 - Loss: 3.529   lengthscale: 10.857   noise: 0.267\n",
      "Iter 201/300 - Loss: 3.526   lengthscale: 11.022   noise: 0.234\n",
      "Iter 211/300 - Loss: 3.523   lengthscale: 11.179   noise: 0.207\n",
      "Iter 221/300 - Loss: 3.520   lengthscale: 11.329   noise: 0.184\n",
      "Iter 231/300 - Loss: 3.517   lengthscale: 11.472   noise: 0.164\n",
      "Iter 241/300 - Loss: 3.515   lengthscale: 11.610   noise: 0.148\n",
      "Iter 251/300 - Loss: 3.513   lengthscale: 11.743   noise: 0.133\n",
      "Iter 261/300 - Loss: 3.511   lengthscale: 11.871   noise: 0.121\n",
      "Iter 271/300 - Loss: 3.510   lengthscale: 11.995   noise: 0.111\n",
      "Iter 281/300 - Loss: 3.508   lengthscale: 12.115   noise: 0.102\n",
      "Iter 291/300 - Loss: 3.507   lengthscale: 12.231   noise: 0.094\n",
      "accuracy: 0.8946, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[280   0]\n",
      " [ 33   0]]\n",
      "accuracy: 0.8875, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[71  0]\n",
      " [ 9  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK9 inhibition moe UNDER\n",
      "trainX:torch.Size([66, 306]), train y: torch.Size([66]), testX: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.254   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.436   lengthscale: 2.023   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.243   lengthscale: 3.098   noise: 2.566\n",
      "Iter 41/300 - Loss: 5.144   lengthscale: 4.422   noise: 2.959\n",
      "Iter 51/300 - Loss: 5.080   lengthscale: 5.791   noise: 3.132\n",
      "Iter 61/300 - Loss: 5.036   lengthscale: 7.026   noise: 3.103\n",
      "Iter 71/300 - Loss: 5.001   lengthscale: 8.079   noise: 2.916\n",
      "Iter 81/300 - Loss: 4.972   lengthscale: 8.972   noise: 2.621\n",
      "Iter 91/300 - Loss: 4.945   lengthscale: 9.745   noise: 2.261\n",
      "Iter 101/300 - Loss: 4.920   lengthscale: 10.431   noise: 1.874\n",
      "Iter 111/300 - Loss: 4.896   lengthscale: 11.053   noise: 1.494\n",
      "Iter 121/300 - Loss: 4.875   lengthscale: 11.626   noise: 1.149\n",
      "Iter 131/300 - Loss: 4.856   lengthscale: 12.158   noise: 0.863\n",
      "Iter 141/300 - Loss: 4.841   lengthscale: 12.657   noise: 0.643\n",
      "Iter 151/300 - Loss: 4.828   lengthscale: 13.128   noise: 0.482\n",
      "Iter 161/300 - Loss: 4.818   lengthscale: 13.575   noise: 0.368\n",
      "Iter 171/300 - Loss: 4.810   lengthscale: 14.002   noise: 0.289\n",
      "Iter 181/300 - Loss: 4.804   lengthscale: 14.411   noise: 0.233\n",
      "Iter 191/300 - Loss: 4.799   lengthscale: 14.805   noise: 0.192\n",
      "Iter 201/300 - Loss: 4.794   lengthscale: 15.185   noise: 0.162\n",
      "Iter 211/300 - Loss: 4.791   lengthscale: 15.552   noise: 0.139\n",
      "Iter 221/300 - Loss: 4.787   lengthscale: 15.906   noise: 0.121\n",
      "Iter 231/300 - Loss: 4.784   lengthscale: 16.249   noise: 0.106\n",
      "Iter 241/300 - Loss: 4.782   lengthscale: 16.582   noise: 0.095\n",
      "Iter 251/300 - Loss: 4.780   lengthscale: 16.904   noise: 0.085\n",
      "Iter 261/300 - Loss: 4.778   lengthscale: 17.217   noise: 0.077\n",
      "Iter 271/300 - Loss: 4.776   lengthscale: 17.521   noise: 0.070\n",
      "Iter 281/300 - Loss: 4.774   lengthscale: 17.817   noise: 0.065\n",
      "Iter 291/300 - Loss: 4.772   lengthscale: 18.105   noise: 0.060\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[33  0]\n",
      " [ 0 33]]\n",
      "accuracy: 0.9125, precision: 0.5833, recall: 0.7778, specificity: 0.9296, cm: [[66  5]\n",
      " [ 2  7]]\n",
      "\n",
      "NEK9 inhibition moe SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([560, 306]), train y: torch.Size([560]), testX: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 6.977   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.673   lengthscale: 1.320   noise: 1.278\n",
      "Iter 21/300 - Loss: 5.013   lengthscale: 2.193   noise: 1.733\n",
      "Iter 31/300 - Loss: 4.642   lengthscale: 3.226   noise: 1.718\n",
      "Iter 41/300 - Loss: 4.355   lengthscale: 4.273   noise: 1.306\n",
      "Iter 51/300 - Loss: 4.130   lengthscale: 5.218   noise: 0.768\n",
      "Iter 61/300 - Loss: 3.966   lengthscale: 5.997   noise: 0.364\n",
      "Iter 71/300 - Loss: 3.860   lengthscale: 6.630   noise: 0.166\n",
      "Iter 81/300 - Loss: 3.796   lengthscale: 7.160   noise: 0.089\n",
      "Iter 91/300 - Loss: 3.754   lengthscale: 7.616   noise: 0.057\n",
      "Iter 101/300 - Loss: 3.726   lengthscale: 8.021   noise: 0.042\n",
      "Iter 111/300 - Loss: 3.707   lengthscale: 8.387   noise: 0.033\n",
      "Iter 121/300 - Loss: 3.692   lengthscale: 8.722   noise: 0.027\n",
      "Iter 131/300 - Loss: 3.680   lengthscale: 9.034   noise: 0.023\n",
      "Iter 141/300 - Loss: 3.670   lengthscale: 9.325   noise: 0.020\n",
      "Iter 151/300 - Loss: 3.661   lengthscale: 9.601   noise: 0.018\n",
      "Iter 161/300 - Loss: 3.654   lengthscale: 9.863   noise: 0.016\n",
      "Iter 171/300 - Loss: 3.647   lengthscale: 10.113   noise: 0.014\n",
      "Iter 181/300 - Loss: 3.641   lengthscale: 10.352   noise: 0.013\n",
      "Iter 191/300 - Loss: 3.636   lengthscale: 10.582   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.631   lengthscale: 10.805   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.627   lengthscale: 11.020   noise: 0.010\n",
      "Iter 221/300 - Loss: 3.623   lengthscale: 11.228   noise: 0.009\n",
      "Iter 231/300 - Loss: 3.620   lengthscale: 11.431   noise: 0.009\n",
      "Iter 241/300 - Loss: 3.616   lengthscale: 11.628   noise: 0.008\n",
      "Iter 251/300 - Loss: 3.613   lengthscale: 11.820   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.611   lengthscale: 12.008   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.608   lengthscale: 12.191   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.605   lengthscale: 12.371   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.603   lengthscale: 12.547   noise: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9982, precision: 0.9964, recall: 1.0000, specificity: 0.9964, cm: [[279   1]\n",
      " [  0 280]]\n",
      "accuracy: 0.9500, precision: 0.8571, recall: 0.6667, specificity: 0.9859, cm: [[70  1]\n",
      " [ 3  6]]\n",
      "\n",
      "NEK9 inhibition moe ADASYN\n",
      "trainX:torch.Size([560, 306]), train y: torch.Size([560]), testX: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 6.968   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.665   lengthscale: 1.320   noise: 1.276\n",
      "Iter 21/300 - Loss: 5.024   lengthscale: 2.188   noise: 1.728\n",
      "Iter 31/300 - Loss: 4.667   lengthscale: 3.212   noise: 1.718\n",
      "Iter 41/300 - Loss: 4.385   lengthscale: 4.260   noise: 1.311\n",
      "Iter 51/300 - Loss: 4.157   lengthscale: 5.218   noise: 0.770\n",
      "Iter 61/300 - Loss: 3.991   lengthscale: 6.017   noise: 0.363\n",
      "Iter 71/300 - Loss: 3.885   lengthscale: 6.669   noise: 0.164\n",
      "Iter 81/300 - Loss: 3.821   lengthscale: 7.212   noise: 0.088\n",
      "Iter 91/300 - Loss: 3.780   lengthscale: 7.680   noise: 0.056\n",
      "Iter 101/300 - Loss: 3.753   lengthscale: 8.092   noise: 0.041\n",
      "Iter 111/300 - Loss: 3.733   lengthscale: 8.463   noise: 0.033\n",
      "Iter 121/300 - Loss: 3.718   lengthscale: 8.801   noise: 0.027\n",
      "Iter 131/300 - Loss: 3.706   lengthscale: 9.113   noise: 0.023\n",
      "Iter 141/300 - Loss: 3.696   lengthscale: 9.406   noise: 0.020\n",
      "Iter 151/300 - Loss: 3.688   lengthscale: 9.682   noise: 0.018\n",
      "Iter 161/300 - Loss: 3.681   lengthscale: 9.943   noise: 0.016\n",
      "Iter 171/300 - Loss: 3.674   lengthscale: 10.193   noise: 0.014\n",
      "Iter 181/300 - Loss: 3.669   lengthscale: 10.432   noise: 0.013\n",
      "Iter 191/300 - Loss: 3.664   lengthscale: 10.662   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.659   lengthscale: 10.884   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.655   lengthscale: 11.098   noise: 0.010\n",
      "Iter 221/300 - Loss: 3.651   lengthscale: 11.306   noise: 0.009\n",
      "Iter 231/300 - Loss: 3.648   lengthscale: 11.507   noise: 0.009\n",
      "Iter 241/300 - Loss: 3.644   lengthscale: 11.703   noise: 0.008\n",
      "Iter 251/300 - Loss: 3.641   lengthscale: 11.895   noise: 0.007\n",
      "Iter 261/300 - Loss: 3.639   lengthscale: 12.081   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.636   lengthscale: 12.263   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.634   lengthscale: 12.442   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.632   lengthscale: 12.616   noise: 0.006\n",
      "accuracy: 0.9982, precision: 0.9964, recall: 1.0000, specificity: 0.9964, cm: [[279   1]\n",
      " [  0 280]]\n",
      "accuracy: 0.9625, precision: 0.8750, recall: 0.7778, specificity: 0.9859, cm: [[70  1]\n",
      " [ 2  7]]\n",
      "\n",
      "NEK9 inhibition mfp scaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX:torch.Size([313, 2048]), train y: torch.Size([313]), testX: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.090   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.452   lengthscale: 1.305   noise: 0.807\n",
      "Iter 21/300 - Loss: 4.132   lengthscale: 2.165   noise: 1.023\n",
      "Iter 31/300 - Loss: 3.731   lengthscale: 3.029   noise: 1.120\n",
      "Iter 41/300 - Loss: 3.637   lengthscale: 3.634   noise: 1.097\n",
      "Iter 51/300 - Loss: 3.598   lengthscale: 4.018   noise: 1.008\n",
      "Iter 61/300 - Loss: 3.574   lengthscale: 4.266   noise: 0.889\n",
      "Iter 71/300 - Loss: 3.555   lengthscale: 4.443   noise: 0.760\n",
      "Iter 81/300 - Loss: 3.538   lengthscale: 4.581   noise: 0.633\n",
      "Iter 91/300 - Loss: 3.524   lengthscale: 4.699   noise: 0.518\n",
      "Iter 101/300 - Loss: 3.512   lengthscale: 4.804   noise: 0.420\n",
      "Iter 111/300 - Loss: 3.502   lengthscale: 4.900   noise: 0.340\n",
      "Iter 121/300 - Loss: 3.493   lengthscale: 4.990   noise: 0.276\n",
      "Iter 131/300 - Loss: 3.486   lengthscale: 5.074   noise: 0.227\n",
      "Iter 141/300 - Loss: 3.481   lengthscale: 5.154   noise: 0.190\n",
      "Iter 151/300 - Loss: 3.476   lengthscale: 5.229   noise: 0.161\n",
      "Iter 161/300 - Loss: 3.472   lengthscale: 5.301   noise: 0.138\n",
      "Iter 171/300 - Loss: 3.468   lengthscale: 5.369   noise: 0.120\n",
      "Iter 181/300 - Loss: 3.465   lengthscale: 5.435   noise: 0.106\n",
      "Iter 191/300 - Loss: 3.462   lengthscale: 5.498   noise: 0.094\n",
      "Iter 201/300 - Loss: 3.459   lengthscale: 5.558   noise: 0.085\n",
      "Iter 211/300 - Loss: 3.457   lengthscale: 5.616   noise: 0.076\n",
      "Iter 221/300 - Loss: 3.455   lengthscale: 5.673   noise: 0.069\n",
      "Iter 231/300 - Loss: 3.453   lengthscale: 5.727   noise: 0.063\n",
      "Iter 241/300 - Loss: 3.452   lengthscale: 5.780   noise: 0.058\n",
      "Iter 251/300 - Loss: 3.450   lengthscale: 5.831   noise: 0.054\n",
      "Iter 261/300 - Loss: 3.448   lengthscale: 5.881   noise: 0.050\n",
      "Iter 271/300 - Loss: 3.447   lengthscale: 5.930   noise: 0.047\n",
      "Iter 281/300 - Loss: 3.446   lengthscale: 5.977   noise: 0.043\n",
      "Iter 291/300 - Loss: 3.445   lengthscale: 6.023   noise: 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8978, precision: 1.0000, recall: 0.0303, specificity: 1.0000, cm: [[280   0]\n",
      " [ 32   1]]\n",
      "accuracy: 0.8875, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[71  0]\n",
      " [ 9  0]]\n",
      "\n",
      "NEK9 inhibition mfp UNDER\n",
      "trainX:torch.Size([66, 2048]), train y: torch.Size([66]), testX: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.932   lengthscale: 1.299   noise: 1.298\n",
      "Iter 21/300 - Loss: 5.435   lengthscale: 2.168   noise: 1.993\n",
      "Iter 31/300 - Loss: 5.298   lengthscale: 2.929   noise: 2.633\n",
      "Iter 41/300 - Loss: 5.258   lengthscale: 3.092   noise: 3.164\n",
      "Iter 51/300 - Loss: 5.241   lengthscale: 2.869   noise: 3.567\n",
      "Iter 61/300 - Loss: 5.231   lengthscale: 2.491   noise: 3.853\n",
      "Iter 71/300 - Loss: 5.224   lengthscale: 2.084   noise: 4.048\n",
      "Iter 81/300 - Loss: 5.220   lengthscale: 1.728   noise: 4.179\n",
      "Iter 91/300 - Loss: 5.218   lengthscale: 1.463   noise: 4.272\n",
      "Iter 101/300 - Loss: 5.217   lengthscale: 1.284   noise: 4.343\n",
      "Iter 111/300 - Loss: 5.216   lengthscale: 1.167   noise: 4.406\n",
      "Iter 121/300 - Loss: 5.215   lengthscale: 1.087   noise: 4.466\n",
      "Iter 131/300 - Loss: 5.215   lengthscale: 1.032   noise: 4.524\n",
      "Iter 141/300 - Loss: 5.214   lengthscale: 0.990   noise: 4.582\n",
      "Iter 151/300 - Loss: 5.214   lengthscale: 0.956   noise: 4.640\n",
      "Iter 161/300 - Loss: 5.214   lengthscale: 0.926   noise: 4.698\n",
      "Iter 171/300 - Loss: 5.214   lengthscale: 0.901   noise: 4.756\n",
      "Iter 181/300 - Loss: 5.213   lengthscale: 0.877   noise: 4.814\n",
      "Iter 191/300 - Loss: 5.213   lengthscale: 0.855   noise: 4.873\n",
      "Iter 201/300 - Loss: 5.213   lengthscale: 0.835   noise: 4.933\n",
      "Iter 211/300 - Loss: 5.212   lengthscale: 0.817   noise: 4.994\n",
      "Iter 221/300 - Loss: 5.212   lengthscale: 0.799   noise: 5.056\n",
      "Iter 231/300 - Loss: 5.212   lengthscale: 0.781   noise: 5.118\n",
      "Iter 241/300 - Loss: 5.211   lengthscale: 0.764   noise: 5.180\n",
      "Iter 251/300 - Loss: 5.211   lengthscale: 0.747   noise: 5.243\n",
      "Iter 261/300 - Loss: 5.211   lengthscale: 0.731   noise: 5.305\n",
      "Iter 271/300 - Loss: 5.211   lengthscale: 0.716   noise: 5.368\n",
      "Iter 281/300 - Loss: 5.210   lengthscale: 0.702   noise: 5.431\n",
      "Iter 291/300 - Loss: 5.210   lengthscale: 0.688   noise: 5.494\n",
      "accuracy: 0.9848, precision: 1.0000, recall: 0.9697, specificity: 1.0000, cm: [[33  0]\n",
      " [ 1 32]]\n",
      "accuracy: 0.6875, precision: 0.1000, recall: 0.2222, specificity: 0.7465, cm: [[53 18]\n",
      " [ 7  2]]\n",
      "\n",
      "NEK9 inhibition mfp SMOTE\n",
      "trainX:torch.Size([560, 2048]), train y: torch.Size([560]), testX: torch.Size([80, 2048]), test y: torch.Size([80])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/300 - Loss: 6.409   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.962   lengthscale: 1.307   noise: 0.844\n",
      "Iter 21/300 - Loss: 4.193   lengthscale: 2.093   noise: 0.835\n",
      "Iter 31/300 - Loss: 3.863   lengthscale: 2.836   noise: 0.526\n",
      "Iter 41/300 - Loss: 3.705   lengthscale: 3.373   noise: 0.245\n",
      "Iter 51/300 - Loss: 3.618   lengthscale: 3.748   noise: 0.107\n",
      "Iter 61/300 - Loss: 3.574   lengthscale: 4.032   noise: 0.055\n",
      "Iter 71/300 - Loss: 3.549   lengthscale: 4.267   noise: 0.035\n",
      "Iter 81/300 - Loss: 3.532   lengthscale: 4.474   noise: 0.025\n",
      "Iter 91/300 - Loss: 3.519   lengthscale: 4.664   noise: 0.020\n",
      "Iter 101/300 - Loss: 3.509   lengthscale: 4.841   noise: 0.017\n",
      "Iter 111/300 - Loss: 3.502   lengthscale: 5.007   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.495   lengthscale: 5.165   noise: 0.013\n",
      "Iter 131/300 - Loss: 3.490   lengthscale: 5.316   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.485   lengthscale: 5.461   noise: 0.010\n",
      "Iter 151/300 - Loss: 3.480   lengthscale: 5.600   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.476   lengthscale: 5.735   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.472   lengthscale: 5.865   noise: 0.008\n",
      "Iter 181/300 - Loss: 3.469   lengthscale: 5.991   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.465   lengthscale: 6.114   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.463   lengthscale: 6.233   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.460   lengthscale: 6.349   noise: 0.006\n",
      "Iter 221/300 - Loss: 3.458   lengthscale: 6.463   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.455   lengthscale: 6.573   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.454   lengthscale: 6.681   noise: 0.005\n",
      "Iter 251/300 - Loss: 3.451   lengthscale: 6.787   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.449   lengthscale: 6.890   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.447   lengthscale: 6.991   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.445   lengthscale: 7.090   noise: 0.004\n",
      "Iter 291/300 - Loss: 3.444   lengthscale: 7.187   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2155: NumericalWarning: Runtime Error when computing Cholesky decomposition: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.. Using symeig method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9982, precision: 0.9964, recall: 1.0000, specificity: 0.9964, cm: [[279   1]\n",
      " [  0 280]]\n",
      "accuracy: 0.9375, precision: 0.8333, recall: 0.5556, specificity: 0.9859, cm: [[70  1]\n",
      " [ 4  5]]\n",
      "\n",
      "NEK9 inhibition mfp ADASYN\n",
      "trainX:torch.Size([555, 2048]), train y: torch.Size([555]), testX: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 6.238   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.909   lengthscale: 1.307   noise: 0.794\n",
      "Iter 21/300 - Loss: 4.190   lengthscale: 2.092   noise: 0.797\n",
      "Iter 31/300 - Loss: 3.857   lengthscale: 2.844   noise: 0.490\n",
      "Iter 41/300 - Loss: 3.694   lengthscale: 3.392   noise: 0.222\n",
      "Iter 51/300 - Loss: 3.610   lengthscale: 3.772   noise: 0.096\n",
      "Iter 61/300 - Loss: 3.570   lengthscale: 4.056   noise: 0.050\n",
      "Iter 71/300 - Loss: 3.549   lengthscale: 4.287   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.534   lengthscale: 4.487   noise: 0.024\n",
      "Iter 91/300 - Loss: 3.525   lengthscale: 4.669   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.515   lengthscale: 4.837   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.509   lengthscale: 4.994   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.504   lengthscale: 5.143   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.499   lengthscale: 5.284   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.495   lengthscale: 5.420   noise: 0.010\n",
      "Iter 151/300 - Loss: 3.492   lengthscale: 5.551   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.488   lengthscale: 5.677   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.485   lengthscale: 5.800   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.483   lengthscale: 5.919   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.479   lengthscale: 6.034   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.478   lengthscale: 6.146   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.475   lengthscale: 6.255   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.474   lengthscale: 6.361   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.473   lengthscale: 6.465   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.471   lengthscale: 6.566   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.469   lengthscale: 6.665   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.467   lengthscale: 6.762   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.466   lengthscale: 6.857   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.463   lengthscale: 6.950   noise: 0.004\n",
      "Iter 291/300 - Loss: 3.462   lengthscale: 7.040   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[280   0]\n",
      " [  0 275]]\n",
      "accuracy: 0.9375, precision: 0.8333, recall: 0.5556, specificity: 0.9859, cm: [[70  1]\n",
      " [ 4  5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "samplings = ['scaled', 'UNDER', 'SMOTE', 'ADASYN'] \n",
    "feat_types = ['moe', 'mfp']\n",
    "neks = ['2', '3', '5', '9']\n",
    "GP_path= '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_matern_kernel/' \n",
    "for nek in neks:\n",
    "    print(f'NEK{nek}')\n",
    "    bind_inhib = ['binding', 'inhibition']\n",
    "    if nek in ['3','5']: \n",
    "        bind_inhib = ['binding']\n",
    "    else: \n",
    "        bind_inhib = ['binding', 'inhibition']\n",
    "    for bi in bind_inhib: \n",
    "        if bi == 'binding': \n",
    "            this_bi = 'bind' \n",
    "        if bi == 'inhibition': \n",
    "            this_bi = 'inhib'\n",
    "        nek_path= f'{data_dir}NEK{nek}/{this_bi}/'\n",
    "        for feat in feat_types: \n",
    "            for samp in samplings: \n",
    "                print(f'NEK{nek} {bi} {feat} {samp}')\n",
    "                file_root = f'NEK{nek}_{bi}_{feat}_{samp}'\n",
    "                trainX, trainy, testX, testy = make_torch_tens_float(nek_path,file_root) \n",
    "                print(f'trainX:{trainX.shape}, train y: {trainy.shape}, testX: {testX.shape}, test y: {testy.shape}')\n",
    "                train_perf_df, test_perf_df = save_results(trainX, trainy, testX, testy,file_root, n_iterations=300)\n",
    "                train_perf_df['NEK'] = f'NEK{nek}_{bi}'\n",
    "                train_perf_df['strategy'] = f'{samp}'\n",
    "                train_perf_df['feat_type'] = f'{feat}'\n",
    "                test_perf_df['NEK'] = f'NEK{nek}_{bi}'\n",
    "                test_perf_df['strategy'] = f'{samp}'\n",
    "                test_perf_df['feat_type'] = f'{feat}'\n",
    "                train_perf_df.to_csv(f'{GP_path}{file_root}_train_GP_matern.csv',index=False) \n",
    "                test_perf_df.to_csv(f'{GP_path}{file_root}_test_GP_matern.csv',index=False) \n",
    "                print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "958505ef-7fd7-4494-a3df-5ffc1298d0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2 bind moe scaled\n",
      "NEK2 bind moe UNDER\n",
      "NEK2 bind moe SMOTE\n",
      "NEK2 bind moe ADASYN\n",
      "NEK2 bind mfp scaled\n",
      "NEK2 bind mfp UNDER\n",
      "NEK2 bind mfp SMOTE\n",
      "NEK2 bind mfp ADASYN\n",
      "NEK2 inhib moe scaled\n",
      "NEK2 inhib moe UNDER\n",
      "NEK2 inhib moe SMOTE\n",
      "NEK2 inhib moe ADASYN\n",
      "NEK2 inhib mfp scaled\n",
      "NEK2 inhib mfp UNDER\n",
      "NEK2 inhib mfp SMOTE\n",
      "NEK2 inhib mfp ADASYN\n",
      "NEK3 bind moe scaled\n",
      "NEK3 bind moe UNDER\n",
      "NEK3 bind moe SMOTE\n",
      "NEK3 bind moe ADASYN\n",
      "NEK3 bind mfp scaled\n",
      "NEK3 bind mfp UNDER\n",
      "NEK3 bind mfp SMOTE\n",
      "NEK3 bind mfp ADASYN\n",
      "NEK5 bind moe scaled\n",
      "NEK5 bind moe UNDER\n",
      "NEK5 bind moe SMOTE\n",
      "NEK5 bind moe ADASYN\n",
      "NEK5 bind mfp scaled\n",
      "NEK5 bind mfp UNDER\n",
      "NEK5 bind mfp SMOTE\n",
      "NEK5 bind mfp ADASYN\n",
      "NEK9 bind moe scaled\n",
      "NEK9 bind moe UNDER\n",
      "NEK9 bind moe SMOTE\n",
      "NEK9 bind moe ADASYN\n",
      "NEK9 bind mfp scaled\n",
      "NEK9 bind mfp UNDER\n",
      "NEK9 bind mfp SMOTE\n",
      "NEK9 bind mfp ADASYN\n",
      "NEK9 inhib moe scaled\n",
      "NEK9 inhib moe UNDER\n",
      "NEK9 inhib moe SMOTE\n",
      "NEK9 inhib moe ADASYN\n",
      "NEK9 inhib mfp scaled\n",
      "NEK9 inhib mfp UNDER\n",
      "NEK9 inhib mfp SMOTE\n",
      "NEK9 inhib mfp ADASYN\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "GP_path= '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_matern_kernel/' \n",
    "train_results = [] \n",
    "test_results = [] \n",
    "for nek in neks:\n",
    "    bind_inhib = ['binding', 'inhibition']\n",
    "    if nek in ['3','5']: \n",
    "        bind_inhib = ['binding']\n",
    "    for bi in bind_inhib: \n",
    "        if bi == 'binding': \n",
    "            this_bi = 'bind' \n",
    "        if bi == 'inhibition': \n",
    "            this_bi = 'inhib'\n",
    "        nek_path= f'{data_dir}NEK{nek}/{this_bi}/'\n",
    "        for feat in feat_types: \n",
    "            for samp in samplings: \n",
    "                print(f'NEK{nek} {this_bi} {feat} {samp}')\n",
    "                file_root = f'NEK{nek}_{bi}_{feat}_{samp}'\n",
    "                train = pd.read_csv(f'{GP_path}{file_root}_train_GP_matern.csv').iloc[0]\n",
    "                test = pd.read_csv(f'{GP_path}{file_root}_test_GP_matern.csv').iloc[0]\n",
    "                train_results.append(train)\n",
    "                test_results.append(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8427cf4a-98a6-4424-96c7-51416f287f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = ['model','NEK', 'strategy', 'feat_type','cm','prediction_type', 'recall','ROC-AUC', 'MCC',\n",
    "       'Balanced Accuracy', 'f1', 'accuracy', 'precision',\n",
    "       'specificity', 'TN', 'FN', 'FP','TP']\n",
    "\n",
    "train_df =  pd.DataFrame(train_results,columns=metric_cols)\n",
    "\n",
    "train_df.to_csv(f'{GP_path}GP_maternkern_train_results.csv', index=False)\n",
    "test_df =  pd.DataFrame(test_results,columns=metric_cols)\n",
    "test_df.to_csv(f'{GP_path}GP_maternkern_test_results.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56e7b5b-d1ce-41b5-abf1-87efcf2c487d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>NEK</th>\n",
       "      <th>strategy</th>\n",
       "      <th>feat_type</th>\n",
       "      <th>cm</th>\n",
       "      <th>prediction_type</th>\n",
       "      <th>recall</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEK2_binding_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[271, 0, 12, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEK2_binding_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[212, 59, 5, 7]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.682811</td>\n",
       "      <td>0.174223</td>\n",
       "      <td>0.682811</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.773852</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.782288</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEK2_binding_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[270, 1, 9, 3]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.623155</td>\n",
       "      <td>0.420460</td>\n",
       "      <td>0.623155</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.964664</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.996310</td>\n",
       "      <td>270</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEK2_binding_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[271, 0, 9, 3]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.491899</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.968198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEK2_binding_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[271, 0, 12, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEK2_binding_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[4, 267, 0, 12]</td>\n",
       "      <td>FP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507380</td>\n",
       "      <td>0.025196</td>\n",
       "      <td>0.507380</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NEK2_binding_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[271, 0, 10, 2]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400918</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.964664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NEK2_binding_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[271, 0, 10, 2]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400918</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.964664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NEK2_inhibition_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[381, 0, 28, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>381</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NEK2_inhibition_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[331, 50, 6, 22]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.827240</td>\n",
       "      <td>0.433967</td>\n",
       "      <td>0.827240</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.863081</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.868766</td>\n",
       "      <td>331</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NEK2_inhibition_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[378, 3, 12, 16]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.781777</td>\n",
       "      <td>0.676189</td>\n",
       "      <td>0.781777</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.963325</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>378</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NEK2_inhibition_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[376, 5, 12, 16]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.779153</td>\n",
       "      <td>0.638833</td>\n",
       "      <td>0.779153</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.958435</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>376</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NEK2_inhibition_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[381, 0, 27, 1]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.182622</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.933985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>381</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NEK2_inhibition_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[100, 281, 5, 23]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.541948</td>\n",
       "      <td>0.048501</td>\n",
       "      <td>0.541948</td>\n",
       "      <td>0.138554</td>\n",
       "      <td>0.300733</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.262467</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>281</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NEK2_inhibition_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[379, 2, 13, 15]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.765232</td>\n",
       "      <td>0.671167</td>\n",
       "      <td>0.765232</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.963325</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>379</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NEK2_inhibition_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[379, 2, 13, 15]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.765232</td>\n",
       "      <td>0.671167</td>\n",
       "      <td>0.765232</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.963325</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>379</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEK3_binding_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[265, 0, 17, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NEK3_binding_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[159, 106, 5, 12]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.652941</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>0.652941</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NEK3_binding_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[259, 6, 15, 2]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.547503</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.547503</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>259</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NEK3_binding_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[257, 8, 15, 2]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.543729</td>\n",
       "      <td>0.112555</td>\n",
       "      <td>0.543729</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.918440</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>257</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEK3_binding_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[265, 0, 17, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NEK3_binding_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[125, 140, 3, 14]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.647614</td>\n",
       "      <td>0.141136</td>\n",
       "      <td>0.647614</td>\n",
       "      <td>0.163743</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEK3_binding_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[264, 1, 11, 6]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.674584</td>\n",
       "      <td>0.534153</td>\n",
       "      <td>0.674584</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>264</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NEK3_binding_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[264, 1, 12, 5]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.645172</td>\n",
       "      <td>0.478884</td>\n",
       "      <td>0.645172</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.953901</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>264</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NEK5_binding_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[228, 0, 20, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>228</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NEK5_binding_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[167, 61, 4, 16]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.766228</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.766228</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0.737903</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.732456</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NEK5_binding_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[225, 3, 9, 11]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.633369</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>225</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NEK5_binding_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[224, 4, 10, 10]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.569204</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>224</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NEK5_binding_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[228, 0, 20, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>228</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NEK5_binding_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[118, 110, 8, 12]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.558772</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.558772</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NEK5_binding_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[227, 1, 10, 10]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.747807</td>\n",
       "      <td>0.655474</td>\n",
       "      <td>0.747807</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.955645</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>227</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NEK5_binding_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[228, 0, 12, 8]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.616441</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>228</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NEK9_binding_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[270, 0, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>270</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NEK9_binding_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[180, 90, 5, 8]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.124103</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NEK9_binding_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[268, 2, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>-0.018512</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>268</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NEK9_binding_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[268, 2, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>-0.018512</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>268</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NEK9_binding_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[270, 0, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>270</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NEK9_binding_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[201, 69, 10, 3]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>-0.011914</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>201</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NEK9_binding_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[269, 1, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498148</td>\n",
       "      <td>-0.013067</td>\n",
       "      <td>0.498148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>269</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NEK9_binding_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[270, 0, 13, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>270</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NEK9_inhibition_moe_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>scaled</td>\n",
       "      <td>moe</td>\n",
       "      <td>[71, 0, 9, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NEK9_inhibition_moe_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>moe</td>\n",
       "      <td>[66, 5, 2, 7]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.853678</td>\n",
       "      <td>0.625955</td>\n",
       "      <td>0.853678</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NEK9_inhibition_moe_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>moe</td>\n",
       "      <td>[70, 1, 3, 6]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>0.729752</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NEK9_inhibition_moe_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>moe</td>\n",
       "      <td>[70, 1, 2, 7]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.881847</td>\n",
       "      <td>0.804374</td>\n",
       "      <td>0.881847</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NEK9_inhibition_mfp_scaled_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>scaled</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[71, 0, 9, 0]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NEK9_inhibition_mfp_UNDER_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[53, 18, 7, 2]</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.484351</td>\n",
       "      <td>-0.022840</td>\n",
       "      <td>0.484351</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NEK9_inhibition_mfp_SMOTE_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[70, 1, 4, 5]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.770736</td>\n",
       "      <td>0.649582</td>\n",
       "      <td>0.770736</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NEK9_inhibition_mfp_ADASYN_GP_Dirichlet_matern</td>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>mfp</td>\n",
       "      <td>[70, 1, 4, 5]</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.770736</td>\n",
       "      <td>0.649582</td>\n",
       "      <td>0.770736</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model              NEK strategy  \\\n",
       "0      NEK2_binding_moe_scaled_GP_Dirichlet_matern     NEK2_binding   scaled   \n",
       "1       NEK2_binding_moe_UNDER_GP_Dirichlet_matern     NEK2_binding    UNDER   \n",
       "2       NEK2_binding_moe_SMOTE_GP_Dirichlet_matern     NEK2_binding    SMOTE   \n",
       "3      NEK2_binding_moe_ADASYN_GP_Dirichlet_matern     NEK2_binding   ADASYN   \n",
       "4      NEK2_binding_mfp_scaled_GP_Dirichlet_matern     NEK2_binding   scaled   \n",
       "5       NEK2_binding_mfp_UNDER_GP_Dirichlet_matern     NEK2_binding    UNDER   \n",
       "6       NEK2_binding_mfp_SMOTE_GP_Dirichlet_matern     NEK2_binding    SMOTE   \n",
       "7      NEK2_binding_mfp_ADASYN_GP_Dirichlet_matern     NEK2_binding   ADASYN   \n",
       "8   NEK2_inhibition_moe_scaled_GP_Dirichlet_matern  NEK2_inhibition   scaled   \n",
       "9    NEK2_inhibition_moe_UNDER_GP_Dirichlet_matern  NEK2_inhibition    UNDER   \n",
       "10   NEK2_inhibition_moe_SMOTE_GP_Dirichlet_matern  NEK2_inhibition    SMOTE   \n",
       "11  NEK2_inhibition_moe_ADASYN_GP_Dirichlet_matern  NEK2_inhibition   ADASYN   \n",
       "12  NEK2_inhibition_mfp_scaled_GP_Dirichlet_matern  NEK2_inhibition   scaled   \n",
       "13   NEK2_inhibition_mfp_UNDER_GP_Dirichlet_matern  NEK2_inhibition    UNDER   \n",
       "14   NEK2_inhibition_mfp_SMOTE_GP_Dirichlet_matern  NEK2_inhibition    SMOTE   \n",
       "15  NEK2_inhibition_mfp_ADASYN_GP_Dirichlet_matern  NEK2_inhibition   ADASYN   \n",
       "16     NEK3_binding_moe_scaled_GP_Dirichlet_matern     NEK3_binding   scaled   \n",
       "17      NEK3_binding_moe_UNDER_GP_Dirichlet_matern     NEK3_binding    UNDER   \n",
       "18      NEK3_binding_moe_SMOTE_GP_Dirichlet_matern     NEK3_binding    SMOTE   \n",
       "19     NEK3_binding_moe_ADASYN_GP_Dirichlet_matern     NEK3_binding   ADASYN   \n",
       "20     NEK3_binding_mfp_scaled_GP_Dirichlet_matern     NEK3_binding   scaled   \n",
       "21      NEK3_binding_mfp_UNDER_GP_Dirichlet_matern     NEK3_binding    UNDER   \n",
       "22      NEK3_binding_mfp_SMOTE_GP_Dirichlet_matern     NEK3_binding    SMOTE   \n",
       "23     NEK3_binding_mfp_ADASYN_GP_Dirichlet_matern     NEK3_binding   ADASYN   \n",
       "24     NEK5_binding_moe_scaled_GP_Dirichlet_matern     NEK5_binding   scaled   \n",
       "25      NEK5_binding_moe_UNDER_GP_Dirichlet_matern     NEK5_binding    UNDER   \n",
       "26      NEK5_binding_moe_SMOTE_GP_Dirichlet_matern     NEK5_binding    SMOTE   \n",
       "27     NEK5_binding_moe_ADASYN_GP_Dirichlet_matern     NEK5_binding   ADASYN   \n",
       "28     NEK5_binding_mfp_scaled_GP_Dirichlet_matern     NEK5_binding   scaled   \n",
       "29      NEK5_binding_mfp_UNDER_GP_Dirichlet_matern     NEK5_binding    UNDER   \n",
       "30      NEK5_binding_mfp_SMOTE_GP_Dirichlet_matern     NEK5_binding    SMOTE   \n",
       "31     NEK5_binding_mfp_ADASYN_GP_Dirichlet_matern     NEK5_binding   ADASYN   \n",
       "32     NEK9_binding_moe_scaled_GP_Dirichlet_matern     NEK9_binding   scaled   \n",
       "33      NEK9_binding_moe_UNDER_GP_Dirichlet_matern     NEK9_binding    UNDER   \n",
       "34      NEK9_binding_moe_SMOTE_GP_Dirichlet_matern     NEK9_binding    SMOTE   \n",
       "35     NEK9_binding_moe_ADASYN_GP_Dirichlet_matern     NEK9_binding   ADASYN   \n",
       "36     NEK9_binding_mfp_scaled_GP_Dirichlet_matern     NEK9_binding   scaled   \n",
       "37      NEK9_binding_mfp_UNDER_GP_Dirichlet_matern     NEK9_binding    UNDER   \n",
       "38      NEK9_binding_mfp_SMOTE_GP_Dirichlet_matern     NEK9_binding    SMOTE   \n",
       "39     NEK9_binding_mfp_ADASYN_GP_Dirichlet_matern     NEK9_binding   ADASYN   \n",
       "40  NEK9_inhibition_moe_scaled_GP_Dirichlet_matern  NEK9_inhibition   scaled   \n",
       "41   NEK9_inhibition_moe_UNDER_GP_Dirichlet_matern  NEK9_inhibition    UNDER   \n",
       "42   NEK9_inhibition_moe_SMOTE_GP_Dirichlet_matern  NEK9_inhibition    SMOTE   \n",
       "43  NEK9_inhibition_moe_ADASYN_GP_Dirichlet_matern  NEK9_inhibition   ADASYN   \n",
       "44  NEK9_inhibition_mfp_scaled_GP_Dirichlet_matern  NEK9_inhibition   scaled   \n",
       "45   NEK9_inhibition_mfp_UNDER_GP_Dirichlet_matern  NEK9_inhibition    UNDER   \n",
       "46   NEK9_inhibition_mfp_SMOTE_GP_Dirichlet_matern  NEK9_inhibition    SMOTE   \n",
       "47  NEK9_inhibition_mfp_ADASYN_GP_Dirichlet_matern  NEK9_inhibition   ADASYN   \n",
       "\n",
       "   feat_type                 cm prediction_type    recall   ROC-AUC       MCC  \\\n",
       "0        moe    [271, 0, 12, 0]              TN  0.000000  0.500000  0.000000   \n",
       "1        moe    [212, 59, 5, 7]              TN  0.583333  0.682811  0.174223   \n",
       "2        moe     [270, 1, 9, 3]              TN  0.250000  0.623155  0.420460   \n",
       "3        moe     [271, 0, 9, 3]              TN  0.250000  0.625000  0.491899   \n",
       "4        mfp    [271, 0, 12, 0]              TN  0.000000  0.500000  0.000000   \n",
       "5        mfp    [4, 267, 0, 12]              FP  1.000000  0.507380  0.025196   \n",
       "6        mfp    [271, 0, 10, 2]              TN  0.166667  0.583333  0.400918   \n",
       "7        mfp    [271, 0, 10, 2]              TN  0.166667  0.583333  0.400918   \n",
       "8        moe    [381, 0, 28, 0]              TN  0.000000  0.500000  0.000000   \n",
       "9        moe   [331, 50, 6, 22]              TN  0.785714  0.827240  0.433967   \n",
       "10       moe   [378, 3, 12, 16]              TN  0.571429  0.781777  0.676189   \n",
       "11       moe   [376, 5, 12, 16]              TN  0.571429  0.779153  0.638833   \n",
       "12       mfp    [381, 0, 27, 1]              TN  0.035714  0.517857  0.182622   \n",
       "13       mfp  [100, 281, 5, 23]              TN  0.821429  0.541948  0.048501   \n",
       "14       mfp   [379, 2, 13, 15]              TN  0.535714  0.765232  0.671167   \n",
       "15       mfp   [379, 2, 13, 15]              TN  0.535714  0.765232  0.671167   \n",
       "16       moe    [265, 0, 17, 0]              TN  0.000000  0.500000  0.000000   \n",
       "17       moe  [159, 106, 5, 12]              FP  0.705882  0.652941  0.147584   \n",
       "18       moe    [259, 6, 15, 2]              TN  0.117647  0.547503  0.136200   \n",
       "19       moe    [257, 8, 15, 2]              TN  0.117647  0.543729  0.112555   \n",
       "20       mfp    [265, 0, 17, 0]              TN  0.000000  0.500000  0.000000   \n",
       "21       mfp  [125, 140, 3, 14]              FP  0.823529  0.647614  0.141136   \n",
       "22       mfp    [264, 1, 11, 6]              TN  0.352941  0.674584  0.534153   \n",
       "23       mfp    [264, 1, 12, 5]              TN  0.294118  0.645172  0.478884   \n",
       "24       moe    [228, 0, 20, 0]              TN  0.000000  0.500000  0.000000   \n",
       "25       moe   [167, 61, 4, 16]              FP  0.800000  0.766228  0.313345   \n",
       "26       moe    [225, 3, 9, 11]              FP  0.550000  0.768421  0.633369   \n",
       "27       moe   [224, 4, 10, 10]              FP  0.500000  0.741228  0.569204   \n",
       "28       mfp    [228, 0, 20, 0]              TN  0.000000  0.500000  0.000000   \n",
       "29       mfp  [118, 110, 8, 12]              FP  0.600000  0.558772  0.064020   \n",
       "30       mfp   [227, 1, 10, 10]              FP  0.500000  0.747807  0.655474   \n",
       "31       mfp    [228, 0, 12, 8]              TN  0.400000  0.700000  0.616441   \n",
       "32       moe    [270, 0, 13, 0]              TN  0.000000  0.500000  0.000000   \n",
       "33       moe    [180, 90, 5, 8]              TN  0.615385  0.641026  0.124103   \n",
       "34       moe    [268, 2, 13, 0]              TN  0.000000  0.496296 -0.018512   \n",
       "35       moe    [268, 2, 13, 0]              TN  0.000000  0.496296 -0.018512   \n",
       "36       mfp    [270, 0, 13, 0]              TN  0.000000  0.500000  0.000000   \n",
       "37       mfp   [201, 69, 10, 3]              FP  0.230769  0.487607 -0.011914   \n",
       "38       mfp    [269, 1, 13, 0]              TN  0.000000  0.498148 -0.013067   \n",
       "39       mfp    [270, 0, 13, 0]              TN  0.000000  0.500000  0.000000   \n",
       "40       moe      [71, 0, 9, 0]              TN  0.000000  0.500000  0.000000   \n",
       "41       moe      [66, 5, 2, 7]              TN  0.777778  0.853678  0.625955   \n",
       "42       moe      [70, 1, 3, 6]              TN  0.666667  0.826291  0.729752   \n",
       "43       moe      [70, 1, 2, 7]              TN  0.777778  0.881847  0.804374   \n",
       "44       mfp      [71, 0, 9, 0]              TN  0.000000  0.500000  0.000000   \n",
       "45       mfp     [53, 18, 7, 2]              FP  0.222222  0.484351 -0.022840   \n",
       "46       mfp      [70, 1, 4, 5]              TN  0.555556  0.770736  0.649582   \n",
       "47       mfp      [70, 1, 4, 5]              TN  0.555556  0.770736  0.649582   \n",
       "\n",
       "    Balanced Accuracy        f1  accuracy  precision  specificity   TN  FN  \\\n",
       "0            0.500000  0.000000  0.957597   0.000000     1.000000  271  12   \n",
       "1            0.682811  0.179487  0.773852   0.106061     0.782288  212   5   \n",
       "2            0.623155  0.375000  0.964664   0.750000     0.996310  270   9   \n",
       "3            0.625000  0.400000  0.968198   1.000000     1.000000  271   9   \n",
       "4            0.500000  0.000000  0.957597   0.000000     1.000000  271  12   \n",
       "5            0.507380  0.082474  0.056537   0.043011     0.014760    4   0   \n",
       "6            0.583333  0.285714  0.964664   1.000000     1.000000  271  10   \n",
       "7            0.583333  0.285714  0.964664   1.000000     1.000000  271  10   \n",
       "8            0.500000  0.000000  0.931540   0.000000     1.000000  381  28   \n",
       "9            0.827240  0.440000  0.863081   0.305556     0.868766  331   6   \n",
       "10           0.781777  0.680851  0.963325   0.842105     0.992126  378  12   \n",
       "11           0.779153  0.653061  0.958435   0.761905     0.986877  376  12   \n",
       "12           0.517857  0.068966  0.933985   1.000000     1.000000  381  27   \n",
       "13           0.541948  0.138554  0.300733   0.075658     0.262467  100   5   \n",
       "14           0.765232  0.666667  0.963325   0.882353     0.994751  379  13   \n",
       "15           0.765232  0.666667  0.963325   0.882353     0.994751  379  13   \n",
       "16           0.500000  0.000000  0.939716   0.000000     1.000000  265  17   \n",
       "17           0.652941  0.177778  0.606383   0.101695     0.600000  159   5   \n",
       "18           0.547503  0.160000  0.925532   0.250000     0.977358  259  15   \n",
       "19           0.543729  0.148148  0.918440   0.200000     0.969811  257  15   \n",
       "20           0.500000  0.000000  0.939716   0.000000     1.000000  265  17   \n",
       "21           0.647614  0.163743  0.492908   0.090909     0.471698  125   3   \n",
       "22           0.674584  0.500000  0.957447   0.857143     0.996226  264  11   \n",
       "23           0.645172  0.434783  0.953901   0.833333     0.996226  264  12   \n",
       "24           0.500000  0.000000  0.919355   0.000000     1.000000  228  20   \n",
       "25           0.766228  0.329897  0.737903   0.207792     0.732456  167   4   \n",
       "26           0.768421  0.647059  0.951613   0.785714     0.986842  225   9   \n",
       "27           0.741228  0.588235  0.943548   0.714286     0.982456  224  10   \n",
       "28           0.500000  0.000000  0.919355   0.000000     1.000000  228  20   \n",
       "29           0.558772  0.169014  0.524194   0.098361     0.517544  118   8   \n",
       "30           0.747807  0.645161  0.955645   0.909091     0.995614  227  10   \n",
       "31           0.700000  0.571429  0.951613   1.000000     1.000000  228  12   \n",
       "32           0.500000  0.000000  0.954064   0.000000     1.000000  270  13   \n",
       "33           0.641026  0.144144  0.664311   0.081633     0.666667  180   5   \n",
       "34           0.496296  0.000000  0.946996   0.000000     0.992593  268  13   \n",
       "35           0.496296  0.000000  0.946996   0.000000     0.992593  268  13   \n",
       "36           0.500000  0.000000  0.954064   0.000000     1.000000  270  13   \n",
       "37           0.487607  0.070588  0.720848   0.041667     0.744444  201  10   \n",
       "38           0.498148  0.000000  0.950530   0.000000     0.996296  269  13   \n",
       "39           0.500000  0.000000  0.954064   0.000000     1.000000  270  13   \n",
       "40           0.500000  0.000000  0.887500   0.000000     1.000000   71   9   \n",
       "41           0.853678  0.666667  0.912500   0.583333     0.929577   66   2   \n",
       "42           0.826291  0.750000  0.950000   0.857143     0.985915   70   3   \n",
       "43           0.881847  0.823529  0.962500   0.875000     0.985915   70   2   \n",
       "44           0.500000  0.000000  0.887500   0.000000     1.000000   71   9   \n",
       "45           0.484351  0.137931  0.687500   0.100000     0.746479   53   7   \n",
       "46           0.770736  0.666667  0.937500   0.833333     0.985915   70   4   \n",
       "47           0.770736  0.666667  0.937500   0.833333     0.985915   70   4   \n",
       "\n",
       "     FP  TP  \n",
       "0     0   0  \n",
       "1    59   7  \n",
       "2     1   3  \n",
       "3     0   3  \n",
       "4     0   0  \n",
       "5   267  12  \n",
       "6     0   2  \n",
       "7     0   2  \n",
       "8     0   0  \n",
       "9    50  22  \n",
       "10    3  16  \n",
       "11    5  16  \n",
       "12    0   1  \n",
       "13  281  23  \n",
       "14    2  15  \n",
       "15    2  15  \n",
       "16    0   0  \n",
       "17  106  12  \n",
       "18    6   2  \n",
       "19    8   2  \n",
       "20    0   0  \n",
       "21  140  14  \n",
       "22    1   6  \n",
       "23    1   5  \n",
       "24    0   0  \n",
       "25   61  16  \n",
       "26    3  11  \n",
       "27    4  10  \n",
       "28    0   0  \n",
       "29  110  12  \n",
       "30    1  10  \n",
       "31    0   8  \n",
       "32    0   0  \n",
       "33   90   8  \n",
       "34    2   0  \n",
       "35    2   0  \n",
       "36    0   0  \n",
       "37   69   3  \n",
       "38    1   0  \n",
       "39    0   0  \n",
       "40    0   0  \n",
       "41    5   7  \n",
       "42    1   6  \n",
       "43    1   7  \n",
       "44    0   0  \n",
       "45   18   2  \n",
       "46    1   5  \n",
       "47    1   5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(GP_path+'GP_maternkern_test_results.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ee53c-f735-4673-9418-381eb7d8dc81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch-venv",
   "language": "python",
   "name": "gpytorch-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
