{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44f45b88-5313-4030-9dbe-a4b4ef5b2053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix, f1_score, roc_curve,precision_recall_curve, auc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from RF_GSCV import * # RF_GSCV contains the calculate metrics function to get the TP, TN, FP, FN scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10403267-c199-43db-859f-8bf41e1ae50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DirichletGPModel(ExactGP):\n",
    "    \"\"\"\n",
    "    A Dirichlet Gaussian Process (GP) model for multi-class classification.\n",
    "\n",
    "    This model uses a Gaussian Process with a Dirichlet prior to handle multi-class classification tasks.\n",
    "    It extends the ExactGP class from GPyTorch, a library for Gaussian Processes in PyTorch.\n",
    "\n",
    "    Attributes:\n",
    "        mean_module (gpytorch.means.ConstantMean): The mean module for the GP, initialized with a constant mean function for each class.\n",
    "        covar_module (gpytorch.kernels.ScaleKernel): The covariance module for the GP, using a scaled RBF kernel for each class.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training data features.\n",
    "        train_y (torch.Tensor): Training data labels.\n",
    "        likelihood (gpytorch.likelihoods.Likelihood): The likelihood function.\n",
    "        num_classes (int): The number of classes for the classification task.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the GP model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data features.\n",
    "\n",
    "        Returns:\n",
    "            gpytorch.distributions.MultivariateNormal: The multivariate normal distribution representing the GP posterior.\n",
    "        \"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdb81028-fc87-4351-b233-6a0e03c5be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self,model, likelihood, iterations): \n",
    "        self.model = model\n",
    "        self.likelihood = likelihood \n",
    "        smoke_test = ('CI' in os.environ)\n",
    "        self.n_iterations = 2 if smoke_test else iterations\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        self.loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "    def train(self, train_x, train_y): \n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        predictions = [] \n",
    "        for i in range(self.n_iterations): \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(train_x)\n",
    "            loss = -self.loss_fn(output, self.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if (i%10==0): \n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, self.n_iterations, loss.item(),\n",
    "                    self.model.covar_module.base_kernel.lengthscale.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "             \n",
    "          \n",
    "            self.optimizer.step() \n",
    "\n",
    "\n",
    "    def predict(self, input): \n",
    "        \"\"\"\n",
    "        Make predictions using the GP model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input data for making predictions.\n",
    "        \n",
    "        Returns:\n",
    "            dist (gpytorch.distributions.MultivariateNormal): The distribution representing the GP posterior.\n",
    "            observed_pred (gpytorch.distributions.MultivariateNormal): The predicted distribution considering the likelihood.\n",
    "            pred_means (torch.Tensor): The means of the predicted distributions.\n",
    "            class_pred (torch.Tensor): The predicted class labels.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            dist = self.model(input)     # output distribution\n",
    "            pred_means = dist.loc          # means of distributino \n",
    "            observed_pred = self.likelihood(self.model(input))    # likelihood predictions mean and var  \n",
    "\n",
    "            class_pred = self.model(input).loc.max(0)[1]\n",
    "            \n",
    "        return dist, observed_pred, pred_means, class_pred\n",
    "    \n",
    "\n",
    "    def evaluate(self, x_input, y_true): \n",
    "        \"\"\"\n",
    "        Evaluate the GP model.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor): The true labels for the input data.\n",
    "        \n",
    "        Returns:\n",
    "            y_pred (numpy.ndarray): The predicted class labels.\n",
    "        \"\"\"\n",
    "        y_pred = self.model(x_input).loc.max(0)[1].numpy()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def gp_results(self, x_input, y_true, plot_title=None): \n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics and print results.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor or numpy.ndarray): The true labels for the input data.\n",
    "            plot_title (str, optional): The title for the confusion matrix plot.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing evaluation metrics and confusion matrix components.\n",
    "        \"\"\"\n",
    "        y_pred = self.evaluate(x_input, y_true) \n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.numpy().reshape(-1)\n",
    "        # plot_confusion_matrix(y_true, y_pred, ['0','1'], title=plot_title)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        dist = self.model(x_input)     # get predicted distributions \n",
    "        pred_means = dist.loc          # means for predicted dist  \n",
    "\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        tp, tn, fp, fn = calculate_metrics(y_true, y_pred) \n",
    "        sensitivity = tp / (tp + fn) \n",
    "        specificity = tn / (tn + fp) \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, specificity: {specificity:.4f}, cm: {cm}')\n",
    "        return {'accuracy': accuracy, 'precision': precision,  'recall':recall, 'specificity':specificity, 'TN': tn, 'FN': fn, 'FP': fp, 'TP': tp }\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cca1671-8d28-42b6-b01a-bae15caa4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_torch_tens(filepath, filename): \n",
    "    trainX_df = pd.read_csv(filepath+filename+'_trainX.csv')\n",
    "    trainy_df = pd.read_csv(filepath+filename+'_train_y.csv')\n",
    "    testX_df = pd.read_csv(filepath+filename+'_testX.csv')\n",
    "    testy_df = pd.read_csv(filepath+filename+'_test_y.csv')\n",
    "\n",
    "    train_x_temp = trainX_df.to_numpy().astype(\"long\")\n",
    "    test_x_temp = testX_df.to_numpy().astype(\"long\")\n",
    "    \n",
    "    train_y_temp = trainy_df.to_numpy().flatten().astype(\"long\")\n",
    "    test_y_temp = testy_df.to_numpy().flatten().astype(\"long\")\n",
    "    \n",
    "    trainX = torch.from_numpy(train_x_temp)\n",
    "    trainy = torch.from_numpy(train_y_temp)\n",
    "    testX = torch.from_numpy(test_x_temp)\n",
    "    testy = torch.from_numpy(test_y_temp)\n",
    "    print(f'train X: {trainX.shape}, train y: {trainy.shape}, test X: {testX.shape}, test y: {testy.shape}')\n",
    "    return trainX, trainy, testX, testy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43e2d7ce-3d0c-485e-8e20-e4f44d646efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(trainX, trainy, testX, testy, root_name, n_iterations=300, n_samples=100):\n",
    "    \"\"\"\n",
    "    Train a Dirichlet Gaussian Process model and save the training and test performance results.\n",
    "\n",
    "    This function trains a Dirichlet GP model on the given training data, evaluates it on both the training\n",
    "    and test data, and saves various performance metrics and predictions to pandas DataFrames.\n",
    "\n",
    "    Args:\n",
    "        trainX (torch.Tensor): The training data features.\n",
    "        trainy (torch.Tensor): The training data labels.\n",
    "        testX (torch.Tensor): The test data features.\n",
    "        testy (torch.Tensor): The test data labels.\n",
    "        root_name (str): The root name used for labeling the model in the results.\n",
    "        n_iterations (int, optional): The number of training iterations. Default is 300.\n",
    "        n_samples (int, optional): The number of samples for prediction. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "        train_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the training data.\n",
    "        test_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the test data.\n",
    "    \"\"\"\n",
    "    likelihood = DirichletClassificationLikelihood(trainy, learn_additional_noise=True)\n",
    "    model = DirichletGPModel(trainX, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "    # n_iterations = 300\n",
    "    trainer = Trainer(model, likelihood, n_iterations)\n",
    "    trainer.train(trainX, trainy) \n",
    "  \n",
    "    train_dist, train_observed_pred, train_pred_means, train_pred  = trainer.predict(trainX)\n",
    "    train_results = trainer.gp_results(trainX, trainy)\n",
    "    test_dist, test_observed_pred, test_pred_means, test_pred  = trainer.predict(testX)\n",
    "    test_results = trainer.gp_results(testX, testy)\n",
    "    \n",
    "    train_observed_pred.mean.numpy()\n",
    "    train_pred_variance2D = train_observed_pred.variance.numpy()\n",
    "    test_observed_pred.mean.numpy()\n",
    "    test_pred_variance2D=test_observed_pred.variance.numpy()\n",
    "    \n",
    "    train_pred_samples = train_dist.sample(torch.Size((256,))).exp()\n",
    "    train_probabilities = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "\n",
    "    train_prob_stds = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    "    \n",
    "\n",
    "    test_pred_samples = test_dist.sample(torch.Size((100,))).exp()\n",
    "\n",
    "    test_probabilities = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "    test_prob_stds = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    " \n",
    "    train_perf_df = pd.DataFrame()\n",
    "    test_perf_df = pd.DataFrame()\n",
    "    train_perf_df['mean_pred_class0'] = train_observed_pred.mean.numpy()[0,]\n",
    "    train_perf_df['mean_pred_class1'] = train_observed_pred.mean.numpy()[1,]\n",
    "    train_perf_df['y'] = trainy\n",
    "    train_perf_df['y_pred'] = train_pred_means.max(0)[1]\n",
    "    train_perf_df['var_pred_class0']=train_observed_pred.variance.numpy()[0,]\n",
    "    train_perf_df['var_pred_class1']=train_observed_pred.variance.numpy()[1,]\n",
    "    train_perf_df['pred_prob_class0'] = train_probabilities.numpy()[0,]\n",
    "    train_perf_df['pred_prob_class1'] = train_probabilities.numpy()[1,]\n",
    "    train_perf_df['pred_prob_std_class0'] = train_prob_stds.numpy()[0,]\n",
    "    train_perf_df['pred_prob_std_class1'] = train_prob_stds.numpy()[1,]\n",
    "    \n",
    "    train_perf_df['model'] = f'{root_name}_GP'\n",
    "    train_perf_df['subset'] = 'train' \n",
    "    \n",
    "    \n",
    "    test_perf_df['mean_pred_class0'] = test_observed_pred.mean.numpy()[0,]\n",
    "    test_perf_df['mean_pred_class1'] = test_observed_pred.mean.numpy()[1,]\n",
    "    test_perf_df['y'] = testy\n",
    "    test_perf_df['y_pred'] = test_pred_means.max(0)[1]\n",
    "    test_perf_df['var_pred_class0']=test_observed_pred.variance.numpy()[0,]\n",
    "    test_perf_df['var_pred_class1']=test_observed_pred.variance.numpy()[1,]\n",
    "    test_perf_df['pred_prob_class0'] = test_probabilities.numpy()[0,]\n",
    "    test_perf_df['pred_prob_class1'] = test_probabilities.numpy()[1,]\n",
    "    test_perf_df['pred_prob_std_class0'] =test_prob_stds.numpy()[0,]\n",
    "    test_perf_df['pred_prob_std_class1'] = test_prob_stds.numpy()[1,]\n",
    "    test_perf_df['model'] = f'{root_name}_GP'\n",
    "    test_perf_df['subset'] = 'test' \n",
    "    for k, val in train_results.items(): \n",
    "        train_perf_df[k] = val\n",
    "    for k, val in test_results.items():\n",
    "        test_perf_df[k] = val\n",
    "    return train_perf_df, test_perf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "290632ba-20c3-4e47-bb2b-de11524ea402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "\n",
      "moe scaled\n",
      "train X: torch.Size([1125, 306]), train y: torch.Size([1125]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.484   lengthscale: 1.037   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.490   lengthscale: 1.398   noise: 1.073\n",
      "Iter 31/300 - Loss: 3.896   lengthscale: 1.910   noise: 1.331\n",
      "Iter 41/300 - Loss: 3.464   lengthscale: 2.568   noise: 1.482\n",
      "Iter 51/300 - Loss: 3.290   lengthscale: 3.195   noise: 1.511\n",
      "Iter 61/300 - Loss: 3.229   lengthscale: 3.633   noise: 1.458\n",
      "Iter 71/300 - Loss: 3.199   lengthscale: 3.927   noise: 1.362\n",
      "Iter 81/300 - Loss: 3.174   lengthscale: 4.136   noise: 1.250\n",
      "Iter 91/300 - Loss: 3.159   lengthscale: 4.295   noise: 1.133\n",
      "Iter 101/300 - Loss: 3.143   lengthscale: 4.421   noise: 1.020\n",
      "Iter 111/300 - Loss: 3.140   lengthscale: 4.530   noise: 0.917\n",
      "Iter 121/300 - Loss: 3.126   lengthscale: 4.622   noise: 0.829\n",
      "Iter 131/300 - Loss: 3.118   lengthscale: 4.700   noise: 0.756\n",
      "Iter 141/300 - Loss: 3.119   lengthscale: 4.765   noise: 0.701\n",
      "Iter 151/300 - Loss: 3.112   lengthscale: 4.819   noise: 0.661\n",
      "Iter 161/300 - Loss: 3.110   lengthscale: 4.864   noise: 0.634\n",
      "Iter 171/300 - Loss: 3.107   lengthscale: 4.900   noise: 0.617\n",
      "Iter 181/300 - Loss: 3.108   lengthscale: 4.929   noise: 0.608\n",
      "Iter 191/300 - Loss: 3.101   lengthscale: 4.952   noise: 0.605\n",
      "Iter 201/300 - Loss: 3.106   lengthscale: 4.969   noise: 0.606\n",
      "Iter 211/300 - Loss: 3.103   lengthscale: 4.982   noise: 0.609\n",
      "Iter 221/300 - Loss: 3.101   lengthscale: 4.991   noise: 0.614\n",
      "Iter 231/300 - Loss: 3.097   lengthscale: 4.997   noise: 0.619\n",
      "Iter 241/300 - Loss: 3.107   lengthscale: 5.002   noise: 0.625\n",
      "Iter 251/300 - Loss: 3.094   lengthscale: 5.005   noise: 0.630\n",
      "Iter 261/300 - Loss: 3.092   lengthscale: 5.007   noise: 0.635\n",
      "Iter 271/300 - Loss: 3.098   lengthscale: 5.006   noise: 0.640\n",
      "Iter 281/300 - Loss: 3.097   lengthscale: 5.004   noise: 0.643\n",
      "Iter 291/300 - Loss: 3.093   lengthscale: 4.998   noise: 0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9600, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1080    0]\n",
      " [  45    0]]\n",
      "accuracy: 0.9576, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[271   0]\n",
      " [ 12   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n",
      "train X: torch.Size([90, 306]), train y: torch.Size([90]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.887   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.439   lengthscale: 1.231   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.262   lengthscale: 1.918   noise: 2.574\n",
      "Iter 41/300 - Loss: 5.199   lengthscale: 2.952   noise: 3.007\n",
      "Iter 51/300 - Loss: 5.173   lengthscale: 4.160   noise: 3.297\n",
      "Iter 61/300 - Loss: 5.154   lengthscale: 5.325   noise: 3.464\n",
      "Iter 71/300 - Loss: 5.140   lengthscale: 6.303   noise: 3.524\n",
      "Iter 81/300 - Loss: 5.133   lengthscale: 7.003   noise: 3.513\n",
      "Iter 91/300 - Loss: 5.129   lengthscale: 7.395   noise: 3.463\n",
      "Iter 101/300 - Loss: 5.125   lengthscale: 7.557   noise: 3.393\n",
      "Iter 111/300 - Loss: 5.122   lengthscale: 7.603   noise: 3.306\n",
      "Iter 121/300 - Loss: 5.119   lengthscale: 7.615   noise: 3.202\n",
      "Iter 131/300 - Loss: 5.116   lengthscale: 7.636   noise: 3.083\n",
      "Iter 141/300 - Loss: 5.114   lengthscale: 7.671   noise: 2.953\n",
      "Iter 151/300 - Loss: 5.111   lengthscale: 7.708   noise: 2.816\n",
      "Iter 161/300 - Loss: 5.109   lengthscale: 7.733   noise: 2.675\n",
      "Iter 171/300 - Loss: 5.106   lengthscale: 7.743   noise: 2.532\n",
      "Iter 181/300 - Loss: 5.104   lengthscale: 7.744   noise: 2.388\n",
      "Iter 191/300 - Loss: 5.102   lengthscale: 7.740   noise: 2.242\n",
      "Iter 201/300 - Loss: 5.099   lengthscale: 7.734   noise: 2.097\n",
      "Iter 211/300 - Loss: 5.097   lengthscale: 7.725   noise: 1.952\n",
      "Iter 221/300 - Loss: 5.095   lengthscale: 7.713   noise: 1.809\n",
      "Iter 231/300 - Loss: 5.093   lengthscale: 7.700   noise: 1.669\n",
      "Iter 241/300 - Loss: 5.091   lengthscale: 7.688   noise: 1.534\n",
      "Iter 251/300 - Loss: 5.089   lengthscale: 7.676   noise: 1.404\n",
      "Iter 261/300 - Loss: 5.087   lengthscale: 7.665   noise: 1.281\n",
      "Iter 271/300 - Loss: 5.085   lengthscale: 7.657   noise: 1.166\n",
      "Iter 281/300 - Loss: 5.083   lengthscale: 7.652   noise: 1.059\n",
      "Iter 291/300 - Loss: 5.082   lengthscale: 7.650   noise: 0.961\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[45  0]\n",
      " [ 0 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7385, precision: 0.1026, recall: 0.6667, specificity: 0.7417, cm: [[201  70]\n",
      " [  4   8]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n",
      "train X: torch.Size([2160, 306]), train y: torch.Size([2160]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.994   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.640   lengthscale: 1.321   noise: 1.278\n",
      "Iter 21/300 - Loss: 4.908   lengthscale: 2.196   noise: 1.720\n",
      "Iter 31/300 - Loss: 4.490   lengthscale: 3.216   noise: 1.657\n",
      "Iter 41/300 - Loss: 4.153   lengthscale: 4.215   noise: 1.189\n",
      "Iter 51/300 - Loss: 3.897   lengthscale: 5.062   noise: 0.638\n",
      "Iter 61/300 - Loss: 3.729   lengthscale: 5.660   noise: 0.277\n",
      "Iter 71/300 - Loss: 3.650   lengthscale: 6.038   noise: 0.125\n",
      "Iter 81/300 - Loss: 3.607   lengthscale: 6.261   noise: 0.071\n",
      "Iter 91/300 - Loss: 3.586   lengthscale: 6.382   noise: 0.048\n",
      "Iter 101/300 - Loss: 3.577   lengthscale: 6.440   noise: 0.036\n",
      "Iter 111/300 - Loss: 3.569   lengthscale: 6.464   noise: 0.030\n",
      "Iter 121/300 - Loss: 3.567   lengthscale: 6.468   noise: 0.025\n",
      "Iter 131/300 - Loss: 3.561   lengthscale: 6.466   noise: 0.022\n",
      "Iter 141/300 - Loss: 3.567   lengthscale: 6.461   noise: 0.019\n",
      "Iter 151/300 - Loss: 3.565   lengthscale: 6.455   noise: 0.017\n",
      "Iter 161/300 - Loss: 3.557   lengthscale: 6.445   noise: 0.015\n",
      "Iter 171/300 - Loss: 3.549   lengthscale: 6.421   noise: 0.014\n",
      "Iter 181/300 - Loss: 3.559   lengthscale: 6.391   noise: 0.013\n",
      "Iter 191/300 - Loss: 3.557   lengthscale: 6.357   noise: 0.012\n",
      "Iter 201/300 - Loss: 3.540   lengthscale: 6.319   noise: 0.011\n",
      "Iter 211/300 - Loss: 3.547   lengthscale: 6.274   noise: 0.010\n",
      "Iter 221/300 - Loss: 3.537   lengthscale: 6.224   noise: 0.009\n",
      "Iter 231/300 - Loss: 3.530   lengthscale: 6.172   noise: 0.009\n",
      "Iter 241/300 - Loss: 3.536   lengthscale: 6.116   noise: 0.008\n",
      "Iter 251/300 - Loss: 3.534   lengthscale: 6.063   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.527   lengthscale: 6.011   noise: 0.007\n",
      "Iter 271/300 - Loss: 3.525   lengthscale: 5.962   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.531   lengthscale: 5.923   noise: 0.006\n",
      "Iter 291/300 - Loss: 3.519   lengthscale: 5.888   noise: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9991, precision: 0.9982, recall: 1.0000, specificity: 0.9981, cm: [[1078    2]\n",
      " [   0 1080]]\n",
      "accuracy: 0.9682, precision: 0.8000, recall: 0.3333, specificity: 0.9963, cm: [[270   1]\n",
      " [  8   4]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([2158, 306]), train y: torch.Size([2158]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.026   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.724   lengthscale: 1.321   noise: 1.285\n",
      "Iter 21/300 - Loss: 4.978   lengthscale: 2.204   noise: 1.793\n",
      "Iter 31/300 - Loss: 4.539   lengthscale: 3.263   noise: 1.803\n",
      "Iter 41/300 - Loss: 4.196   lengthscale: 4.296   noise: 1.351\n",
      "Iter 51/300 - Loss: 3.955   lengthscale: 5.165   noise: 0.756\n",
      "Iter 61/300 - Loss: 3.779   lengthscale: 5.780   noise: 0.338\n",
      "Iter 71/300 - Loss: 3.695   lengthscale: 6.170   noise: 0.152\n",
      "Iter 81/300 - Loss: 3.654   lengthscale: 6.398   noise: 0.084\n",
      "Iter 91/300 - Loss: 3.625   lengthscale: 6.516   noise: 0.056\n",
      "Iter 101/300 - Loss: 3.624   lengthscale: 6.567   noise: 0.042\n",
      "Iter 111/300 - Loss: 3.622   lengthscale: 6.578   noise: 0.034\n",
      "Iter 121/300 - Loss: 3.609   lengthscale: 6.571   noise: 0.028\n",
      "Iter 131/300 - Loss: 3.596   lengthscale: 6.556   noise: 0.024\n",
      "Iter 141/300 - Loss: 3.591   lengthscale: 6.542   noise: 0.022\n",
      "Iter 151/300 - Loss: 3.595   lengthscale: 6.525   noise: 0.019\n",
      "Iter 161/300 - Loss: 3.584   lengthscale: 6.505   noise: 0.017\n",
      "Iter 171/300 - Loss: 3.580   lengthscale: 6.484   noise: 0.016\n",
      "Iter 181/300 - Loss: 3.585   lengthscale: 6.455   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.578   lengthscale: 6.418   noise: 0.013\n",
      "Iter 201/300 - Loss: 3.579   lengthscale: 6.376   noise: 0.012\n",
      "Iter 211/300 - Loss: 3.575   lengthscale: 6.331   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.570   lengthscale: 6.285   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.555   lengthscale: 6.235   noise: 0.010\n",
      "Iter 241/300 - Loss: 3.570   lengthscale: 6.176   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.565   lengthscale: 6.117   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.558   lengthscale: 6.061   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.555   lengthscale: 6.015   noise: 0.008\n",
      "Iter 281/300 - Loss: 3.558   lengthscale: 5.976   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.546   lengthscale: 5.951   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9986, precision: 0.9972, recall: 1.0000, specificity: 0.9972, cm: [[1077    3]\n",
      " [   0 1078]]\n",
      "accuracy: 0.9611, precision: 0.5714, recall: 0.3333, specificity: 0.9889, cm: [[268   3]\n",
      " [  8   4]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([1125, 2048]), train y: torch.Size([1125]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.095   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.467   lengthscale: 1.253   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.324   lengthscale: 2.070   noise: 1.067\n",
      "Iter 31/300 - Loss: 3.335   lengthscale: 3.153   noise: 1.261\n",
      "Iter 41/300 - Loss: 3.187   lengthscale: 4.190   noise: 1.288\n",
      "Iter 51/300 - Loss: 3.144   lengthscale: 4.945   noise: 1.222\n",
      "Iter 61/300 - Loss: 3.121   lengthscale: 5.495   noise: 1.114\n",
      "Iter 71/300 - Loss: 3.105   lengthscale: 5.903   noise: 0.990\n",
      "Iter 81/300 - Loss: 3.088   lengthscale: 6.221   noise: 0.865\n",
      "Iter 91/300 - Loss: 3.073   lengthscale: 6.480   noise: 0.748\n",
      "Iter 101/300 - Loss: 3.062   lengthscale: 6.694   noise: 0.644\n",
      "Iter 111/300 - Loss: 3.055   lengthscale: 6.879   noise: 0.558\n",
      "Iter 121/300 - Loss: 3.055   lengthscale: 7.042   noise: 0.490\n",
      "Iter 131/300 - Loss: 3.047   lengthscale: 7.190   noise: 0.438\n",
      "Iter 141/300 - Loss: 3.055   lengthscale: 7.323   noise: 0.400\n",
      "Iter 151/300 - Loss: 3.043   lengthscale: 7.445   noise: 0.371\n",
      "Iter 161/300 - Loss: 3.042   lengthscale: 7.555   noise: 0.350\n",
      "Iter 171/300 - Loss: 3.039   lengthscale: 7.657   noise: 0.334\n",
      "Iter 181/300 - Loss: 3.045   lengthscale: 7.753   noise: 0.322\n",
      "Iter 191/300 - Loss: 3.039   lengthscale: 7.838   noise: 0.312\n",
      "Iter 201/300 - Loss: 3.043   lengthscale: 7.918   noise: 0.304\n",
      "Iter 211/300 - Loss: 3.034   lengthscale: 7.993   noise: 0.298\n",
      "Iter 221/300 - Loss: 3.046   lengthscale: 8.062   noise: 0.293\n",
      "Iter 231/300 - Loss: 3.040   lengthscale: 8.125   noise: 0.289\n",
      "Iter 241/300 - Loss: 3.033   lengthscale: 8.185   noise: 0.284\n",
      "Iter 251/300 - Loss: 3.039   lengthscale: 8.245   noise: 0.279\n",
      "Iter 261/300 - Loss: 3.035   lengthscale: 8.301   noise: 0.275\n",
      "Iter 271/300 - Loss: 3.041   lengthscale: 8.354   noise: 0.271\n",
      "Iter 281/300 - Loss: 3.039   lengthscale: 8.405   noise: 0.268\n",
      "Iter 291/300 - Loss: 3.037   lengthscale: 8.453   noise: 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9600, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1080    0]\n",
      " [  45    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9576, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[271   0]\n",
      " [ 12   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([90, 2048]), train y: torch.Size([90]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.932   lengthscale: 0.669   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.343   noise: 1.983\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.242   noise: 2.577\n",
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.210   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.198   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.194   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.192   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.192   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.192   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.192   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.896\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.894\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.893\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.191   noise: 3.892\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[45  0]\n",
      " [ 0 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 0.9963, cm: [[270   1]\n",
      " [ 12   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n",
      "train X: torch.Size([2160, 2048]), train y: torch.Size([2160]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.066   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.839   lengthscale: 1.312   noise: 0.795\n",
      "Iter 21/300 - Loss: 4.192   lengthscale: 2.141   noise: 0.884\n",
      "Iter 31/300 - Loss: 3.667   lengthscale: 2.992   noise: 0.621\n",
      "Iter 41/300 - Loss: 3.421   lengthscale: 3.663   noise: 0.288\n",
      "Iter 51/300 - Loss: 3.303   lengthscale: 4.036   noise: 0.115\n",
      "Iter 61/300 - Loss: 3.254   lengthscale: 4.206   noise: 0.054\n",
      "Iter 71/300 - Loss: 3.232   lengthscale: 4.268   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.220   lengthscale: 4.291   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.212   lengthscale: 4.317   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.209   lengthscale: 4.345   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.206   lengthscale: 4.365   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.206   lengthscale: 4.378   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.210   lengthscale: 4.389   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.208   lengthscale: 4.400   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.205   lengthscale: 4.412   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.193   lengthscale: 4.422   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.199   lengthscale: 4.431   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.199   lengthscale: 4.440   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.193   lengthscale: 4.450   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.199   lengthscale: 4.459   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.191   lengthscale: 4.466   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.197   lengthscale: 4.471   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.189   lengthscale: 4.475   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.195   lengthscale: 4.477   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.191   lengthscale: 4.478   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.198   lengthscale: 4.478   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.186   lengthscale: 4.478   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.195   lengthscale: 4.481   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.189   lengthscale: 4.481   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9931, precision: 0.9991, recall: 0.9870, specificity: 0.9991, cm: [[1079    1]\n",
      " [  14 1066]]\n",
      "accuracy: 0.9647, precision: 1.0000, recall: 0.1667, specificity: 1.0000, cm: [[271   0]\n",
      " [ 10   2]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: torch.Size([2168, 2048]), train y: torch.Size([2168]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.114   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.858   lengthscale: 1.307   noise: 0.795\n",
      "Iter 21/300 - Loss: 4.199   lengthscale: 2.133   noise: 0.880\n",
      "Iter 31/300 - Loss: 3.689   lengthscale: 2.982   noise: 0.613\n",
      "Iter 41/300 - Loss: 3.434   lengthscale: 3.654   noise: 0.282\n",
      "Iter 51/300 - Loss: 3.325   lengthscale: 4.029   noise: 0.112\n",
      "Iter 61/300 - Loss: 3.265   lengthscale: 4.203   noise: 0.053\n",
      "Iter 71/300 - Loss: 3.241   lengthscale: 4.267   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.234   lengthscale: 4.284   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.221   lengthscale: 4.300   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.220   lengthscale: 4.323   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.218   lengthscale: 4.342   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.214   lengthscale: 4.356   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.211   lengthscale: 4.368   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.207   lengthscale: 4.381   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.215   lengthscale: 4.392   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.212   lengthscale: 4.404   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.210   lengthscale: 4.415   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.213   lengthscale: 4.425   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.209   lengthscale: 4.435   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.205   lengthscale: 4.442   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.204   lengthscale: 4.449   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.211   lengthscale: 4.457   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.202   lengthscale: 4.462   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.210   lengthscale: 4.464   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.208   lengthscale: 4.467   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.201   lengthscale: 4.467   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.206   lengthscale: 4.466   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.206   lengthscale: 4.462   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.200   lengthscale: 4.458   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9940, precision: 0.9991, recall: 0.9890, specificity: 0.9991, cm: [[1079    1]\n",
      " [  12 1076]]\n",
      "accuracy: 0.9647, precision: 1.0000, recall: 0.1667, specificity: 1.0000, cm: [[271   0]\n",
      " [ 10   2]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/bind/NEK2_binding_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "\n",
      "moe scaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: torch.Size([1635, 306]), train y: torch.Size([1635]), test X: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.101   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.536   lengthscale: 1.258   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.581   lengthscale: 2.057   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.926   lengthscale: 3.125   noise: 1.320\n",
      "Iter 41/300 - Loss: 3.560   lengthscale: 4.403   noise: 1.448\n",
      "Iter 51/300 - Loss: 3.426   lengthscale: 5.619   noise: 1.451\n",
      "Iter 61/300 - Loss: 3.373   lengthscale: 6.576   noise: 1.377\n",
      "Iter 71/300 - Loss: 3.349   lengthscale: 7.284   noise: 1.263\n",
      "Iter 81/300 - Loss: 3.325   lengthscale: 7.797   noise: 1.132\n",
      "Iter 91/300 - Loss: 3.303   lengthscale: 8.191   noise: 0.995\n",
      "Iter 101/300 - Loss: 3.285   lengthscale: 8.508   noise: 0.860\n",
      "Iter 111/300 - Loss: 3.274   lengthscale: 8.770   noise: 0.738\n",
      "Iter 121/300 - Loss: 3.260   lengthscale: 8.992   noise: 0.632\n",
      "Iter 131/300 - Loss: 3.255   lengthscale: 9.185   noise: 0.544\n",
      "Iter 141/300 - Loss: 3.254   lengthscale: 9.352   noise: 0.474\n",
      "Iter 151/300 - Loss: 3.248   lengthscale: 9.499   noise: 0.418\n",
      "Iter 161/300 - Loss: 3.239   lengthscale: 9.630   noise: 0.374\n",
      "Iter 171/300 - Loss: 3.240   lengthscale: 9.749   noise: 0.340\n",
      "Iter 181/300 - Loss: 3.240   lengthscale: 9.855   noise: 0.312\n",
      "Iter 191/300 - Loss: 3.235   lengthscale: 9.948   noise: 0.290\n",
      "Iter 201/300 - Loss: 3.237   lengthscale: 10.028   noise: 0.271\n",
      "Iter 211/300 - Loss: 3.239   lengthscale: 10.109   noise: 0.254\n",
      "Iter 221/300 - Loss: 3.237   lengthscale: 10.181   noise: 0.239\n",
      "Iter 231/300 - Loss: 3.234   lengthscale: 10.243   noise: 0.226\n",
      "Iter 241/300 - Loss: 3.229   lengthscale: 10.299   noise: 0.214\n",
      "Iter 251/300 - Loss: 3.235   lengthscale: 10.347   noise: 0.202\n",
      "Iter 261/300 - Loss: 3.235   lengthscale: 10.390   noise: 0.191\n",
      "Iter 271/300 - Loss: 3.225   lengthscale: 10.429   noise: 0.181\n",
      "Iter 281/300 - Loss: 3.224   lengthscale: 10.466   noise: 0.172\n",
      "Iter 291/300 - Loss: 3.228   lengthscale: 10.501   noise: 0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9333, precision: 1.0000, recall: 0.0268, specificity: 1.0000, cm: [[1523    0]\n",
      " [ 109    3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9315, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[381   0]\n",
      " [ 28   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n",
      "train X: torch.Size([224, 306]), train y: torch.Size([224]), test X: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.930   lengthscale: 1.255   noise: 1.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21/300 - Loss: 5.435   lengthscale: 2.072   noise: 1.981\n",
      "Iter 31/300 - Loss: 5.222   lengthscale: 3.129   noise: 2.563\n",
      "Iter 41/300 - Loss: 5.027   lengthscale: 4.443   noise: 2.911\n",
      "Iter 51/300 - Loss: 4.891   lengthscale: 5.804   noise: 2.925\n",
      "Iter 61/300 - Loss: 4.818   lengthscale: 6.903   noise: 2.657\n",
      "Iter 71/300 - Loss: 4.773   lengthscale: 7.686   noise: 2.238\n",
      "Iter 81/300 - Loss: 4.740   lengthscale: 8.221   noise: 1.778\n",
      "Iter 91/300 - Loss: 4.714   lengthscale: 8.580   noise: 1.354\n",
      "Iter 101/300 - Loss: 4.693   lengthscale: 8.814   noise: 1.009\n",
      "Iter 111/300 - Loss: 4.677   lengthscale: 8.964   noise: 0.751\n",
      "Iter 121/300 - Loss: 4.665   lengthscale: 9.059   noise: 0.566\n",
      "Iter 131/300 - Loss: 4.656   lengthscale: 9.124   noise: 0.436\n",
      "Iter 141/300 - Loss: 4.649   lengthscale: 9.179   noise: 0.343\n",
      "Iter 151/300 - Loss: 4.643   lengthscale: 9.234   noise: 0.275\n",
      "Iter 161/300 - Loss: 4.639   lengthscale: 9.293   noise: 0.225\n",
      "Iter 171/300 - Loss: 4.636   lengthscale: 9.358   noise: 0.188\n",
      "Iter 181/300 - Loss: 4.634   lengthscale: 9.425   noise: 0.160\n",
      "Iter 191/300 - Loss: 4.632   lengthscale: 9.493   noise: 0.138\n",
      "Iter 201/300 - Loss: 4.630   lengthscale: 9.559   noise: 0.121\n",
      "Iter 211/300 - Loss: 4.629   lengthscale: 9.622   noise: 0.107\n",
      "Iter 221/300 - Loss: 4.628   lengthscale: 9.681   noise: 0.095\n",
      "Iter 231/300 - Loss: 4.627   lengthscale: 9.737   noise: 0.086\n",
      "Iter 241/300 - Loss: 4.626   lengthscale: 9.788   noise: 0.078\n",
      "Iter 251/300 - Loss: 4.625   lengthscale: 9.837   noise: 0.071\n",
      "Iter 261/300 - Loss: 4.625   lengthscale: 9.882   noise: 0.065\n",
      "Iter 271/300 - Loss: 4.624   lengthscale: 9.925   noise: 0.060\n",
      "Iter 281/300 - Loss: 4.624   lengthscale: 9.965   noise: 0.056\n",
      "Iter 291/300 - Loss: 4.623   lengthscale: 10.003   noise: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[112   0]\n",
      " [  0 112]]\n",
      "accuracy: 0.8655, precision: 0.3099, recall: 0.7857, specificity: 0.8714, cm: [[332  49]\n",
      " [  6  22]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n",
      "train X: torch.Size([3046, 306]), train y: torch.Size([3046]), test X: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.036   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.751   lengthscale: 1.320   noise: 1.287\n",
      "Iter 21/300 - Loss: 5.004   lengthscale: 2.197   noise: 1.814\n",
      "Iter 31/300 - Loss: 4.498   lengthscale: 3.271   noise: 1.834\n",
      "Iter 41/300 - Loss: 4.148   lengthscale: 4.324   noise: 1.350\n",
      "Iter 51/300 - Loss: 3.907   lengthscale: 5.168   noise: 0.742\n",
      "Iter 61/300 - Loss: 3.757   lengthscale: 5.782   noise: 0.331\n",
      "Iter 71/300 - Loss: 3.660   lengthscale: 6.222   noise: 0.151\n",
      "Iter 81/300 - Loss: 3.615   lengthscale: 6.532   noise: 0.083\n",
      "Iter 91/300 - Loss: 3.591   lengthscale: 6.753   noise: 0.056\n",
      "Iter 101/300 - Loss: 3.585   lengthscale: 6.908   noise: 0.042\n",
      "Iter 111/300 - Loss: 3.567   lengthscale: 7.017   noise: 0.033\n",
      "Iter 121/300 - Loss: 3.568   lengthscale: 7.094   noise: 0.028\n",
      "Iter 131/300 - Loss: 3.569   lengthscale: 7.157   noise: 0.024\n",
      "Iter 141/300 - Loss: 3.561   lengthscale: 7.207   noise: 0.021\n",
      "Iter 151/300 - Loss: 3.563   lengthscale: 7.251   noise: 0.019\n",
      "Iter 161/300 - Loss: 3.559   lengthscale: 7.289   noise: 0.017\n",
      "Iter 171/300 - Loss: 3.560   lengthscale: 7.319   noise: 0.015\n",
      "Iter 181/300 - Loss: 3.553   lengthscale: 7.345   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.552   lengthscale: 7.366   noise: 0.013\n",
      "Iter 201/300 - Loss: 3.559   lengthscale: 7.381   noise: 0.012\n",
      "Iter 211/300 - Loss: 3.555   lengthscale: 7.391   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.552   lengthscale: 7.400   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.549   lengthscale: 7.402   noise: 0.010\n",
      "Iter 241/300 - Loss: 3.541   lengthscale: 7.407   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.544   lengthscale: 7.413   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.550   lengthscale: 7.416   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.538   lengthscale: 7.413   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.542   lengthscale: 7.408   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.541   lengthscale: 7.405   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9977, precision: 0.9954, recall: 1.0000, specificity: 0.9954, cm: [[1516    7]\n",
      " [   0 1523]]\n",
      "accuracy: 0.9487, precision: 0.6667, recall: 0.5000, specificity: 0.9816, cm: [[374   7]\n",
      " [ 14  14]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([3037, 306]), train y: torch.Size([3037]), test X: torch.Size([409, 306]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.041   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.760   lengthscale: 1.319   noise: 1.288\n",
      "Iter 21/300 - Loss: 5.030   lengthscale: 2.197   noise: 1.824\n",
      "Iter 31/300 - Loss: 4.540   lengthscale: 3.273   noise: 1.869\n",
      "Iter 41/300 - Loss: 4.181   lengthscale: 4.338   noise: 1.400\n",
      "Iter 51/300 - Loss: 3.946   lengthscale: 5.197   noise: 0.782\n",
      "Iter 61/300 - Loss: 3.787   lengthscale: 5.816   noise: 0.353\n",
      "Iter 71/300 - Loss: 3.703   lengthscale: 6.250   noise: 0.161\n",
      "Iter 81/300 - Loss: 3.657   lengthscale: 6.551   noise: 0.088\n",
      "Iter 91/300 - Loss: 3.641   lengthscale: 6.759   noise: 0.059\n",
      "Iter 101/300 - Loss: 3.628   lengthscale: 6.898   noise: 0.044\n",
      "Iter 111/300 - Loss: 3.620   lengthscale: 6.987   noise: 0.035\n",
      "Iter 121/300 - Loss: 3.613   lengthscale: 7.049   noise: 0.030\n",
      "Iter 131/300 - Loss: 3.608   lengthscale: 7.094   noise: 0.026\n",
      "Iter 141/300 - Loss: 3.610   lengthscale: 7.130   noise: 0.023\n",
      "Iter 151/300 - Loss: 3.605   lengthscale: 7.155   noise: 0.020\n",
      "Iter 161/300 - Loss: 3.606   lengthscale: 7.172   noise: 0.018\n",
      "Iter 171/300 - Loss: 3.600   lengthscale: 7.187   noise: 0.016\n",
      "Iter 181/300 - Loss: 3.605   lengthscale: 7.201   noise: 0.015\n",
      "Iter 191/300 - Loss: 3.597   lengthscale: 7.212   noise: 0.014\n",
      "Iter 201/300 - Loss: 3.599   lengthscale: 7.218   noise: 0.013\n",
      "Iter 211/300 - Loss: 3.600   lengthscale: 7.225   noise: 0.012\n",
      "Iter 221/300 - Loss: 3.593   lengthscale: 7.226   noise: 0.011\n",
      "Iter 231/300 - Loss: 3.589   lengthscale: 7.222   noise: 0.010\n",
      "Iter 241/300 - Loss: 3.589   lengthscale: 7.216   noise: 0.010\n",
      "Iter 251/300 - Loss: 3.590   lengthscale: 7.213   noise: 0.009\n",
      "Iter 261/300 - Loss: 3.586   lengthscale: 7.207   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.590   lengthscale: 7.197   noise: 0.008\n",
      "Iter 281/300 - Loss: 3.596   lengthscale: 7.188   noise: 0.008\n",
      "Iter 291/300 - Loss: 3.595   lengthscale: 7.180   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9974, precision: 0.9947, recall: 1.0000, specificity: 0.9947, cm: [[1515    8]\n",
      " [   0 1514]]\n",
      "accuracy: 0.9511, precision: 0.6818, recall: 0.5357, specificity: 0.9816, cm: [[374   7]\n",
      " [ 13  15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([1635, 2048]), train y: torch.Size([1635]), test X: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.093   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.516   lengthscale: 1.160   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.300   lengthscale: 1.929   noise: 1.063\n",
      "Iter 31/300 - Loss: 3.427   lengthscale: 2.999   noise: 1.227\n",
      "Iter 41/300 - Loss: 3.300   lengthscale: 4.000   noise: 1.227\n",
      "Iter 51/300 - Loss: 3.266   lengthscale: 4.685   noise: 1.139\n",
      "Iter 61/300 - Loss: 3.244   lengthscale: 5.111   noise: 1.012\n",
      "Iter 71/300 - Loss: 3.226   lengthscale: 5.385   noise: 0.870\n",
      "Iter 81/300 - Loss: 3.205   lengthscale: 5.580   noise: 0.731\n",
      "Iter 91/300 - Loss: 3.196   lengthscale: 5.734   noise: 0.605\n",
      "Iter 101/300 - Loss: 3.182   lengthscale: 5.861   noise: 0.498\n",
      "Iter 111/300 - Loss: 3.179   lengthscale: 5.973   noise: 0.411\n",
      "Iter 121/300 - Loss: 3.178   lengthscale: 6.075   noise: 0.345\n",
      "Iter 131/300 - Loss: 3.159   lengthscale: 6.168   noise: 0.295\n",
      "Iter 141/300 - Loss: 3.161   lengthscale: 6.254   noise: 0.257\n",
      "Iter 151/300 - Loss: 3.161   lengthscale: 6.336   noise: 0.228\n",
      "Iter 161/300 - Loss: 3.158   lengthscale: 6.413   noise: 0.205\n",
      "Iter 171/300 - Loss: 3.153   lengthscale: 6.486   noise: 0.186\n",
      "Iter 181/300 - Loss: 3.154   lengthscale: 6.557   noise: 0.171\n",
      "Iter 191/300 - Loss: 3.153   lengthscale: 6.621   noise: 0.159\n",
      "Iter 201/300 - Loss: 3.147   lengthscale: 6.680   noise: 0.148\n",
      "Iter 211/300 - Loss: 3.146   lengthscale: 6.735   noise: 0.138\n",
      "Iter 221/300 - Loss: 3.153   lengthscale: 6.793   noise: 0.129\n",
      "Iter 231/300 - Loss: 3.152   lengthscale: 6.851   noise: 0.121\n",
      "Iter 241/300 - Loss: 3.152   lengthscale: 6.907   noise: 0.114\n",
      "Iter 251/300 - Loss: 3.149   lengthscale: 6.962   noise: 0.108\n",
      "Iter 261/300 - Loss: 3.141   lengthscale: 7.018   noise: 0.102\n",
      "Iter 271/300 - Loss: 3.149   lengthscale: 7.075   noise: 0.097\n",
      "Iter 281/300 - Loss: 3.148   lengthscale: 7.130   noise: 0.092\n",
      "Iter 291/300 - Loss: 3.146   lengthscale: 7.186   noise: 0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9547, precision: 1.0000, recall: 0.3393, specificity: 1.0000, cm: [[1523    0]\n",
      " [  74   38]]\n",
      "accuracy: 0.9438, precision: 1.0000, recall: 0.1786, specificity: 1.0000, cm: [[381   0]\n",
      " [ 23   5]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([224, 2048]), train y: torch.Size([224]), test X: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.262   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.439   lengthscale: 2.076   noise: 1.983\n",
      "Iter 31/300 - Loss: 5.289   lengthscale: 2.943   noise: 2.599\n",
      "Iter 41/300 - Loss: 5.236   lengthscale: 2.405   noise: 3.114\n",
      "Iter 51/300 - Loss: 5.211   lengthscale: 1.601   noise: 3.468\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 1.137   noise: 3.681\n",
      "Iter 71/300 - Loss: 5.202   lengthscale: 0.945   noise: 3.807\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.868   noise: 3.884\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.835   noise: 3.931\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.818   noise: 3.960\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.808   noise: 3.975\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.800   noise: 3.982\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.794   noise: 3.985\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.788   noise: 3.985\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.783   noise: 3.984\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.778   noise: 3.983\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.773   noise: 3.983\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.768   noise: 3.982\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.763   noise: 3.982\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.758   noise: 3.982\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.754   noise: 3.982\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.750   noise: 3.982\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.746   noise: 3.982\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.742   noise: 3.982\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.738   noise: 3.982\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.734   noise: 3.982\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.731   noise: 3.982\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.727   noise: 3.982\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.724   noise: 3.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[112   0]\n",
      " [  0 112]]\n",
      "accuracy: 0.1051, precision: 0.0689, recall: 0.9643, specificity: 0.0420, cm: [[ 16 365]\n",
      " [  1  27]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n",
      "train X: torch.Size([3046, 2048]), train y: torch.Size([3046]), test X: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.287   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.932   lengthscale: 1.307   noise: 0.798\n",
      "Iter 21/300 - Loss: 4.160   lengthscale: 2.123   noise: 0.886\n",
      "Iter 31/300 - Loss: 3.644   lengthscale: 2.987   noise: 0.613\n",
      "Iter 41/300 - Loss: 3.432   lengthscale: 3.642   noise: 0.287\n",
      "Iter 51/300 - Loss: 3.323   lengthscale: 4.039   noise: 0.116\n",
      "Iter 61/300 - Loss: 3.270   lengthscale: 4.272   noise: 0.054\n",
      "Iter 71/300 - Loss: 3.251   lengthscale: 4.407   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.242   lengthscale: 4.484   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.234   lengthscale: 4.524   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.227   lengthscale: 4.546   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.226   lengthscale: 4.560   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.220   lengthscale: 4.576   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.218   lengthscale: 4.595   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.221   lengthscale: 4.619   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.211   lengthscale: 4.649   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.213   lengthscale: 4.683   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.209   lengthscale: 4.717   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.209   lengthscale: 4.749   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.207   lengthscale: 4.781   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.206   lengthscale: 4.811   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.210   lengthscale: 4.838   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.205   lengthscale: 4.865   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.204   lengthscale: 4.889   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.206   lengthscale: 4.912   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.203   lengthscale: 4.934   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.208   lengthscale: 4.957   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.200   lengthscale: 4.979   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.200   lengthscale: 4.998   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.208   lengthscale: 5.016   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9944, precision: 0.9941, recall: 0.9947, specificity: 0.9941, cm: [[1514    9]\n",
      " [   8 1515]]\n",
      "accuracy: 0.9682, precision: 0.8947, recall: 0.6071, specificity: 0.9948, cm: [[379   2]\n",
      " [ 11  17]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n",
      "train X: torch.Size([3027, 2048]), train y: torch.Size([3027]), test X: torch.Size([409, 2048]), test y: torch.Size([409])\n",
      "Iter 1/300 - Loss: 6.165   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.887   lengthscale: 1.305   noise: 0.796\n",
      "Iter 21/300 - Loss: 4.164   lengthscale: 2.118   noise: 0.883\n",
      "Iter 31/300 - Loss: 3.650   lengthscale: 2.980   noise: 0.605\n",
      "Iter 41/300 - Loss: 3.437   lengthscale: 3.632   noise: 0.281\n",
      "Iter 51/300 - Loss: 3.329   lengthscale: 4.017   noise: 0.114\n",
      "Iter 61/300 - Loss: 3.287   lengthscale: 4.228   noise: 0.054\n",
      "Iter 71/300 - Loss: 3.270   lengthscale: 4.337   noise: 0.033\n",
      "Iter 81/300 - Loss: 3.254   lengthscale: 4.385   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.247   lengthscale: 4.402   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.248   lengthscale: 4.407   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.245   lengthscale: 4.414   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.233   lengthscale: 4.433   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.232   lengthscale: 4.462   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.232   lengthscale: 4.497   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.232   lengthscale: 4.533   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.233   lengthscale: 4.568   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.229   lengthscale: 4.599   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.230   lengthscale: 4.628   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.228   lengthscale: 4.654   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.221   lengthscale: 4.678   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.232   lengthscale: 4.700   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.229   lengthscale: 4.720   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.228   lengthscale: 4.742   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.226   lengthscale: 4.762   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.220   lengthscale: 4.783   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.224   lengthscale: 4.801   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.226   lengthscale: 4.818   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.222   lengthscale: 4.834   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.219   lengthscale: 4.846   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9950, precision: 0.9947, recall: 0.9953, specificity: 0.9947, cm: [[1515    8]\n",
      " [   7 1497]]\n",
      "accuracy: 0.9658, precision: 0.8889, recall: 0.5714, specificity: 0.9948, cm: [[379   2]\n",
      " [ 12  16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK2/inhib/NEK2_inhibition_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "NEK3\n",
      "\n",
      "moe scaled\n",
      "train X: torch.Size([1122, 306]), train y: torch.Size([1122]), test X: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.108   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.520   lengthscale: 0.974   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.553   lengthscale: 1.363   noise: 1.072\n",
      "Iter 31/300 - Loss: 3.972   lengthscale: 1.889   noise: 1.329\n",
      "Iter 41/300 - Loss: 3.570   lengthscale: 2.543   noise: 1.481\n",
      "Iter 51/300 - Loss: 3.410   lengthscale: 3.153   noise: 1.514\n",
      "Iter 61/300 - Loss: 3.358   lengthscale: 3.579   noise: 1.472\n",
      "Iter 71/300 - Loss: 3.336   lengthscale: 3.857   noise: 1.394\n",
      "Iter 81/300 - Loss: 3.319   lengthscale: 4.049   noise: 1.303\n",
      "Iter 91/300 - Loss: 3.306   lengthscale: 4.192   noise: 1.210\n",
      "Iter 101/300 - Loss: 3.297   lengthscale: 4.306   noise: 1.121\n",
      "Iter 111/300 - Loss: 3.290   lengthscale: 4.400   noise: 1.042\n",
      "Iter 121/300 - Loss: 3.284   lengthscale: 4.481   noise: 0.974\n",
      "Iter 131/300 - Loss: 3.280   lengthscale: 4.549   noise: 0.919\n",
      "Iter 141/300 - Loss: 3.273   lengthscale: 4.608   noise: 0.876\n",
      "Iter 151/300 - Loss: 3.275   lengthscale: 4.658   noise: 0.844\n",
      "Iter 161/300 - Loss: 3.278   lengthscale: 4.698   noise: 0.823\n",
      "Iter 171/300 - Loss: 3.273   lengthscale: 4.727   noise: 0.811\n",
      "Iter 181/300 - Loss: 3.271   lengthscale: 4.749   noise: 0.805\n",
      "Iter 191/300 - Loss: 3.273   lengthscale: 4.766   noise: 0.802\n",
      "Iter 201/300 - Loss: 3.266   lengthscale: 4.780   noise: 0.803\n",
      "Iter 211/300 - Loss: 3.267   lengthscale: 4.792   noise: 0.806\n",
      "Iter 221/300 - Loss: 3.267   lengthscale: 4.800   noise: 0.811\n",
      "Iter 231/300 - Loss: 3.261   lengthscale: 4.807   noise: 0.813\n",
      "Iter 241/300 - Loss: 3.265   lengthscale: 4.813   noise: 0.815\n",
      "Iter 251/300 - Loss: 3.270   lengthscale: 4.820   noise: 0.815\n",
      "Iter 261/300 - Loss: 3.261   lengthscale: 4.825   noise: 0.817\n",
      "Iter 271/300 - Loss: 3.264   lengthscale: 4.824   noise: 0.820\n",
      "Iter 281/300 - Loss: 3.269   lengthscale: 4.822   noise: 0.821\n",
      "Iter 291/300 - Loss: 3.254   lengthscale: 4.818   noise: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9430, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [  64    0]]\n",
      "accuracy: 0.9397, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[265   0]\n",
      " [ 17   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n",
      "train X: torch.Size([128, 306]), train y: torch.Size([128]), test X: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.693   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.693   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.693   noise: 2.576\n",
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.693   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.693   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.693   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.693   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.897\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.895\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.894\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[64  0]\n",
      " [ 0 64]]\n",
      "accuracy: 0.9326, precision: 0.0000, recall: 0.0000, specificity: 0.9925, cm: [[263   2]\n",
      " [ 17   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n",
      "train X: torch.Size([2116, 306]), train y: torch.Size([2116]), test X: torch.Size([282, 306]), test y: torch.Size([282])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/300 - Loss: 7.051   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.783   lengthscale: 1.316   noise: 1.289\n",
      "Iter 21/300 - Loss: 5.066   lengthscale: 2.193   noise: 1.845\n",
      "Iter 31/300 - Loss: 4.647   lengthscale: 3.270   noise: 1.955\n",
      "Iter 41/300 - Loss: 4.337   lengthscale: 4.331   noise: 1.569\n",
      "Iter 51/300 - Loss: 4.107   lengthscale: 5.240   noise: 0.949\n",
      "Iter 61/300 - Loss: 3.942   lengthscale: 5.896   noise: 0.450\n",
      "Iter 71/300 - Loss: 3.845   lengthscale: 6.317   noise: 0.202\n",
      "Iter 81/300 - Loss: 3.804   lengthscale: 6.570   noise: 0.107\n",
      "Iter 91/300 - Loss: 3.780   lengthscale: 6.714   noise: 0.068\n",
      "Iter 101/300 - Loss: 3.766   lengthscale: 6.791   noise: 0.050\n",
      "Iter 111/300 - Loss: 3.771   lengthscale: 6.824   noise: 0.040\n",
      "Iter 121/300 - Loss: 3.750   lengthscale: 6.838   noise: 0.033\n",
      "Iter 131/300 - Loss: 3.744   lengthscale: 6.842   noise: 0.028\n",
      "Iter 141/300 - Loss: 3.745   lengthscale: 6.843   noise: 0.025\n",
      "Iter 151/300 - Loss: 3.747   lengthscale: 6.842   noise: 0.022\n",
      "Iter 161/300 - Loss: 3.737   lengthscale: 6.839   noise: 0.020\n",
      "Iter 171/300 - Loss: 3.746   lengthscale: 6.833   noise: 0.018\n",
      "Iter 181/300 - Loss: 3.736   lengthscale: 6.823   noise: 0.016\n",
      "Iter 191/300 - Loss: 3.730   lengthscale: 6.812   noise: 0.015\n",
      "Iter 201/300 - Loss: 3.734   lengthscale: 6.800   noise: 0.014\n",
      "Iter 211/300 - Loss: 3.728   lengthscale: 6.791   noise: 0.013\n",
      "Iter 221/300 - Loss: 3.730   lengthscale: 6.774   noise: 0.012\n",
      "Iter 231/300 - Loss: 3.729   lengthscale: 6.756   noise: 0.011\n",
      "Iter 241/300 - Loss: 3.723   lengthscale: 6.737   noise: 0.010\n",
      "Iter 251/300 - Loss: 3.722   lengthscale: 6.707   noise: 0.010\n",
      "Iter 261/300 - Loss: 3.723   lengthscale: 6.680   noise: 0.009\n",
      "Iter 271/300 - Loss: 3.726   lengthscale: 6.656   noise: 0.009\n",
      "Iter 281/300 - Loss: 3.722   lengthscale: 6.633   noise: 0.008\n",
      "Iter 291/300 - Loss: 3.723   lengthscale: 6.615   noise: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [   0 1058]]\n",
      "accuracy: 0.8901, precision: 0.1111, recall: 0.1176, specificity: 0.9396, cm: [[249  16]\n",
      " [ 15   2]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([2113, 306]), train y: torch.Size([2113]), test X: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.053   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.785   lengthscale: 1.321   noise: 1.289\n",
      "Iter 21/300 - Loss: 5.070   lengthscale: 2.202   noise: 1.847\n",
      "Iter 31/300 - Loss: 4.662   lengthscale: 3.277   noise: 1.964\n",
      "Iter 41/300 - Loss: 4.354   lengthscale: 4.344   noise: 1.583\n",
      "Iter 51/300 - Loss: 4.117   lengthscale: 5.261   noise: 0.962\n",
      "Iter 61/300 - Loss: 3.955   lengthscale: 5.921   noise: 0.456\n",
      "Iter 71/300 - Loss: 3.862   lengthscale: 6.344   noise: 0.204\n",
      "Iter 81/300 - Loss: 3.813   lengthscale: 6.600   noise: 0.108\n",
      "Iter 91/300 - Loss: 3.801   lengthscale: 6.746   noise: 0.069\n",
      "Iter 101/300 - Loss: 3.784   lengthscale: 6.826   noise: 0.051\n",
      "Iter 111/300 - Loss: 3.784   lengthscale: 6.864   noise: 0.040\n",
      "Iter 121/300 - Loss: 3.775   lengthscale: 6.872   noise: 0.034\n",
      "Iter 131/300 - Loss: 3.779   lengthscale: 6.872   noise: 0.029\n",
      "Iter 141/300 - Loss: 3.761   lengthscale: 6.870   noise: 0.025\n",
      "Iter 151/300 - Loss: 3.755   lengthscale: 6.864   noise: 0.022\n",
      "Iter 161/300 - Loss: 3.757   lengthscale: 6.852   noise: 0.020\n",
      "Iter 171/300 - Loss: 3.766   lengthscale: 6.839   noise: 0.018\n",
      "Iter 181/300 - Loss: 3.745   lengthscale: 6.827   noise: 0.017\n",
      "Iter 191/300 - Loss: 3.741   lengthscale: 6.816   noise: 0.015\n",
      "Iter 201/300 - Loss: 3.751   lengthscale: 6.804   noise: 0.014\n",
      "Iter 211/300 - Loss: 3.747   lengthscale: 6.794   noise: 0.013\n",
      "Iter 221/300 - Loss: 3.743   lengthscale: 6.778   noise: 0.012\n",
      "Iter 231/300 - Loss: 3.745   lengthscale: 6.754   noise: 0.011\n",
      "Iter 241/300 - Loss: 3.737   lengthscale: 6.733   noise: 0.010\n",
      "Iter 251/300 - Loss: 3.735   lengthscale: 6.711   noise: 0.010\n",
      "Iter 261/300 - Loss: 3.740   lengthscale: 6.686   noise: 0.009\n",
      "Iter 271/300 - Loss: 3.727   lengthscale: 6.664   noise: 0.009\n",
      "Iter 281/300 - Loss: 3.734   lengthscale: 6.652   noise: 0.008\n",
      "Iter 291/300 - Loss: 3.724   lengthscale: 6.637   noise: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [   0 1055]]\n",
      "accuracy: 0.8865, precision: 0.1053, recall: 0.1176, specificity: 0.9358, cm: [[248  17]\n",
      " [ 15   2]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([1122, 2048]), train y: torch.Size([1122]), test X: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.092   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.494   lengthscale: 1.033   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.407   lengthscale: 1.470   noise: 1.067\n",
      "Iter 31/300 - Loss: 3.493   lengthscale: 2.082   noise: 1.269\n",
      "Iter 41/300 - Loss: 3.346   lengthscale: 2.635   noise: 1.317\n",
      "Iter 51/300 - Loss: 3.299   lengthscale: 3.018   noise: 1.277\n",
      "Iter 61/300 - Loss: 3.285   lengthscale: 3.486   noise: 1.198\n",
      "Iter 71/300 - Loss: 3.271   lengthscale: 4.304   noise: 1.106\n",
      "Iter 81/300 - Loss: 3.251   lengthscale: 5.296   noise: 1.013\n",
      "Iter 91/300 - Loss: 3.258   lengthscale: 6.202   noise: 0.924\n",
      "Iter 101/300 - Loss: 3.249   lengthscale: 6.933   noise: 0.845\n",
      "Iter 111/300 - Loss: 3.242   lengthscale: 7.488   noise: 0.778\n",
      "Iter 121/300 - Loss: 3.242   lengthscale: 7.906   noise: 0.723\n",
      "Iter 131/300 - Loss: 3.235   lengthscale: 8.233   noise: 0.682\n",
      "Iter 141/300 - Loss: 3.233   lengthscale: 8.509   noise: 0.651\n",
      "Iter 151/300 - Loss: 3.234   lengthscale: 8.749   noise: 0.629\n",
      "Iter 161/300 - Loss: 3.233   lengthscale: 8.959   noise: 0.614\n",
      "Iter 171/300 - Loss: 3.239   lengthscale: 9.143   noise: 0.605\n",
      "Iter 181/300 - Loss: 3.231   lengthscale: 9.311   noise: 0.599\n",
      "Iter 191/300 - Loss: 3.230   lengthscale: 9.468   noise: 0.595\n",
      "Iter 201/300 - Loss: 3.233   lengthscale: 9.618   noise: 0.593\n",
      "Iter 211/300 - Loss: 3.227   lengthscale: 9.758   noise: 0.592\n",
      "Iter 221/300 - Loss: 3.229   lengthscale: 9.889   noise: 0.589\n",
      "Iter 231/300 - Loss: 3.230   lengthscale: 10.008   noise: 0.587\n",
      "Iter 241/300 - Loss: 3.235   lengthscale: 10.122   noise: 0.586\n",
      "Iter 251/300 - Loss: 3.224   lengthscale: 10.229   noise: 0.586\n",
      "Iter 261/300 - Loss: 3.224   lengthscale: 10.330   noise: 0.585\n",
      "Iter 271/300 - Loss: 3.231   lengthscale: 10.428   noise: 0.585\n",
      "Iter 281/300 - Loss: 3.230   lengthscale: 10.522   noise: 0.584\n",
      "Iter 291/300 - Loss: 3.233   lengthscale: 10.614   noise: 0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9430, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1058    0]\n",
      " [  64    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9397, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[265   0]\n",
      " [ 17   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([128, 2048]), train y: torch.Size([128]), test X: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.930   lengthscale: 1.256   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.434   lengthscale: 2.074   noise: 1.981\n",
      "Iter 31/300 - Loss: 5.255   lengthscale: 3.171   noise: 2.571\n",
      "Iter 41/300 - Loss: 5.219   lengthscale: 3.761   noise: 3.032\n",
      "Iter 51/300 - Loss: 5.203   lengthscale: 3.412   noise: 3.375\n",
      "Iter 61/300 - Loss: 5.197   lengthscale: 2.959   noise: 3.594\n",
      "Iter 71/300 - Loss: 5.196   lengthscale: 2.785   noise: 3.715\n",
      "Iter 81/300 - Loss: 5.195   lengthscale: 2.833   noise: 3.774\n",
      "Iter 91/300 - Loss: 5.195   lengthscale: 2.916   noise: 3.798\n",
      "Iter 101/300 - Loss: 5.195   lengthscale: 2.935   noise: 3.804\n",
      "Iter 111/300 - Loss: 5.195   lengthscale: 2.912   noise: 3.802\n",
      "Iter 121/300 - Loss: 5.195   lengthscale: 2.894   noise: 3.794\n",
      "Iter 131/300 - Loss: 5.195   lengthscale: 2.891   noise: 3.784\n",
      "Iter 141/300 - Loss: 5.195   lengthscale: 2.892   noise: 3.771\n",
      "Iter 151/300 - Loss: 5.195   lengthscale: 2.891   noise: 3.757\n",
      "Iter 161/300 - Loss: 5.195   lengthscale: 2.890   noise: 3.743\n",
      "Iter 171/300 - Loss: 5.195   lengthscale: 2.890   noise: 3.728\n",
      "Iter 181/300 - Loss: 5.195   lengthscale: 2.889   noise: 3.712\n",
      "Iter 191/300 - Loss: 5.195   lengthscale: 2.888   noise: 3.696\n",
      "Iter 201/300 - Loss: 5.195   lengthscale: 2.887   noise: 3.679\n",
      "Iter 211/300 - Loss: 5.195   lengthscale: 2.887   noise: 3.662\n",
      "Iter 221/300 - Loss: 5.195   lengthscale: 2.886   noise: 3.645\n",
      "Iter 231/300 - Loss: 5.195   lengthscale: 2.885   noise: 3.627\n",
      "Iter 241/300 - Loss: 5.195   lengthscale: 2.884   noise: 3.609\n",
      "Iter 251/300 - Loss: 5.195   lengthscale: 2.883   noise: 3.590\n",
      "Iter 261/300 - Loss: 5.195   lengthscale: 2.882   noise: 3.571\n",
      "Iter 271/300 - Loss: 5.195   lengthscale: 2.881   noise: 3.552\n",
      "Iter 281/300 - Loss: 5.195   lengthscale: 2.881   noise: 3.532\n",
      "Iter 291/300 - Loss: 5.195   lengthscale: 2.880   noise: 3.512\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[64  0]\n",
      " [ 0 64]]\n",
      "accuracy: 0.4645, precision: 0.0813, recall: 0.7647, specificity: 0.4453, cm: [[118 147]\n",
      " [  4  13]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: torch.Size([2116, 2048]), train y: torch.Size([2116]), test X: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.325   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.992   lengthscale: 1.313   noise: 0.799\n",
      "Iter 21/300 - Loss: 4.289   lengthscale: 2.152   noise: 0.909\n",
      "Iter 31/300 - Loss: 3.808   lengthscale: 3.025   noise: 0.684\n",
      "Iter 41/300 - Loss: 3.569   lengthscale: 3.725   noise: 0.337\n",
      "Iter 51/300 - Loss: 3.442   lengthscale: 4.129   noise: 0.136\n",
      "Iter 61/300 - Loss: 3.396   lengthscale: 4.323   noise: 0.061\n",
      "Iter 71/300 - Loss: 3.356   lengthscale: 4.397   noise: 0.035\n",
      "Iter 81/300 - Loss: 3.349   lengthscale: 4.405   noise: 0.024\n",
      "Iter 91/300 - Loss: 3.332   lengthscale: 4.387   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.326   lengthscale: 4.376   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.330   lengthscale: 4.387   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.325   lengthscale: 4.415   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.313   lengthscale: 4.442   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.321   lengthscale: 4.461   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.320   lengthscale: 4.478   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.317   lengthscale: 4.495   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.318   lengthscale: 4.510   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.307   lengthscale: 4.524   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.322   lengthscale: 4.538   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.303   lengthscale: 4.552   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.314   lengthscale: 4.562   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.322   lengthscale: 4.572   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.304   lengthscale: 4.580   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.305   lengthscale: 4.587   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.306   lengthscale: 4.591   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.301   lengthscale: 4.593   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.310   lengthscale: 4.595   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.300   lengthscale: 4.599   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.310   lengthscale: 4.599   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9957, precision: 1.0000, recall: 0.9915, specificity: 1.0000, cm: [[1058    0]\n",
      " [   9 1049]]\n",
      "accuracy: 0.9539, precision: 0.7500, recall: 0.3529, specificity: 0.9925, cm: [[263   2]\n",
      " [ 11   6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n",
      "train X: torch.Size([2130, 2048]), train y: torch.Size([2130]), test X: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 6.319   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.982   lengthscale: 1.313   noise: 0.798\n",
      "Iter 21/300 - Loss: 4.283   lengthscale: 2.150   noise: 0.901\n",
      "Iter 31/300 - Loss: 3.806   lengthscale: 3.011   noise: 0.665\n",
      "Iter 41/300 - Loss: 3.573   lengthscale: 3.701   noise: 0.323\n",
      "Iter 51/300 - Loss: 3.450   lengthscale: 4.094   noise: 0.129\n",
      "Iter 61/300 - Loss: 3.396   lengthscale: 4.279   noise: 0.059\n",
      "Iter 71/300 - Loss: 3.359   lengthscale: 4.343   noise: 0.034\n",
      "Iter 81/300 - Loss: 3.346   lengthscale: 4.347   noise: 0.024\n",
      "Iter 91/300 - Loss: 3.329   lengthscale: 4.333   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.322   lengthscale: 4.332   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.322   lengthscale: 4.351   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.325   lengthscale: 4.376   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.328   lengthscale: 4.397   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.318   lengthscale: 4.414   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.327   lengthscale: 4.432   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.317   lengthscale: 4.450   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.313   lengthscale: 4.466   noise: 0.006\n",
      "Iter 181/300 - Loss: 3.317   lengthscale: 4.478   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.323   lengthscale: 4.490   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.311   lengthscale: 4.503   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.310   lengthscale: 4.514   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.309   lengthscale: 4.524   noise: 0.004\n",
      "Iter 231/300 - Loss: 3.312   lengthscale: 4.532   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.307   lengthscale: 4.536   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.314   lengthscale: 4.539   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.315   lengthscale: 4.543   noise: 0.003\n",
      "Iter 271/300 - Loss: 3.307   lengthscale: 4.545   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.306   lengthscale: 4.546   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.310   lengthscale: 4.546   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9967, precision: 1.0000, recall: 0.9935, specificity: 1.0000, cm: [[1058    0]\n",
      " [   7 1065]]\n",
      "accuracy: 0.9433, precision: 0.5556, recall: 0.2941, specificity: 0.9849, cm: [[261   4]\n",
      " [ 12   5]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK3/bind/NEK3_binding_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "\n",
      "NEK5\n",
      "\n",
      "moe scaled\n",
      "train X: torch.Size([989, 306]), train y: torch.Size([989]), test X: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.561   lengthscale: 1.039   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.630   lengthscale: 1.341   noise: 1.072\n",
      "Iter 31/300 - Loss: 4.073   lengthscale: 1.823   noise: 1.329\n",
      "Iter 41/300 - Loss: 3.693   lengthscale: 2.460   noise: 1.481\n",
      "Iter 51/300 - Loss: 3.540   lengthscale: 3.063   noise: 1.515\n",
      "Iter 61/300 - Loss: 3.483   lengthscale: 3.492   noise: 1.474\n",
      "Iter 71/300 - Loss: 3.467   lengthscale: 3.777   noise: 1.397\n",
      "Iter 81/300 - Loss: 3.448   lengthscale: 3.975   noise: 1.306\n",
      "Iter 91/300 - Loss: 3.428   lengthscale: 4.125   noise: 1.213\n",
      "Iter 101/300 - Loss: 3.427   lengthscale: 4.246   noise: 1.125\n",
      "Iter 111/300 - Loss: 3.419   lengthscale: 4.347   noise: 1.045\n",
      "Iter 121/300 - Loss: 3.419   lengthscale: 4.431   noise: 0.977\n",
      "Iter 131/300 - Loss: 3.411   lengthscale: 4.502   noise: 0.921\n",
      "Iter 141/300 - Loss: 3.407   lengthscale: 4.561   noise: 0.879\n",
      "Iter 151/300 - Loss: 3.411   lengthscale: 4.611   noise: 0.846\n",
      "Iter 161/300 - Loss: 3.414   lengthscale: 4.653   noise: 0.823\n",
      "Iter 171/300 - Loss: 3.411   lengthscale: 4.689   noise: 0.807\n",
      "Iter 181/300 - Loss: 3.408   lengthscale: 4.718   noise: 0.795\n",
      "Iter 191/300 - Loss: 3.409   lengthscale: 4.743   noise: 0.789\n",
      "Iter 201/300 - Loss: 3.403   lengthscale: 4.764   noise: 0.787\n",
      "Iter 211/300 - Loss: 3.401   lengthscale: 4.783   noise: 0.785\n",
      "Iter 221/300 - Loss: 3.396   lengthscale: 4.799   noise: 0.784\n",
      "Iter 231/300 - Loss: 3.406   lengthscale: 4.813   noise: 0.781\n",
      "Iter 241/300 - Loss: 3.394   lengthscale: 4.827   noise: 0.778\n",
      "Iter 251/300 - Loss: 3.398   lengthscale: 4.837   noise: 0.777\n",
      "Iter 261/300 - Loss: 3.406   lengthscale: 4.846   noise: 0.775\n",
      "Iter 271/300 - Loss: 3.401   lengthscale: 4.856   noise: 0.774\n",
      "Iter 281/300 - Loss: 3.401   lengthscale: 4.862   noise: 0.772\n",
      "Iter 291/300 - Loss: 3.397   lengthscale: 4.868   noise: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9221, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[912   0]\n",
      " [ 77   0]]\n",
      "accuracy: 0.9194, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[228   0]\n",
      " [ 20   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n",
      "train X: torch.Size([154, 306]), train y: torch.Size([154]), test X: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.694   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.694   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.695   noise: 2.576\n",
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.696   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.696   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.697   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.697   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.698   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.699   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.699   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.700   noise: 3.897\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.701   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.702   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.702   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.703   noise: 3.895\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.704   noise: 3.894\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.705   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.706   noise: 3.893\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.707   noise: 3.893\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.708   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.709   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.711   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.712   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.713   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.715   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.717   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.719   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.721   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.724   noise: 3.892\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[77  0]\n",
      " [ 0 77]]\n",
      "accuracy: 0.9194, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[228   0]\n",
      " [ 20   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n",
      "train X: torch.Size([1824, 306]), train y: torch.Size([1824]), test X: torch.Size([248, 306]), test y: torch.Size([248])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/300 - Loss: 7.064   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.806   lengthscale: 1.316   noise: 1.289\n",
      "Iter 21/300 - Loss: 5.116   lengthscale: 2.196   noise: 1.862\n",
      "Iter 31/300 - Loss: 4.692   lengthscale: 3.287   noise: 2.025\n",
      "Iter 41/300 - Loss: 4.387   lengthscale: 4.385   noise: 1.678\n",
      "Iter 51/300 - Loss: 4.160   lengthscale: 5.313   noise: 1.060\n",
      "Iter 61/300 - Loss: 4.003   lengthscale: 5.977   noise: 0.523\n",
      "Iter 71/300 - Loss: 3.915   lengthscale: 6.401   noise: 0.237\n",
      "Iter 81/300 - Loss: 3.877   lengthscale: 6.656   noise: 0.124\n",
      "Iter 91/300 - Loss: 3.855   lengthscale: 6.802   noise: 0.078\n",
      "Iter 101/300 - Loss: 3.850   lengthscale: 6.886   noise: 0.056\n",
      "Iter 111/300 - Loss: 3.819   lengthscale: 6.931   noise: 0.044\n",
      "Iter 121/300 - Loss: 3.830   lengthscale: 6.955   noise: 0.037\n",
      "Iter 131/300 - Loss: 3.819   lengthscale: 6.965   noise: 0.031\n",
      "Iter 141/300 - Loss: 3.822   lengthscale: 6.964   noise: 0.027\n",
      "Iter 151/300 - Loss: 3.826   lengthscale: 6.962   noise: 0.024\n",
      "Iter 161/300 - Loss: 3.808   lengthscale: 6.960   noise: 0.022\n",
      "Iter 171/300 - Loss: 3.819   lengthscale: 6.949   noise: 0.020\n",
      "Iter 181/300 - Loss: 3.816   lengthscale: 6.934   noise: 0.018\n",
      "Iter 191/300 - Loss: 3.804   lengthscale: 6.913   noise: 0.016\n",
      "Iter 201/300 - Loss: 3.812   lengthscale: 6.895   noise: 0.015\n",
      "Iter 211/300 - Loss: 3.804   lengthscale: 6.878   noise: 0.014\n",
      "Iter 221/300 - Loss: 3.802   lengthscale: 6.854   noise: 0.013\n",
      "Iter 231/300 - Loss: 3.803   lengthscale: 6.826   noise: 0.012\n",
      "Iter 241/300 - Loss: 3.791   lengthscale: 6.810   noise: 0.011\n",
      "Iter 251/300 - Loss: 3.791   lengthscale: 6.802   noise: 0.010\n",
      "Iter 261/300 - Loss: 3.801   lengthscale: 6.780   noise: 0.010\n",
      "Iter 271/300 - Loss: 3.796   lengthscale: 6.757   noise: 0.009\n",
      "Iter 281/300 - Loss: 3.796   lengthscale: 6.738   noise: 0.009\n",
      "Iter 291/300 - Loss: 3.783   lengthscale: 6.724   noise: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9989, recall: 1.0000, specificity: 0.9989, cm: [[911   1]\n",
      " [  0 912]]\n",
      "accuracy: 0.9274, precision: 0.5500, recall: 0.5500, specificity: 0.9605, cm: [[219   9]\n",
      " [  9  11]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([1831, 306]), train y: torch.Size([1831]), test X: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.069   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.816   lengthscale: 1.320   noise: 1.290\n",
      "Iter 21/300 - Loss: 5.140   lengthscale: 2.204   noise: 1.878\n",
      "Iter 31/300 - Loss: 4.723   lengthscale: 3.304   noise: 2.071\n",
      "Iter 41/300 - Loss: 4.429   lengthscale: 4.410   noise: 1.749\n",
      "Iter 51/300 - Loss: 4.210   lengthscale: 5.340   noise: 1.127\n",
      "Iter 61/300 - Loss: 4.050   lengthscale: 6.002   noise: 0.565\n",
      "Iter 71/300 - Loss: 3.967   lengthscale: 6.420   noise: 0.257\n",
      "Iter 81/300 - Loss: 3.907   lengthscale: 6.663   noise: 0.133\n",
      "Iter 91/300 - Loss: 3.882   lengthscale: 6.797   noise: 0.083\n",
      "Iter 101/300 - Loss: 3.881   lengthscale: 6.868   noise: 0.060\n",
      "Iter 111/300 - Loss: 3.872   lengthscale: 6.897   noise: 0.047\n",
      "Iter 121/300 - Loss: 3.860   lengthscale: 6.903   noise: 0.039\n",
      "Iter 131/300 - Loss: 3.843   lengthscale: 6.900   noise: 0.033\n",
      "Iter 141/300 - Loss: 3.854   lengthscale: 6.888   noise: 0.029\n",
      "Iter 151/300 - Loss: 3.855   lengthscale: 6.873   noise: 0.026\n",
      "Iter 161/300 - Loss: 3.855   lengthscale: 6.863   noise: 0.023\n",
      "Iter 171/300 - Loss: 3.849   lengthscale: 6.839   noise: 0.021\n",
      "Iter 181/300 - Loss: 3.839   lengthscale: 6.816   noise: 0.019\n",
      "Iter 191/300 - Loss: 3.853   lengthscale: 6.797   noise: 0.017\n",
      "Iter 201/300 - Loss: 3.847   lengthscale: 6.781   noise: 0.016\n",
      "Iter 211/300 - Loss: 3.840   lengthscale: 6.763   noise: 0.015\n",
      "Iter 221/300 - Loss: 3.848   lengthscale: 6.743   noise: 0.014\n",
      "Iter 231/300 - Loss: 3.836   lengthscale: 6.725   noise: 0.013\n",
      "Iter 241/300 - Loss: 3.827   lengthscale: 6.704   noise: 0.012\n",
      "Iter 251/300 - Loss: 3.828   lengthscale: 6.679   noise: 0.011\n",
      "Iter 261/300 - Loss: 3.834   lengthscale: 6.663   noise: 0.010\n",
      "Iter 271/300 - Loss: 3.827   lengthscale: 6.649   noise: 0.010\n",
      "Iter 281/300 - Loss: 3.827   lengthscale: 6.641   noise: 0.009\n",
      "Iter 291/300 - Loss: 3.833   lengthscale: 6.644   noise: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9989, recall: 1.0000, specificity: 0.9989, cm: [[911   1]\n",
      " [  0 919]]\n",
      "accuracy: 0.9395, precision: 0.6190, recall: 0.6500, specificity: 0.9649, cm: [[220   8]\n",
      " [  7  13]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([989, 2048]), train y: torch.Size([989]), test X: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.099   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.548   lengthscale: 1.273   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.472   lengthscale: 2.110   noise: 1.067\n",
      "Iter 31/300 - Loss: 3.583   lengthscale: 3.200   noise: 1.262\n",
      "Iter 41/300 - Loss: 3.434   lengthscale: 4.210   noise: 1.298\n",
      "Iter 51/300 - Loss: 3.413   lengthscale: 4.886   noise: 1.242\n",
      "Iter 61/300 - Loss: 3.381   lengthscale: 5.310   noise: 1.147\n",
      "Iter 71/300 - Loss: 3.380   lengthscale: 5.596   noise: 1.037\n",
      "Iter 81/300 - Loss: 3.364   lengthscale: 5.805   noise: 0.925\n",
      "Iter 91/300 - Loss: 3.358   lengthscale: 5.972   noise: 0.818\n",
      "Iter 101/300 - Loss: 3.347   lengthscale: 6.109   noise: 0.720\n",
      "Iter 111/300 - Loss: 3.334   lengthscale: 6.228   noise: 0.636\n",
      "Iter 121/300 - Loss: 3.339   lengthscale: 6.333   noise: 0.567\n",
      "Iter 131/300 - Loss: 3.337   lengthscale: 6.423   noise: 0.510\n",
      "Iter 141/300 - Loss: 3.338   lengthscale: 6.504   noise: 0.464\n",
      "Iter 151/300 - Loss: 3.332   lengthscale: 6.574   noise: 0.425\n",
      "Iter 161/300 - Loss: 3.332   lengthscale: 6.637   noise: 0.393\n",
      "Iter 171/300 - Loss: 3.331   lengthscale: 6.691   noise: 0.367\n",
      "Iter 181/300 - Loss: 3.336   lengthscale: 6.740   noise: 0.344\n",
      "Iter 191/300 - Loss: 3.329   lengthscale: 6.785   noise: 0.323\n",
      "Iter 201/300 - Loss: 3.331   lengthscale: 6.829   noise: 0.303\n",
      "Iter 211/300 - Loss: 3.326   lengthscale: 6.872   noise: 0.286\n",
      "Iter 221/300 - Loss: 3.323   lengthscale: 6.911   noise: 0.271\n",
      "Iter 231/300 - Loss: 3.332   lengthscale: 6.946   noise: 0.257\n",
      "Iter 241/300 - Loss: 3.321   lengthscale: 6.975   noise: 0.243\n",
      "Iter 251/300 - Loss: 3.317   lengthscale: 7.002   noise: 0.231\n",
      "Iter 261/300 - Loss: 3.319   lengthscale: 7.027   noise: 0.219\n",
      "Iter 271/300 - Loss: 3.325   lengthscale: 7.052   noise: 0.207\n",
      "Iter 281/300 - Loss: 3.327   lengthscale: 7.076   noise: 0.197\n",
      "Iter 291/300 - Loss: 3.307   lengthscale: 7.098   noise: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9262, precision: 1.0000, recall: 0.0519, specificity: 1.0000, cm: [[912   0]\n",
      " [ 73   4]]\n",
      "accuracy: 0.9234, precision: 1.0000, recall: 0.0500, specificity: 1.0000, cm: [[228   0]\n",
      " [ 19   1]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([154, 2048]), train y: torch.Size([154]), test X: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.930   lengthscale: 1.221   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.427   lengthscale: 2.028   noise: 1.980\n",
      "Iter 31/300 - Loss: 5.242   lengthscale: 3.128   noise: 2.560\n",
      "Iter 41/300 - Loss: 5.207   lengthscale: 3.774   noise: 3.001\n",
      "Iter 51/300 - Loss: 5.193   lengthscale: 3.604   noise: 3.320\n",
      "Iter 61/300 - Loss: 5.186   lengthscale: 3.228   noise: 3.518\n",
      "Iter 71/300 - Loss: 5.185   lengthscale: 2.997   noise: 3.616\n",
      "Iter 81/300 - Loss: 5.184   lengthscale: 2.981   noise: 3.648\n",
      "Iter 91/300 - Loss: 5.184   lengthscale: 3.061   noise: 3.642\n",
      "Iter 101/300 - Loss: 5.184   lengthscale: 3.119   noise: 3.618\n",
      "Iter 111/300 - Loss: 5.184   lengthscale: 3.125   noise: 3.584\n",
      "Iter 121/300 - Loss: 5.183   lengthscale: 3.107   noise: 3.546\n",
      "Iter 131/300 - Loss: 5.183   lengthscale: 3.094   noise: 3.504\n",
      "Iter 141/300 - Loss: 5.183   lengthscale: 3.093   noise: 3.460\n",
      "Iter 151/300 - Loss: 5.183   lengthscale: 3.097   noise: 3.414\n",
      "Iter 161/300 - Loss: 5.183   lengthscale: 3.098   noise: 3.366\n",
      "Iter 171/300 - Loss: 5.182   lengthscale: 3.097   noise: 3.317\n",
      "Iter 181/300 - Loss: 5.182   lengthscale: 3.096   noise: 3.267\n",
      "Iter 191/300 - Loss: 5.182   lengthscale: 3.097   noise: 3.215\n",
      "Iter 201/300 - Loss: 5.182   lengthscale: 3.097   noise: 3.162\n",
      "Iter 211/300 - Loss: 5.182   lengthscale: 3.098   noise: 3.107\n",
      "Iter 221/300 - Loss: 5.181   lengthscale: 3.098   noise: 3.051\n",
      "Iter 231/300 - Loss: 5.181   lengthscale: 3.099   noise: 2.994\n",
      "Iter 241/300 - Loss: 5.181   lengthscale: 3.099   noise: 2.935\n",
      "Iter 251/300 - Loss: 5.181   lengthscale: 3.100   noise: 2.876\n",
      "Iter 261/300 - Loss: 5.180   lengthscale: 3.100   noise: 2.815\n",
      "Iter 271/300 - Loss: 5.180   lengthscale: 3.100   noise: 2.753\n",
      "Iter 281/300 - Loss: 5.180   lengthscale: 3.100   noise: 2.691\n",
      "Iter 291/300 - Loss: 5.180   lengthscale: 3.101   noise: 2.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[77  0]\n",
      " [ 0 77]]\n",
      "accuracy: 0.5484, precision: 0.0965, recall: 0.5500, specificity: 0.5482, cm: [[125 103]\n",
      " [  9  11]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n",
      "train X: torch.Size([1824, 2048]), train y: torch.Size([1824]), test X: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.380   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.035   lengthscale: 1.310   noise: 0.842\n",
      "Iter 21/300 - Loss: 4.321   lengthscale: 2.145   noise: 0.939\n",
      "Iter 31/300 - Loss: 3.835   lengthscale: 3.027   noise: 0.714\n",
      "Iter 41/300 - Loss: 3.593   lengthscale: 3.736   noise: 0.360\n",
      "Iter 51/300 - Loss: 3.477   lengthscale: 4.153   noise: 0.147\n",
      "Iter 61/300 - Loss: 3.427   lengthscale: 4.370   noise: 0.066\n",
      "Iter 71/300 - Loss: 3.396   lengthscale: 4.474   noise: 0.037\n",
      "Iter 81/300 - Loss: 3.383   lengthscale: 4.517   noise: 0.025\n",
      "Iter 91/300 - Loss: 3.378   lengthscale: 4.527   noise: 0.020\n",
      "Iter 101/300 - Loss: 3.370   lengthscale: 4.526   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.363   lengthscale: 4.530   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.356   lengthscale: 4.553   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.353   lengthscale: 4.586   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.353   lengthscale: 4.620   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.356   lengthscale: 4.652   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.358   lengthscale: 4.679   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.353   lengthscale: 4.708   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.348   lengthscale: 4.736   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.353   lengthscale: 4.763   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.359   lengthscale: 4.790   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.346   lengthscale: 4.814   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.336   lengthscale: 4.832   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.351   lengthscale: 4.852   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.350   lengthscale: 4.874   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.350   lengthscale: 4.885   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.346   lengthscale: 4.894   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.346   lengthscale: 4.907   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.347   lengthscale: 4.924   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.349   lengthscale: 4.939   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9951, precision: 0.9989, recall: 0.9912, specificity: 0.9989, cm: [[911   1]\n",
      " [  8 904]]\n",
      "accuracy: 0.9556, precision: 0.8462, recall: 0.5500, specificity: 0.9912, cm: [[226   2]\n",
      " [  9  11]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n",
      "train X: torch.Size([1805, 2048]), train y: torch.Size([1805]), test X: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 6.427   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.048   lengthscale: 1.308   noise: 0.850\n",
      "Iter 21/300 - Loss: 4.335   lengthscale: 2.134   noise: 0.952\n",
      "Iter 31/300 - Loss: 3.851   lengthscale: 3.001   noise: 0.748\n",
      "Iter 41/300 - Loss: 3.628   lengthscale: 3.698   noise: 0.391\n",
      "Iter 51/300 - Loss: 3.505   lengthscale: 4.107   noise: 0.162\n",
      "Iter 61/300 - Loss: 3.418   lengthscale: 4.316   noise: 0.072\n",
      "Iter 71/300 - Loss: 3.407   lengthscale: 4.411   noise: 0.040\n",
      "Iter 81/300 - Loss: 3.394   lengthscale: 4.449   noise: 0.027\n",
      "Iter 91/300 - Loss: 3.373   lengthscale: 4.456   noise: 0.020\n",
      "Iter 101/300 - Loss: 3.373   lengthscale: 4.462   noise: 0.017\n",
      "Iter 111/300 - Loss: 3.372   lengthscale: 4.480   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.374   lengthscale: 4.513   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.368   lengthscale: 4.554   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.376   lengthscale: 4.592   noise: 0.010\n",
      "Iter 151/300 - Loss: 3.366   lengthscale: 4.624   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.378   lengthscale: 4.653   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.353   lengthscale: 4.681   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.362   lengthscale: 4.704   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.365   lengthscale: 4.726   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.352   lengthscale: 4.745   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.365   lengthscale: 4.771   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.371   lengthscale: 4.791   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.359   lengthscale: 4.808   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.348   lengthscale: 4.828   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.366   lengthscale: 4.846   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.374   lengthscale: 4.855   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.353   lengthscale: 4.865   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.357   lengthscale: 4.866   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.357   lengthscale: 4.868   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9961, precision: 0.9989, recall: 0.9933, specificity: 0.9989, cm: [[911   1]\n",
      " [  6 887]]\n",
      "accuracy: 0.9516, precision: 0.8333, recall: 0.5000, specificity: 0.9912, cm: [[226   2]\n",
      " [ 10  10]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK5/bind/NEK5_binding_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "\n",
      "NEK9\n",
      "\n",
      "moe scaled\n",
      "train X: torch.Size([1126, 306]), train y: torch.Size([1126]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.109   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.493   lengthscale: 0.955   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.501   lengthscale: 1.361   noise: 1.073\n",
      "Iter 31/300 - Loss: 3.896   lengthscale: 1.864   noise: 1.330\n",
      "Iter 41/300 - Loss: 3.469   lengthscale: 2.510   noise: 1.478\n",
      "Iter 51/300 - Loss: 3.305   lengthscale: 3.118   noise: 1.501\n",
      "Iter 61/300 - Loss: 3.238   lengthscale: 3.545   noise: 1.442\n",
      "Iter 71/300 - Loss: 3.207   lengthscale: 3.831   noise: 1.343\n",
      "Iter 81/300 - Loss: 3.189   lengthscale: 4.031   noise: 1.228\n",
      "Iter 91/300 - Loss: 3.170   lengthscale: 4.187   noise: 1.109\n",
      "Iter 101/300 - Loss: 3.159   lengthscale: 4.315   noise: 0.994\n",
      "Iter 111/300 - Loss: 3.147   lengthscale: 4.423   noise: 0.891\n",
      "Iter 121/300 - Loss: 3.135   lengthscale: 4.515   noise: 0.803\n",
      "Iter 131/300 - Loss: 3.132   lengthscale: 4.593   noise: 0.729\n",
      "Iter 141/300 - Loss: 3.128   lengthscale: 4.659   noise: 0.674\n",
      "Iter 151/300 - Loss: 3.123   lengthscale: 4.715   noise: 0.635\n",
      "Iter 161/300 - Loss: 3.129   lengthscale: 4.761   noise: 0.609\n",
      "Iter 171/300 - Loss: 3.122   lengthscale: 4.799   noise: 0.593\n",
      "Iter 181/300 - Loss: 3.117   lengthscale: 4.830   noise: 0.584\n",
      "Iter 191/300 - Loss: 3.113   lengthscale: 4.855   noise: 0.581\n",
      "Iter 201/300 - Loss: 3.118   lengthscale: 4.877   noise: 0.580\n",
      "Iter 211/300 - Loss: 3.113   lengthscale: 4.896   noise: 0.581\n",
      "Iter 221/300 - Loss: 3.118   lengthscale: 4.911   noise: 0.583\n",
      "Iter 231/300 - Loss: 3.119   lengthscale: 4.925   noise: 0.587\n",
      "Iter 241/300 - Loss: 3.115   lengthscale: 4.935   noise: 0.592\n",
      "Iter 251/300 - Loss: 3.119   lengthscale: 4.945   noise: 0.598\n",
      "Iter 261/300 - Loss: 3.112   lengthscale: 4.953   noise: 0.603\n",
      "Iter 271/300 - Loss: 3.115   lengthscale: 4.959   noise: 0.606\n",
      "Iter 281/300 - Loss: 3.118   lengthscale: 4.966   noise: 0.608\n",
      "Iter 291/300 - Loss: 3.109   lengthscale: 4.970   noise: 0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9574, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [  48    0]]\n",
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: torch.Size([96, 306]), train y: torch.Size([96]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.929   lengthscale: 1.276   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.434   lengthscale: 2.092   noise: 1.980\n",
      "Iter 31/300 - Loss: 5.254   lengthscale: 3.147   noise: 2.565\n",
      "Iter 41/300 - Loss: 5.178   lengthscale: 4.463   noise: 2.979\n",
      "Iter 51/300 - Loss: 5.131   lengthscale: 5.887   noise: 3.219\n",
      "Iter 61/300 - Loss: 5.104   lengthscale: 7.173   noise: 3.311\n",
      "Iter 71/300 - Loss: 5.090   lengthscale: 8.153   noise: 3.311\n",
      "Iter 81/300 - Loss: 5.083   lengthscale: 8.839   noise: 3.270\n",
      "Iter 91/300 - Loss: 5.078   lengthscale: 9.309   noise: 3.215\n",
      "Iter 101/300 - Loss: 5.074   lengthscale: 9.636   noise: 3.157\n",
      "Iter 111/300 - Loss: 5.072   lengthscale: 9.870   noise: 3.098\n",
      "Iter 121/300 - Loss: 5.069   lengthscale: 10.046   noise: 3.037\n",
      "Iter 131/300 - Loss: 5.067   lengthscale: 10.183   noise: 2.973\n",
      "Iter 141/300 - Loss: 5.065   lengthscale: 10.295   noise: 2.907\n",
      "Iter 151/300 - Loss: 5.064   lengthscale: 10.387   noise: 2.839\n",
      "Iter 161/300 - Loss: 5.062   lengthscale: 10.463   noise: 2.770\n",
      "Iter 171/300 - Loss: 5.061   lengthscale: 10.526   noise: 2.700\n",
      "Iter 181/300 - Loss: 5.059   lengthscale: 10.577   noise: 2.631\n",
      "Iter 191/300 - Loss: 5.058   lengthscale: 10.617   noise: 2.562\n",
      "Iter 201/300 - Loss: 5.057   lengthscale: 10.650   noise: 2.495\n",
      "Iter 211/300 - Loss: 5.056   lengthscale: 10.675   noise: 2.428\n",
      "Iter 221/300 - Loss: 5.055   lengthscale: 10.694   noise: 2.363\n",
      "Iter 231/300 - Loss: 5.054   lengthscale: 10.708   noise: 2.298\n",
      "Iter 241/300 - Loss: 5.054   lengthscale: 10.717   noise: 2.235\n",
      "Iter 251/300 - Loss: 5.053   lengthscale: 10.724   noise: 2.174\n",
      "Iter 261/300 - Loss: 5.052   lengthscale: 10.727   noise: 2.114\n",
      "Iter 271/300 - Loss: 5.052   lengthscale: 10.728   noise: 2.055\n",
      "Iter 281/300 - Loss: 5.051   lengthscale: 10.727   noise: 1.997\n",
      "Iter 291/300 - Loss: 5.051   lengthscale: 10.725   noise: 1.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[48  0]\n",
      " [ 0 48]]\n",
      "accuracy: 0.6290, precision: 0.0577, recall: 0.4615, specificity: 0.6370, cm: [[172  98]\n",
      " [  7   6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n",
      "train X: torch.Size([2156, 306]), train y: torch.Size([2156]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.031   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.732   lengthscale: 1.323   noise: 1.285\n",
      "Iter 21/300 - Loss: 4.992   lengthscale: 2.208   noise: 1.794\n",
      "Iter 31/300 - Loss: 4.553   lengthscale: 3.272   noise: 1.810\n",
      "Iter 41/300 - Loss: 4.214   lengthscale: 4.319   noise: 1.358\n",
      "Iter 51/300 - Loss: 3.960   lengthscale: 5.210   noise: 0.758\n",
      "Iter 61/300 - Loss: 3.788   lengthscale: 5.851   noise: 0.337\n",
      "Iter 71/300 - Loss: 3.704   lengthscale: 6.264   noise: 0.151\n",
      "Iter 81/300 - Loss: 3.658   lengthscale: 6.513   noise: 0.082\n",
      "Iter 91/300 - Loss: 3.645   lengthscale: 6.652   noise: 0.054\n",
      "Iter 101/300 - Loss: 3.637   lengthscale: 6.725   noise: 0.041\n",
      "Iter 111/300 - Loss: 3.624   lengthscale: 6.756   noise: 0.033\n",
      "Iter 121/300 - Loss: 3.616   lengthscale: 6.763   noise: 0.028\n",
      "Iter 131/300 - Loss: 3.616   lengthscale: 6.764   noise: 0.024\n",
      "Iter 141/300 - Loss: 3.615   lengthscale: 6.755   noise: 0.021\n",
      "Iter 151/300 - Loss: 3.605   lengthscale: 6.745   noise: 0.019\n",
      "Iter 161/300 - Loss: 3.610   lengthscale: 6.734   noise: 0.017\n",
      "Iter 171/300 - Loss: 3.613   lengthscale: 6.722   noise: 0.015\n",
      "Iter 181/300 - Loss: 3.600   lengthscale: 6.706   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.609   lengthscale: 6.688   noise: 0.013\n",
      "Iter 201/300 - Loss: 3.597   lengthscale: 6.662   noise: 0.012\n",
      "Iter 211/300 - Loss: 3.590   lengthscale: 6.634   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.600   lengthscale: 6.606   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.596   lengthscale: 6.576   noise: 0.009\n",
      "Iter 241/300 - Loss: 3.591   lengthscale: 6.547   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.590   lengthscale: 6.516   noise: 0.008\n",
      "Iter 261/300 - Loss: 3.588   lengthscale: 6.484   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.590   lengthscale: 6.449   noise: 0.007\n",
      "Iter 281/300 - Loss: 3.589   lengthscale: 6.414   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.587   lengthscale: 6.380   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9991, recall: 1.0000, specificity: 0.9991, cm: [[1077    1]\n",
      " [   0 1078]]\n",
      "accuracy: 0.9435, precision: 0.2000, recall: 0.0769, specificity: 0.9852, cm: [[266   4]\n",
      " [ 12   1]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([2164, 306]), train y: torch.Size([2164]), test X: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.035   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.743   lengthscale: 1.321   noise: 1.286\n",
      "Iter 21/300 - Loss: 5.005   lengthscale: 2.204   noise: 1.807\n",
      "Iter 31/300 - Loss: 4.575   lengthscale: 3.268   noise: 1.839\n",
      "Iter 41/300 - Loss: 4.229   lengthscale: 4.320   noise: 1.390\n",
      "Iter 51/300 - Loss: 3.977   lengthscale: 5.219   noise: 0.779\n",
      "Iter 61/300 - Loss: 3.803   lengthscale: 5.870   noise: 0.347\n",
      "Iter 71/300 - Loss: 3.719   lengthscale: 6.291   noise: 0.155\n",
      "Iter 81/300 - Loss: 3.662   lengthscale: 6.548   noise: 0.085\n",
      "Iter 91/300 - Loss: 3.650   lengthscale: 6.695   noise: 0.056\n",
      "Iter 101/300 - Loss: 3.648   lengthscale: 6.769   noise: 0.042\n",
      "Iter 111/300 - Loss: 3.636   lengthscale: 6.802   noise: 0.034\n",
      "Iter 121/300 - Loss: 3.640   lengthscale: 6.812   noise: 0.028\n",
      "Iter 131/300 - Loss: 3.639   lengthscale: 6.810   noise: 0.025\n",
      "Iter 141/300 - Loss: 3.634   lengthscale: 6.806   noise: 0.022\n",
      "Iter 151/300 - Loss: 3.622   lengthscale: 6.798   noise: 0.019\n",
      "Iter 161/300 - Loss: 3.626   lengthscale: 6.789   noise: 0.017\n",
      "Iter 171/300 - Loss: 3.615   lengthscale: 6.776   noise: 0.016\n",
      "Iter 181/300 - Loss: 3.614   lengthscale: 6.759   noise: 0.014\n",
      "Iter 191/300 - Loss: 3.618   lengthscale: 6.739   noise: 0.013\n",
      "Iter 201/300 - Loss: 3.609   lengthscale: 6.713   noise: 0.012\n",
      "Iter 211/300 - Loss: 3.606   lengthscale: 6.685   noise: 0.011\n",
      "Iter 221/300 - Loss: 3.607   lengthscale: 6.660   noise: 0.010\n",
      "Iter 231/300 - Loss: 3.608   lengthscale: 6.631   noise: 0.010\n",
      "Iter 241/300 - Loss: 3.604   lengthscale: 6.600   noise: 0.009\n",
      "Iter 251/300 - Loss: 3.603   lengthscale: 6.568   noise: 0.009\n",
      "Iter 261/300 - Loss: 3.596   lengthscale: 6.535   noise: 0.008\n",
      "Iter 271/300 - Loss: 3.595   lengthscale: 6.504   noise: 0.008\n",
      "Iter 281/300 - Loss: 3.601   lengthscale: 6.472   noise: 0.007\n",
      "Iter 291/300 - Loss: 3.592   lengthscale: 6.438   noise: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9995, precision: 0.9991, recall: 1.0000, specificity: 0.9991, cm: [[1077    1]\n",
      " [   0 1086]]\n",
      "accuracy: 0.9435, precision: 0.2000, recall: 0.0769, specificity: 0.9852, cm: [[266   4]\n",
      " [ 12   1]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([1126, 2048]), train y: torch.Size([1126]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.098   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.468   lengthscale: 1.266   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.339   lengthscale: 2.087   noise: 1.067\n",
      "Iter 31/300 - Loss: 3.367   lengthscale: 3.172   noise: 1.263\n",
      "Iter 41/300 - Loss: 3.206   lengthscale: 4.226   noise: 1.292\n",
      "Iter 51/300 - Loss: 3.167   lengthscale: 5.026   noise: 1.229\n",
      "Iter 61/300 - Loss: 3.150   lengthscale: 5.606   noise: 1.126\n",
      "Iter 71/300 - Loss: 3.138   lengthscale: 6.034   noise: 1.009\n",
      "Iter 81/300 - Loss: 3.112   lengthscale: 6.359   noise: 0.888\n",
      "Iter 91/300 - Loss: 3.105   lengthscale: 6.621   noise: 0.774\n",
      "Iter 101/300 - Loss: 3.095   lengthscale: 6.841   noise: 0.674\n",
      "Iter 111/300 - Loss: 3.083   lengthscale: 7.032   noise: 0.589\n",
      "Iter 121/300 - Loss: 3.077   lengthscale: 7.200   noise: 0.521\n",
      "Iter 131/300 - Loss: 3.083   lengthscale: 7.349   noise: 0.468\n",
      "Iter 141/300 - Loss: 3.080   lengthscale: 7.484   noise: 0.429\n",
      "Iter 151/300 - Loss: 3.082   lengthscale: 7.606   noise: 0.400\n",
      "Iter 161/300 - Loss: 3.070   lengthscale: 7.720   noise: 0.378\n",
      "Iter 171/300 - Loss: 3.078   lengthscale: 7.826   noise: 0.361\n",
      "Iter 181/300 - Loss: 3.070   lengthscale: 7.922   noise: 0.348\n",
      "Iter 191/300 - Loss: 3.068   lengthscale: 8.007   noise: 0.337\n",
      "Iter 201/300 - Loss: 3.077   lengthscale: 8.086   noise: 0.328\n",
      "Iter 211/300 - Loss: 3.072   lengthscale: 8.161   noise: 0.320\n",
      "Iter 221/300 - Loss: 3.069   lengthscale: 8.234   noise: 0.313\n",
      "Iter 231/300 - Loss: 3.063   lengthscale: 8.302   noise: 0.308\n",
      "Iter 241/300 - Loss: 3.073   lengthscale: 8.368   noise: 0.302\n",
      "Iter 251/300 - Loss: 3.069   lengthscale: 8.430   noise: 0.296\n",
      "Iter 261/300 - Loss: 3.072   lengthscale: 8.488   noise: 0.292\n",
      "Iter 271/300 - Loss: 3.066   lengthscale: 8.543   noise: 0.288\n",
      "Iter 281/300 - Loss: 3.069   lengthscale: 8.594   noise: 0.284\n",
      "Iter 291/300 - Loss: 3.065   lengthscale: 8.644   noise: 0.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9574, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[1078    0]\n",
      " [  48    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([96, 2048]), train y: torch.Size([96]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.739   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.509   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.436   noise: 2.576\n",
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.410   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.400   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.396   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.395   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.897\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.895\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.894\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.893\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.893\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.394   noise: 3.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[48  0]\n",
      " [ 0 48]]\n",
      "accuracy: 0.9541, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[270   0]\n",
      " [ 13   0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n",
      "train X: torch.Size([2156, 2048]), train y: torch.Size([2156]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.135   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.889   lengthscale: 1.311   noise: 0.796\n",
      "Iter 21/300 - Loss: 4.235   lengthscale: 2.145   noise: 0.887\n",
      "Iter 31/300 - Loss: 3.715   lengthscale: 3.001   noise: 0.628\n",
      "Iter 41/300 - Loss: 3.471   lengthscale: 3.682   noise: 0.292\n",
      "Iter 51/300 - Loss: 3.361   lengthscale: 4.067   noise: 0.116\n",
      "Iter 61/300 - Loss: 3.310   lengthscale: 4.250   noise: 0.054\n",
      "Iter 71/300 - Loss: 3.277   lengthscale: 4.321   noise: 0.033\n",
      "Iter 81/300 - Loss: 3.260   lengthscale: 4.340   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.259   lengthscale: 4.352   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.248   lengthscale: 4.378   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.255   lengthscale: 4.409   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.254   lengthscale: 4.434   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.248   lengthscale: 4.452   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.244   lengthscale: 4.470   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.243   lengthscale: 4.489   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.244   lengthscale: 4.510   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.237   lengthscale: 4.527   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.248   lengthscale: 4.543   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.248   lengthscale: 4.558   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.236   lengthscale: 4.572   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.237   lengthscale: 4.582   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.241   lengthscale: 4.593   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.236   lengthscale: 4.601   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.235   lengthscale: 4.608   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.239   lengthscale: 4.615   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.230   lengthscale: 4.619   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.236   lengthscale: 4.619   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.234   lengthscale: 4.621   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.235   lengthscale: 4.624   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9944, precision: 0.9981, recall: 0.9907, specificity: 0.9981, cm: [[1076    2]\n",
      " [  10 1068]]\n",
      "accuracy: 0.9505, precision: 0.3333, recall: 0.0769, specificity: 0.9926, cm: [[268   2]\n",
      " [ 12   1]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n",
      "train X: torch.Size([2166, 2048]), train y: torch.Size([2166]), test X: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 6.103   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 4.872   lengthscale: 1.308   noise: 0.795\n",
      "Iter 21/300 - Loss: 4.220   lengthscale: 2.137   noise: 0.880\n",
      "Iter 31/300 - Loss: 3.710   lengthscale: 2.989   noise: 0.613\n",
      "Iter 41/300 - Loss: 3.453   lengthscale: 3.667   noise: 0.282\n",
      "Iter 51/300 - Loss: 3.340   lengthscale: 4.048   noise: 0.112\n",
      "Iter 61/300 - Loss: 3.290   lengthscale: 4.227   noise: 0.053\n",
      "Iter 71/300 - Loss: 3.271   lengthscale: 4.297   noise: 0.032\n",
      "Iter 81/300 - Loss: 3.259   lengthscale: 4.321   noise: 0.023\n",
      "Iter 91/300 - Loss: 3.248   lengthscale: 4.340   noise: 0.018\n",
      "Iter 101/300 - Loss: 3.247   lengthscale: 4.368   noise: 0.015\n",
      "Iter 111/300 - Loss: 3.248   lengthscale: 4.396   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.236   lengthscale: 4.416   noise: 0.011\n",
      "Iter 131/300 - Loss: 3.241   lengthscale: 4.432   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.244   lengthscale: 4.449   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.239   lengthscale: 4.466   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.234   lengthscale: 4.484   noise: 0.007\n",
      "Iter 171/300 - Loss: 3.231   lengthscale: 4.502   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.236   lengthscale: 4.518   noise: 0.006\n",
      "Iter 191/300 - Loss: 3.229   lengthscale: 4.531   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.232   lengthscale: 4.543   noise: 0.005\n",
      "Iter 211/300 - Loss: 3.232   lengthscale: 4.555   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.228   lengthscale: 4.565   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.227   lengthscale: 4.572   noise: 0.004\n",
      "Iter 241/300 - Loss: 3.235   lengthscale: 4.579   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.223   lengthscale: 4.587   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.235   lengthscale: 4.592   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.231   lengthscale: 4.596   noise: 0.003\n",
      "Iter 281/300 - Loss: 3.221   lengthscale: 4.597   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.224   lengthscale: 4.598   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9940, precision: 0.9981, recall: 0.9899, specificity: 0.9981, cm: [[1076    2]\n",
      " [  11 1077]]\n",
      "accuracy: 0.9505, precision: 0.3333, recall: 0.0769, specificity: 0.9926, cm: [[268   2]\n",
      " [ 12   1]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/bind/NEK9_binding_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "\n",
      "moe scaled\n",
      "train X: torch.Size([313, 306]), train y: torch.Size([313]), test X: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.617   lengthscale: 0.898   noise: 0.809\n",
      "Iter 21/300 - Loss: 4.738   lengthscale: 1.241   noise: 1.073\n",
      "Iter 31/300 - Loss: 4.267   lengthscale: 1.742   noise: 1.333\n",
      "Iter 41/300 - Loss: 3.961   lengthscale: 2.382   noise: 1.508\n",
      "Iter 51/300 - Loss: 3.754   lengthscale: 3.116   noise: 1.573\n",
      "Iter 61/300 - Loss: 3.662   lengthscale: 3.758   noise: 1.543\n",
      "Iter 71/300 - Loss: 3.621   lengthscale: 4.222   noise: 1.454\n",
      "Iter 81/300 - Loss: 3.597   lengthscale: 4.542   noise: 1.336\n",
      "Iter 91/300 - Loss: 3.580   lengthscale: 4.772   noise: 1.205\n",
      "Iter 101/300 - Loss: 3.567   lengthscale: 4.945   noise: 1.073\n",
      "Iter 111/300 - Loss: 3.557   lengthscale: 5.079   noise: 0.946\n",
      "Iter 121/300 - Loss: 3.548   lengthscale: 5.185   noise: 0.830\n",
      "Iter 131/300 - Loss: 3.541   lengthscale: 5.268   noise: 0.727\n",
      "Iter 141/300 - Loss: 3.535   lengthscale: 5.331   noise: 0.639\n",
      "Iter 151/300 - Loss: 3.531   lengthscale: 5.376   noise: 0.565\n",
      "Iter 161/300 - Loss: 3.527   lengthscale: 5.406   noise: 0.503\n",
      "Iter 171/300 - Loss: 3.524   lengthscale: 5.424   noise: 0.452\n",
      "Iter 181/300 - Loss: 3.521   lengthscale: 5.432   noise: 0.409\n",
      "Iter 191/300 - Loss: 3.518   lengthscale: 5.433   noise: 0.372\n",
      "Iter 201/300 - Loss: 3.516   lengthscale: 5.428   noise: 0.340\n",
      "Iter 211/300 - Loss: 3.514   lengthscale: 5.420   noise: 0.311\n",
      "Iter 221/300 - Loss: 3.512   lengthscale: 5.409   noise: 0.286\n",
      "Iter 231/300 - Loss: 3.511   lengthscale: 5.396   noise: 0.264\n",
      "Iter 241/300 - Loss: 3.509   lengthscale: 5.383   noise: 0.244\n",
      "Iter 251/300 - Loss: 3.508   lengthscale: 5.369   noise: 0.225\n",
      "Iter 261/300 - Loss: 3.507   lengthscale: 5.355   noise: 0.209\n",
      "Iter 271/300 - Loss: 3.506   lengthscale: 5.340   noise: 0.194\n",
      "Iter 281/300 - Loss: 3.505   lengthscale: 5.326   noise: 0.180\n",
      "Iter 291/300 - Loss: 3.504   lengthscale: 5.312   noise: 0.168\n",
      "accuracy: 0.8978, precision: 1.0000, recall: 0.0303, specificity: 1.0000, cm: [[280   0]\n",
      " [ 32   1]]\n",
      "accuracy: 0.8750, precision: 0.0000, recall: 0.0000, specificity: 0.9859, cm: [[70  1]\n",
      " [ 9  0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_scaled_test_GP.csv\n",
      "\n",
      "moe UNDER\n",
      "train X: torch.Size([66, 306]), train y: torch.Size([66]), test X: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 0.693   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.441   lengthscale: 0.693   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.272   lengthscale: 0.693   noise: 2.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 41/300 - Loss: 5.222   lengthscale: 0.693   noise: 3.023\n",
      "Iter 51/300 - Loss: 5.208   lengthscale: 0.693   noise: 3.341\n",
      "Iter 61/300 - Loss: 5.204   lengthscale: 0.693   noise: 3.562\n",
      "Iter 71/300 - Loss: 5.203   lengthscale: 0.693   noise: 3.710\n",
      "Iter 81/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.804\n",
      "Iter 91/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.858\n",
      "Iter 101/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.885\n",
      "Iter 111/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.897\n",
      "Iter 121/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.899\n",
      "Iter 131/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.898\n",
      "Iter 141/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.896\n",
      "Iter 151/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.895\n",
      "Iter 161/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.894\n",
      "Iter 171/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 181/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 191/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.893\n",
      "Iter 201/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 211/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 221/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 231/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 241/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 251/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 261/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 271/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 281/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "Iter 291/300 - Loss: 5.202   lengthscale: 0.693   noise: 3.892\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[33  0]\n",
      " [ 0 33]]\n",
      "accuracy: 0.1125, precision: 0.1125, recall: 1.0000, specificity: 0.0000, cm: [[ 0 71]\n",
      " [ 0  9]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_UNDER_test_GP.csv\n",
      "\n",
      "moe SMOTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: torch.Size([560, 306]), train y: torch.Size([560]), test X: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.072   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.831   lengthscale: 1.321   noise: 1.292\n",
      "Iter 21/300 - Loss: 5.165   lengthscale: 2.202   noise: 1.892\n",
      "Iter 31/300 - Loss: 4.714   lengthscale: 3.316   noise: 2.103\n",
      "Iter 41/300 - Loss: 4.383   lengthscale: 4.463   noise: 1.785\n",
      "Iter 51/300 - Loss: 4.107   lengthscale: 5.480   noise: 1.153\n",
      "Iter 61/300 - Loss: 3.898   lengthscale: 6.283   noise: 0.570\n",
      "Iter 71/300 - Loss: 3.766   lengthscale: 6.871   noise: 0.250\n",
      "Iter 81/300 - Loss: 3.699   lengthscale: 7.290   noise: 0.124\n",
      "Iter 91/300 - Loss: 3.666   lengthscale: 7.584   noise: 0.076\n",
      "Iter 101/300 - Loss: 3.648   lengthscale: 7.789   noise: 0.054\n",
      "Iter 111/300 - Loss: 3.638   lengthscale: 7.931   noise: 0.042\n",
      "Iter 121/300 - Loss: 3.630   lengthscale: 8.030   noise: 0.035\n",
      "Iter 131/300 - Loss: 3.625   lengthscale: 8.102   noise: 0.029\n",
      "Iter 141/300 - Loss: 3.621   lengthscale: 8.157   noise: 0.026\n",
      "Iter 151/300 - Loss: 3.617   lengthscale: 8.201   noise: 0.023\n",
      "Iter 161/300 - Loss: 3.614   lengthscale: 8.237   noise: 0.020\n",
      "Iter 171/300 - Loss: 3.612   lengthscale: 8.266   noise: 0.018\n",
      "Iter 181/300 - Loss: 3.610   lengthscale: 8.289   noise: 0.017\n",
      "Iter 191/300 - Loss: 3.608   lengthscale: 8.306   noise: 0.015\n",
      "Iter 201/300 - Loss: 3.606   lengthscale: 8.318   noise: 0.014\n",
      "Iter 211/300 - Loss: 3.604   lengthscale: 8.326   noise: 0.013\n",
      "Iter 221/300 - Loss: 3.602   lengthscale: 8.330   noise: 0.012\n",
      "Iter 231/300 - Loss: 3.601   lengthscale: 8.331   noise: 0.011\n",
      "Iter 241/300 - Loss: 3.600   lengthscale: 8.329   noise: 0.011\n",
      "Iter 251/300 - Loss: 3.599   lengthscale: 8.325   noise: 0.010\n",
      "Iter 261/300 - Loss: 3.598   lengthscale: 8.320   noise: 0.009\n",
      "Iter 271/300 - Loss: 3.597   lengthscale: 8.314   noise: 0.009\n",
      "Iter 281/300 - Loss: 3.596   lengthscale: 8.307   noise: 0.008\n",
      "Iter 291/300 - Loss: 3.595   lengthscale: 8.300   noise: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9946, precision: 0.9894, recall: 1.0000, specificity: 0.9893, cm: [[277   3]\n",
      " [  0 280]]\n",
      "accuracy: 0.9500, precision: 0.8571, recall: 0.6667, specificity: 0.9859, cm: [[70  1]\n",
      " [ 3  6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_SMOTE_test_GP.csv\n",
      "\n",
      "moe ADASYN\n",
      "train X: torch.Size([560, 306]), train y: torch.Size([560]), test X: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.067   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.808   lengthscale: 1.319   noise: 1.291\n",
      "Iter 21/300 - Loss: 5.119   lengthscale: 2.198   noise: 1.868\n",
      "Iter 31/300 - Loss: 4.698   lengthscale: 3.290   noise: 2.032\n",
      "Iter 41/300 - Loss: 4.385   lengthscale: 4.395   noise: 1.693\n",
      "Iter 51/300 - Loss: 4.113   lengthscale: 5.384   noise: 1.070\n",
      "Iter 61/300 - Loss: 3.909   lengthscale: 6.167   noise: 0.518\n",
      "Iter 71/300 - Loss: 3.785   lengthscale: 6.728   noise: 0.227\n",
      "Iter 81/300 - Loss: 3.724   lengthscale: 7.113   noise: 0.115\n",
      "Iter 91/300 - Loss: 3.695   lengthscale: 7.370   noise: 0.071\n",
      "Iter 101/300 - Loss: 3.679   lengthscale: 7.537   noise: 0.051\n",
      "Iter 111/300 - Loss: 3.669   lengthscale: 7.642   noise: 0.040\n",
      "Iter 121/300 - Loss: 3.662   lengthscale: 7.707   noise: 0.033\n",
      "Iter 131/300 - Loss: 3.657   lengthscale: 7.748   noise: 0.029\n",
      "Iter 141/300 - Loss: 3.652   lengthscale: 7.775   noise: 0.025\n",
      "Iter 151/300 - Loss: 3.649   lengthscale: 7.793   noise: 0.022\n",
      "Iter 161/300 - Loss: 3.646   lengthscale: 7.805   noise: 0.020\n",
      "Iter 171/300 - Loss: 3.643   lengthscale: 7.812   noise: 0.018\n",
      "Iter 181/300 - Loss: 3.640   lengthscale: 7.814   noise: 0.016\n",
      "Iter 191/300 - Loss: 3.638   lengthscale: 7.812   noise: 0.015\n",
      "Iter 201/300 - Loss: 3.636   lengthscale: 7.805   noise: 0.014\n",
      "Iter 211/300 - Loss: 3.634   lengthscale: 7.795   noise: 0.013\n",
      "Iter 221/300 - Loss: 3.632   lengthscale: 7.782   noise: 0.012\n",
      "Iter 231/300 - Loss: 3.630   lengthscale: 7.767   noise: 0.011\n",
      "Iter 241/300 - Loss: 3.629   lengthscale: 7.751   noise: 0.010\n",
      "Iter 251/300 - Loss: 3.628   lengthscale: 7.734   noise: 0.010\n",
      "Iter 261/300 - Loss: 3.626   lengthscale: 7.719   noise: 0.009\n",
      "Iter 271/300 - Loss: 3.625   lengthscale: 7.704   noise: 0.009\n",
      "Iter 281/300 - Loss: 3.625   lengthscale: 7.692   noise: 0.008\n",
      "Iter 291/300 - Loss: 3.624   lengthscale: 7.683   noise: 0.008\n",
      "accuracy: 0.9964, precision: 0.9929, recall: 1.0000, specificity: 0.9929, cm: [[278   2]\n",
      " [  0 280]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9500, precision: 0.8571, recall: 0.6667, specificity: 0.9859, cm: [[70  1]\n",
      " [ 3  6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_moe_ADASYN_test_GP.csv\n",
      "\n",
      "\n",
      "mfp scaled\n",
      "train X: torch.Size([313, 2048]), train y: torch.Size([313]), test X: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.095   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.598   lengthscale: 1.247   noise: 0.808\n",
      "Iter 21/300 - Loss: 4.618   lengthscale: 2.062   noise: 1.068\n",
      "Iter 31/300 - Loss: 3.798   lengthscale: 3.169   noise: 1.276\n",
      "Iter 41/300 - Loss: 3.570   lengthscale: 4.257   noise: 1.311\n",
      "Iter 51/300 - Loss: 3.520   lengthscale: 4.975   noise: 1.232\n",
      "Iter 61/300 - Loss: 3.493   lengthscale: 5.395   noise: 1.100\n",
      "Iter 71/300 - Loss: 3.472   lengthscale: 5.653   noise: 0.947\n",
      "Iter 81/300 - Loss: 3.454   lengthscale: 5.831   noise: 0.792\n",
      "Iter 91/300 - Loss: 3.438   lengthscale: 5.969   noise: 0.647\n",
      "Iter 101/300 - Loss: 3.425   lengthscale: 6.086   noise: 0.521\n",
      "Iter 111/300 - Loss: 3.415   lengthscale: 6.190   noise: 0.418\n",
      "Iter 121/300 - Loss: 3.408   lengthscale: 6.285   noise: 0.339\n",
      "Iter 131/300 - Loss: 3.402   lengthscale: 6.372   noise: 0.279\n",
      "Iter 141/300 - Loss: 3.398   lengthscale: 6.455   noise: 0.234\n",
      "Iter 151/300 - Loss: 3.394   lengthscale: 6.533   noise: 0.201\n",
      "Iter 161/300 - Loss: 3.392   lengthscale: 6.609   noise: 0.175\n",
      "Iter 171/300 - Loss: 3.389   lengthscale: 6.682   noise: 0.155\n",
      "Iter 181/300 - Loss: 3.387   lengthscale: 6.755   noise: 0.139\n",
      "Iter 191/300 - Loss: 3.386   lengthscale: 6.829   noise: 0.125\n",
      "Iter 201/300 - Loss: 3.384   lengthscale: 6.904   noise: 0.114\n",
      "Iter 211/300 - Loss: 3.383   lengthscale: 6.982   noise: 0.105\n",
      "Iter 221/300 - Loss: 3.381   lengthscale: 7.063   noise: 0.097\n",
      "Iter 231/300 - Loss: 3.380   lengthscale: 7.150   noise: 0.090\n",
      "Iter 241/300 - Loss: 3.379   lengthscale: 7.243   noise: 0.084\n",
      "Iter 251/300 - Loss: 3.377   lengthscale: 7.343   noise: 0.078\n",
      "Iter 261/300 - Loss: 3.376   lengthscale: 7.452   noise: 0.073\n",
      "Iter 271/300 - Loss: 3.375   lengthscale: 7.570   noise: 0.069\n",
      "Iter 281/300 - Loss: 3.374   lengthscale: 7.695   noise: 0.065\n",
      "Iter 291/300 - Loss: 3.373   lengthscale: 7.826   noise: 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9681, precision: 0.9600, recall: 0.7273, specificity: 0.9964, cm: [[279   1]\n",
      " [  9  24]]\n",
      "accuracy: 0.9375, precision: 0.8333, recall: 0.5556, specificity: 0.9859, cm: [[70  1]\n",
      " [ 4  5]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_scaled_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_scaled_test_GP.csv\n",
      "\n",
      "mfp UNDER\n",
      "train X: torch.Size([66, 2048]), train y: torch.Size([66]), test X: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.943   lengthscale: 1.000   noise: 1.298\n",
      "Iter 21/300 - Loss: 5.456   lengthscale: 1.269   noise: 1.995\n",
      "Iter 31/300 - Loss: 5.292   lengthscale: 1.545   noise: 2.620\n",
      "Iter 41/300 - Loss: 5.240   lengthscale: 1.154   noise: 3.116\n",
      "Iter 51/300 - Loss: 5.225   lengthscale: 0.866   noise: 3.485\n",
      "Iter 61/300 - Loss: 5.220   lengthscale: 0.711   noise: 3.755\n",
      "Iter 71/300 - Loss: 5.218   lengthscale: 0.576   noise: 3.952\n",
      "Iter 81/300 - Loss: 5.217   lengthscale: 0.465   noise: 4.088\n",
      "Iter 91/300 - Loss: 5.209   lengthscale: 0.402   noise: 4.181\n",
      "Iter 101/300 - Loss: 5.209   lengthscale: 0.373   noise: 4.247\n",
      "Iter 111/300 - Loss: 5.216   lengthscale: 0.358   noise: 4.300\n",
      "Iter 121/300 - Loss: 5.209   lengthscale: 0.351   noise: 4.343\n",
      "Iter 131/300 - Loss: 5.216   lengthscale: 0.346   noise: 4.385\n",
      "Iter 141/300 - Loss: 5.208   lengthscale: 0.343   noise: 4.429\n",
      "Iter 151/300 - Loss: 5.208   lengthscale: 0.341   noise: 4.475\n",
      "Iter 161/300 - Loss: 5.215   lengthscale: 0.338   noise: 4.517\n",
      "Iter 171/300 - Loss: 5.208   lengthscale: 0.336   noise: 4.563\n",
      "Iter 181/300 - Loss: 5.208   lengthscale: 0.334   noise: 4.598\n",
      "Iter 191/300 - Loss: 5.214   lengthscale: 0.333   noise: 4.635\n",
      "Iter 201/300 - Loss: 5.214   lengthscale: 0.331   noise: 4.693\n",
      "Iter 211/300 - Loss: 5.214   lengthscale: 0.330   noise: 4.760\n",
      "Iter 221/300 - Loss: 5.213   lengthscale: 0.328   noise: 4.830\n",
      "Iter 231/300 - Loss: 5.213   lengthscale: 0.327   noise: 4.899\n",
      "Iter 241/300 - Loss: 5.212   lengthscale: 0.326   noise: 4.968\n",
      "Iter 251/300 - Loss: 5.212   lengthscale: 0.324   noise: 5.037\n",
      "Iter 261/300 - Loss: 5.212   lengthscale: 0.323   noise: 5.106\n",
      "Iter 271/300 - Loss: 5.211   lengthscale: 0.322   noise: 5.175\n",
      "Iter 281/300 - Loss: 5.211   lengthscale: 0.321   noise: 5.244\n",
      "Iter 291/300 - Loss: 5.211   lengthscale: 0.320   noise: 5.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2155: NumericalWarning: Runtime Error when computing Cholesky decomposition: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.. Using symeig method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9848, precision: 0.9706, recall: 1.0000, specificity: 0.9697, cm: [[32  1]\n",
      " [ 0 33]]\n",
      "accuracy: 0.8875, precision: 0.0000, recall: 0.0000, specificity: 1.0000, cm: [[71  0]\n",
      " [ 9  0]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_UNDER_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_UNDER_test_GP.csv\n",
      "\n",
      "mfp SMOTE\n",
      "train X: torch.Size([560, 2048]), train y: torch.Size([560]), test X: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 6.467   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.084   lengthscale: 1.316   noise: 0.903\n",
      "Iter 21/300 - Loss: 4.371   lengthscale: 2.143   noise: 0.974\n",
      "Iter 31/300 - Loss: 3.829   lengthscale: 3.054   noise: 0.738\n",
      "Iter 41/300 - Loss: 3.573   lengthscale: 3.824   noise: 0.374\n",
      "Iter 51/300 - Loss: 3.443   lengthscale: 4.320   noise: 0.152\n",
      "Iter 61/300 - Loss: 3.382   lengthscale: 4.631   noise: 0.068\n",
      "Iter 71/300 - Loss: 3.355   lengthscale: 4.837   noise: 0.039\n",
      "Iter 81/300 - Loss: 3.342   lengthscale: 4.982   noise: 0.027\n",
      "Iter 91/300 - Loss: 3.335   lengthscale: 5.091   noise: 0.021\n",
      "Iter 101/300 - Loss: 3.330   lengthscale: 5.176   noise: 0.017\n",
      "Iter 111/300 - Loss: 3.326   lengthscale: 5.248   noise: 0.014\n",
      "Iter 121/300 - Loss: 3.323   lengthscale: 5.310   noise: 0.013\n",
      "Iter 131/300 - Loss: 3.320   lengthscale: 5.368   noise: 0.011\n",
      "Iter 141/300 - Loss: 3.318   lengthscale: 5.423   noise: 0.010\n",
      "Iter 151/300 - Loss: 3.316   lengthscale: 5.475   noise: 0.009\n",
      "Iter 161/300 - Loss: 3.315   lengthscale: 5.525   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.313   lengthscale: 5.573   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.312   lengthscale: 5.618   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.311   lengthscale: 5.661   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.310   lengthscale: 5.702   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.309   lengthscale: 5.741   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.308   lengthscale: 5.779   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.307   lengthscale: 5.814   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.306   lengthscale: 5.848   noise: 0.005\n",
      "Iter 251/300 - Loss: 3.306   lengthscale: 5.880   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.305   lengthscale: 5.910   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.304   lengthscale: 5.939   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.304   lengthscale: 5.966   noise: 0.004\n",
      "Iter 291/300 - Loss: 3.303   lengthscale: 5.992   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9911, precision: 0.9893, recall: 0.9929, specificity: 0.9893, cm: [[277   3]\n",
      " [  2 278]]\n",
      "accuracy: 0.9500, precision: 0.8571, recall: 0.6667, specificity: 0.9859, cm: [[70  1]\n",
      " [ 3  6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_SMOTE_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_SMOTE_test_GP.csv\n",
      "\n",
      "mfp ADASYN\n",
      "train X: torch.Size([555, 2048]), train y: torch.Size([555]), test X: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 6.282   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 4.992   lengthscale: 1.312   noise: 0.798\n",
      "Iter 21/300 - Loss: 4.359   lengthscale: 2.129   noise: 0.917\n",
      "Iter 31/300 - Loss: 3.855   lengthscale: 3.039   noise: 0.697\n",
      "Iter 41/300 - Loss: 3.606   lengthscale: 3.806   noise: 0.346\n",
      "Iter 51/300 - Loss: 3.485   lengthscale: 4.278   noise: 0.138\n",
      "Iter 61/300 - Loss: 3.431   lengthscale: 4.542   noise: 0.062\n",
      "Iter 71/300 - Loss: 3.409   lengthscale: 4.690   noise: 0.035\n",
      "Iter 81/300 - Loss: 3.397   lengthscale: 4.775   noise: 0.025\n",
      "Iter 91/300 - Loss: 3.391   lengthscale: 4.828   noise: 0.019\n",
      "Iter 101/300 - Loss: 3.386   lengthscale: 4.868   noise: 0.016\n",
      "Iter 111/300 - Loss: 3.383   lengthscale: 4.903   noise: 0.013\n",
      "Iter 121/300 - Loss: 3.380   lengthscale: 4.938   noise: 0.012\n",
      "Iter 131/300 - Loss: 3.378   lengthscale: 4.975   noise: 0.010\n",
      "Iter 141/300 - Loss: 3.376   lengthscale: 5.013   noise: 0.009\n",
      "Iter 151/300 - Loss: 3.374   lengthscale: 5.050   noise: 0.008\n",
      "Iter 161/300 - Loss: 3.372   lengthscale: 5.085   noise: 0.008\n",
      "Iter 171/300 - Loss: 3.371   lengthscale: 5.118   noise: 0.007\n",
      "Iter 181/300 - Loss: 3.370   lengthscale: 5.148   noise: 0.007\n",
      "Iter 191/300 - Loss: 3.369   lengthscale: 5.177   noise: 0.006\n",
      "Iter 201/300 - Loss: 3.368   lengthscale: 5.202   noise: 0.006\n",
      "Iter 211/300 - Loss: 3.367   lengthscale: 5.226   noise: 0.005\n",
      "Iter 221/300 - Loss: 3.366   lengthscale: 5.248   noise: 0.005\n",
      "Iter 231/300 - Loss: 3.365   lengthscale: 5.268   noise: 0.005\n",
      "Iter 241/300 - Loss: 3.364   lengthscale: 5.286   noise: 0.004\n",
      "Iter 251/300 - Loss: 3.363   lengthscale: 5.303   noise: 0.004\n",
      "Iter 261/300 - Loss: 3.363   lengthscale: 5.318   noise: 0.004\n",
      "Iter 271/300 - Loss: 3.362   lengthscale: 5.331   noise: 0.004\n",
      "Iter 281/300 - Loss: 3.361   lengthscale: 5.343   noise: 0.003\n",
      "Iter 291/300 - Loss: 3.361   lengthscale: 5.354   noise: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9946, precision: 0.9892, recall: 1.0000, specificity: 0.9893, cm: [[277   3]\n",
      " [  0 275]]\n",
      "accuracy: 0.9500, precision: 0.8571, recall: 0.6667, specificity: 0.9859, cm: [[70  1]\n",
      " [ 3  6]]\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_ADASYN_train_GP.csv\n",
      "/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/NEK9/inhib/NEK9_inhibition_mfp_ADASYN_test_GP.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "nek_nums = [2,3,5,9]\n",
    "samplings = ['scaled', 'UNDER', 'SMOTE', 'ADASYN'] \n",
    "features = ['moe', 'mfp']\n",
    "NEK= 'NEK'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    nek_path= f'{data_dir}NEK{nek}/bind/'\n",
    " \n",
    "    for k, feat in enumerate(features): \n",
    "        print()\n",
    "        for j, samp in enumerate(samplings): \n",
    "        \n",
    "            print(f'NEK{nek} {feat} {samp}')\n",
    "            file_root = f'NEK{nek}_binding_{feat}_{samp}'\n",
    "            # print(file_root)\n",
    "            trainX, trainy, testX, testy = make_torch_tens(nek_path,file_root)\n",
    "            # train_perf_df = save_results(trainX, trainy, file_root, 'train', n_iterations=300, n_samples=256)\n",
    "            # test_perf_df = save_results(testX, testy, file_root, 'test', n_iterations=300, n_samples=100)\n",
    "            train_perf_df, test_perf_df = save_results(trainX, trainy, testX, testy,file_root, n_iterations=300)\n",
    "            train_perf_df.to_csv(f'{nek_path}{file_root}_train_GP.csv',index=False) \n",
    "            test_perf_df.to_csv(f'{nek_path}{file_root}_test_GP.csv',index=False) \n",
    "            print(f'{nek_path}{file_root}_train_GP.csv')\n",
    "            print(f'{nek_path}{file_root}_test_GP.csv')\n",
    "            print()\n",
    "            \n",
    "            \n",
    "    print()\n",
    "    \n",
    "    if n == 2 or n == 9:\n",
    "\n",
    "        nek_path= f'{data_dir}NEK{nek}/inhib/'\n",
    "        for k, feat in enumerate(features): \n",
    "            print()\n",
    "            for j, samp in enumerate(samplings): \n",
    "                file_root = f'NEK{nek}_inhibition_{feat}_{samp}'\n",
    "                print(f'NEK{nek} {feat} {samp}')\n",
    "                trainX, trainy, testX, testy = make_torch_tens(nek_path,file_root)\n",
    "                train_perf_df, test_perf_df = save_results(trainX, trainy, testX, testy,file_root, n_iterations=300)\n",
    "                train_perf_df.to_csv(f'{nek_path}{file_root}_train_GP.csv',index=False) \n",
    "                test_perf_df.to_csv(f'{nek_path}{file_root}_test_GP.csv',index=False) \n",
    "                print(f'{nek_path}{file_root}_train_GP.csv')\n",
    "                print(f'{nek_path}{file_root}_test_GP.csv')\n",
    "                print()\n",
    "        \n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315eca9e-49ac-4a61-9999-074fd2b8d9ff",
   "metadata": {},
   "source": [
    "# Adding more metrics to csv results files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7648877-7770-4a91-a025-e1e6608b4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix\n",
    "import sys\n",
    "sys.path.append('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/')\n",
    "from RF_atomver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a47dc5b-48c6-4985-832f-ea686bd00bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cm(filepath, filename): \n",
    "    # print(filepath)\n",
    "    # print(filename)\n",
    "    df = pd.read_csv(filepath+filename)\n",
    "    \n",
    "    true_labels = df['y'] \n",
    "    predictions = df['y_pred']\n",
    "    cm = confusion_matrix(true_labels, predictions )\n",
    "    cm_flattened = cm.flatten().tolist()\n",
    "    df['cm'] = [cm_flattened]* len(df)\n",
    "    df['prediction_type'] = df.apply(lambda x: prediction_type(x['y'], x['y_pred']), axis=1)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5340ac8-3e02-42f4-893d-ae6820312e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "gp_result_path = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_results/'\n",
    "# capstone/atom2024/atom2024/notebooks/NEK/GP/GP_results/NEK2_binding_mfp_ADASYN_test_GP.csv\n",
    "nek_nums = [2,3,5,9]\n",
    "samplings = ['scaled', 'UNDER', 'SMOTE', 'ADASYN'] \n",
    "features = ['moe', 'mfp']\n",
    "NEK= 'NEK'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    nek_path= f'{data_dir}NEK{nek}/bind/'\n",
    "    \n",
    "    for k, feat in enumerate(features): \n",
    "        print()\n",
    "        for j, samp in enumerate(samplings): \n",
    "        \n",
    "            print(f'NEK{nek} {feat} {samp}')\n",
    "            file_root = f'NEK{nek}_binding_{feat}_{samp}'\n",
    "            train_file = f'{file_root}_train_GP.csv'\n",
    "            test_file = f'{file_root}_test_GP.csv'\n",
    "\n",
    "            train_df = add_cm(gp_result_path,train_file)\n",
    "            test_df = add_cm(gp_result_path,test_file)\n",
    "            train_df.to_csv(f'{gp_result_path}{file_root}_train_GP.csv',index=False) \n",
    "            test_df.to_csv(f'{gp_result_path}{file_root}_test_GP.csv',index=False) \n",
    "            \n",
    "            print()\n",
    "            \n",
    "            \n",
    "    print()\n",
    "    \n",
    "    if n == 2 or n == 9:\n",
    "\n",
    "        nek_path= f'{data_dir}NEK{nek}/inhib/'\n",
    "        for k, feat in enumerate(features): \n",
    "            print()\n",
    "            for j, samp in enumerate(samplings): \n",
    "                file_root = f'NEK{nek}_inhibition_{feat}_{samp}'\n",
    "                print(f'NEK{nek} {feat} {samp}')\n",
    "                print(f'NEK{nek} {feat} {samp}')\n",
    "                file_root = f'NEK{nek}_inhibition_{feat}_{samp}'\n",
    "                train_file = f'{file_root}_train_GP.csv'\n",
    "                test_file = f'{file_root}_test_GP.csv'\n",
    "    \n",
    "                train_df = add_cm(gp_result_path,train_file)\n",
    "                test_df = add_cm(gp_result_path,test_file)\n",
    "                train_df.to_csv(f'{gp_result_path}{file_root}_train_GP.csv',index=False) \n",
    "                test_df.to_csv(f'{gp_result_path}{file_root}_test_GP.csv',index=False) \n",
    "                print()\n",
    "        \n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd90773-d3a6-44c3-bf81-a111a641ccdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e207a86-6257-41ca-b31b-5a30c4bd7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/'\n",
    "# dest = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_results/'\n",
    "\n",
    "# if not os.path.exists(source):\n",
    "#     os.makedirs(dest)\n",
    "\n",
    "# for root, dirs, files in os.walk(source):\n",
    "#     for file in files:\n",
    "#         if file.endswith('_GP.csv'):\n",
    "#             source_file = os.path.join(root, file)\n",
    "#             dest_file = os.path.join(dest, file)\n",
    "#             shutil.move(source_file,dest_file)\n",
    "#             print(f\"Moved: {source_file} to {dest_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92e5900f-04c5-4f3b-83f5-f6541a3e5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72913c33-4b35-4980-85ab-152d419648df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
