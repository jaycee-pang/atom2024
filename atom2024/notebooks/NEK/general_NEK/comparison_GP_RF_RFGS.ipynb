{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a2064180-9b65-4d2a-a510-ef9dfccc3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc, recall_score, confusion_matrix\n",
    "import sys \n",
    "sys.path.append('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/')\n",
    "from RF_atomver import *\n",
    "from VisUtils import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c4150837-a2cb-47f6-977e-a13b60358c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_metric(df, metric): \n",
    "    averages = []\n",
    "    neks = df['NEK'].unique()\n",
    "    for nek in neks:\n",
    "        nek_df=df[df['NEK'] == nek] \n",
    "        average_score = nek_df[metric].mean() \n",
    "        print(f'{nek} average {metric} score: {average_score:.2f}') \n",
    "        averages.append(average_score) \n",
    "    print()\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a934029-e60d-4d2a-814c-8df318cba23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "result_path  = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_results/'\n",
    "nek_nums = [2,3,5,9]\n",
    "samplings = ['scaled', 'UNDER', 'SMOTE', 'ADASYN'] \n",
    "features = ['moe', 'mfp']\n",
    "\n",
    "NEK= 'NEK'\n",
    "train_ys = []\n",
    "test_ys = []\n",
    "pred_types = []\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    nek_path= f'{data_dir}NEK{nek}/bind/'\n",
    "    for k, feat in enumerate(features): \n",
    "        for j, samp in enumerate(samplings): \n",
    "            # print(f'NEK{nek} bind {feat} {samp}')\n",
    "            file_root = f'NEK{nek}_binding_{feat}_{samp}'\n",
    "            train = pd.read_csv(f'{result_path}{file_root}_train_GP.csv')\n",
    "            test = pd.read_csv(f'{result_path}{file_root}_test_GP.csv')\n",
    "            pred_types.append(test['prediction_type'])\n",
    "    if n == 2 or n == 9:\n",
    "        nek_path= f'{data_dir}NEK{nek}/inhib/'\n",
    "        for k, feat in enumerate(features): \n",
    "            for j, samp in enumerate(samplings): \n",
    "                file_root = f'NEK{nek}_inhibition_{feat}_{samp}'\n",
    "                # print(f'NEK{nek} inbhib {feat} {samp}')\n",
    "                train = pd.read_csv(f'{result_path}{file_root}_train_GP.csv')\n",
    "                test = pd.read_csv(f'{result_path}{file_root}_test_GP.csv')\n",
    "                pred_types.append(test['prediction_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7cd4e3e0-6758-4704-ade4-b9440552abb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gp_df = pd.read_csv(GP_resultpath+'GP_test_results_all_NEK.csv')\n",
    "gp_df['prediction_type'] = pred_types\n",
    "gp_df['dataset_category'] = gp_df['feat_type'].astype(str)+'_'+gp_df['strategy']\n",
    "gp_df['strategy'] = gp_df['strategy'].str.replace('scaled', 'raw')\n",
    "gp_df['model'] = gp_df['model'].str.replace('scaled', 'raw')\n",
    "gp_df['modeling type'] = 'GP' \n",
    "gp_df['model strategy'] = 'GP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "90b08368-39bf-41e4-a95b-e80a1afedecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = pd.read_csv('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/dataset_creation/all_NEK_dataset_sizes.csv') \n",
    "RF_resultpath= '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/RF/' \n",
    "RFGS_resultpath = RF_resultpath+'RF_grid_search/rf_results/'\n",
    "GP_resultpath = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/GP/GP_results/'\n",
    "rf_df = pd.read_csv(RF_resultpath+'RF_results/RF_test_results_all_NEK.csv')\n",
    "rfgs_df = pd.read_csv(RFGS_resultpath+'RF_gridsearch_test_results_all_NEK.csv')\n",
    "rf_df['model'] = rf_df['model'].str.replace('scaled', 'raw')\n",
    "rf_df['strategy'] = rf_df['strategy'].str.replace('scaled', 'raw')\n",
    "rf_df['dataset_category'] = rf_df['feat_type'].astype(str)+'_'+rf_df['strategy']\n",
    "rfgs_df['model'] = rfgs_df['model'].str.replace('scaled', 'raw')\n",
    "rfgs_df['strategy'] = rfgs_df['strategy'].str.replace('scaled', 'raw')\n",
    "rfgs_df=rfgs_df.drop(columns='y')\n",
    "\n",
    "rf_cols = list(rf_df.columns)\n",
    "rfgs_cols = list(rfgs_df.columns)\n",
    "rfgs_df = rfgs_df[rf_cols]\n",
    "# rf_df['modeling type'] = 'noGS'\n",
    "# rfgs_df['modeling type'] = 'GS'\n",
    "# rfgs_df['modeling type'] = rfgs_df['RF_type'].astype(str)+'_'+rfgs_df['modeling type']\n",
    "# rf_df['modeling type'] = rf_df['RF_type'].astype(str)+'_'+rf_df['modeling type']\n",
    "rf_df['modeling type'] = rf_df['RF_type'] \n",
    "rfgs_df['modeling type'] = rfgs_df['RF_type'] \n",
    "rf_df['model strategy'] = 'RF_noGS'\n",
    "rfgs_df['model strategy'] = 'RF_GS'\n",
    "\n",
    "col_order = ['NEK', 'strategy', 'feat_type', 'RF_type', 'dataset_category', 'modeling type','model',\n",
    "            'prediction_type', 'recall', 'accuracy', 'precision','specificity','f1', 'ROC-AUC', 'MCC', 'Balanced Accuracy',\n",
    "             'TN', 'FN', 'FP', 'TP']\n",
    "col_order2 = ['NEK', 'strategy', 'feat_type', 'dataset_category', 'modeling type','model','model strategy','cm',\n",
    "            'prediction_type', 'recall', 'accuracy', 'precision','specificity','f1', 'ROC-AUC', 'MCC', 'Balanced Accuracy',\n",
    "             'TN', 'FN', 'FP', 'TP']\n",
    "df = pd.concat([rf_df, rfgs_df],axis=0)\n",
    "df = df.drop(columns=['RF_type'])\n",
    "df = df[col_order2]\n",
    "df = pd.concat([gp_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a9b20a5c-2468-4ab4-ba2e-c2e176a097a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP\n",
      "NEK2_binding average f1 score: 0.21\n",
      "NEK2_inhibition average f1 score: 0.43\n",
      "NEK3_binding average f1 score: 0.15\n",
      "NEK5_binding average f1 score: 0.34\n",
      "NEK9_binding average f1 score: 0.07\n",
      "NEK9_inhibition average f1 score: 0.48\n",
      "\n",
      "NEK2_binding average MCC score: 0.24\n",
      "NEK2_inhibition average MCC score: 0.43\n",
      "NEK3_binding average MCC score: 0.13\n",
      "NEK5_binding average MCC score: 0.33\n",
      "NEK9_binding average MCC score: 0.07\n",
      "NEK9_inhibition average MCC score: 0.44\n",
      "\n",
      "NEK2_binding average Balanced Accuracy score: 0.59\n",
      "NEK2_inhibition average Balanced Accuracy score: 0.69\n",
      "NEK3_binding average Balanced Accuracy score: 0.56\n",
      "NEK5_binding average Balanced Accuracy score: 0.64\n",
      "NEK9_binding average Balanced Accuracy score: 0.52\n",
      "NEK9_inhibition average Balanced Accuracy score: 0.70\n",
      "\n",
      "NEK2_binding average ROC-AUC score: 0.59\n",
      "NEK2_inhibition average ROC-AUC score: 0.69\n",
      "NEK3_binding average ROC-AUC score: 0.56\n",
      "NEK5_binding average ROC-AUC score: 0.64\n",
      "NEK9_binding average ROC-AUC score: 0.52\n",
      "NEK9_inhibition average ROC-AUC score: 0.70\n",
      "\n",
      "NEK2_binding average precision score: 0.43\n",
      "NEK2_inhibition average precision score: 0.56\n",
      "NEK3_binding average precision score: 0.20\n",
      "NEK5_binding average precision score: 0.49\n",
      "NEK9_binding average precision score: 0.14\n",
      "NEK9_inhibition average precision score: 0.55\n",
      "\n",
      "NEK2_binding average accuracy score: 0.93\n",
      "NEK2_inhibition average accuracy score: 0.83\n",
      "NEK3_binding average accuracy score: 0.87\n",
      "NEK5_binding average accuracy score: 0.89\n",
      "NEK9_binding average accuracy score: 0.91\n",
      "NEK9_inhibition average accuracy score: 0.83\n",
      "\n",
      "NEK2_binding average specificity score: 0.97\n",
      "NEK2_inhibition average specificity score: 0.86\n",
      "NEK3_binding average specificity score: 0.91\n",
      "NEK5_binding average specificity score: 0.93\n",
      "NEK9_binding average specificity score: 0.95\n",
      "NEK9_inhibition average specificity score: 0.86\n",
      "\n",
      "NEK2_binding average recall score: 0.21\n",
      "NEK2_inhibition average recall score: 0.52\n",
      "NEK3_binding average recall score: 0.21\n",
      "NEK5_binding average recall score: 0.36\n",
      "NEK9_binding average recall score: 0.10\n",
      "NEK9_inhibition average recall score: 0.53\n",
      "\n",
      "RF_noGS\n",
      "NEK2_binding average f1 score: 0.27\n",
      "NEK2_inhibition average f1 score: 0.58\n",
      "NEK3_binding average f1 score: 0.22\n",
      "NEK5_binding average f1 score: 0.42\n",
      "NEK9_binding average f1 score: 0.18\n",
      "NEK9_inhibition average f1 score: 0.56\n",
      "\n",
      "NEK2_binding average MCC score: 0.27\n",
      "NEK2_inhibition average MCC score: 0.55\n",
      "NEK3_binding average MCC score: 0.19\n",
      "NEK5_binding average MCC score: 0.40\n",
      "NEK9_binding average MCC score: 0.17\n",
      "NEK9_inhibition average MCC score: 0.49\n",
      "\n",
      "NEK2_binding average Balanced Accuracy score: 0.64\n",
      "NEK2_inhibition average Balanced Accuracy score: 0.75\n",
      "NEK3_binding average Balanced Accuracy score: 0.62\n",
      "NEK5_binding average Balanced Accuracy score: 0.70\n",
      "NEK9_binding average Balanced Accuracy score: 0.59\n",
      "NEK9_inhibition average Balanced Accuracy score: 0.73\n",
      "\n",
      "NEK2_binding average ROC-AUC score: 0.64\n",
      "NEK2_inhibition average ROC-AUC score: 0.75\n",
      "NEK3_binding average ROC-AUC score: 0.62\n",
      "NEK5_binding average ROC-AUC score: 0.70\n",
      "NEK9_binding average ROC-AUC score: 0.59\n",
      "NEK9_inhibition average ROC-AUC score: 0.73\n",
      "\n",
      "NEK2_binding average precision score: 0.37\n",
      "NEK2_inhibition average precision score: 0.66\n",
      "NEK3_binding average precision score: 0.23\n",
      "NEK5_binding average precision score: 0.48\n",
      "NEK9_binding average precision score: 0.24\n",
      "NEK9_inhibition average precision score: 0.61\n",
      "\n",
      "NEK2_binding average accuracy score: 0.85\n",
      "NEK2_inhibition average accuracy score: 0.89\n",
      "NEK3_binding average accuracy score: 0.78\n",
      "NEK5_binding average accuracy score: 0.83\n",
      "NEK9_binding average accuracy score: 0.83\n",
      "NEK9_inhibition average accuracy score: 0.86\n",
      "\n",
      "NEK2_binding average specificity score: 0.86\n",
      "NEK2_inhibition average specificity score: 0.91\n",
      "NEK3_binding average specificity score: 0.81\n",
      "NEK5_binding average specificity score: 0.86\n",
      "NEK9_binding average specificity score: 0.85\n",
      "NEK9_inhibition average specificity score: 0.90\n",
      "\n",
      "NEK2_binding average recall score: 0.41\n",
      "NEK2_inhibition average recall score: 0.59\n",
      "NEK3_binding average recall score: 0.43\n",
      "NEK5_binding average recall score: 0.54\n",
      "NEK9_binding average recall score: 0.34\n",
      "NEK9_inhibition average recall score: 0.55\n",
      "\n",
      "RF_GS\n",
      "NEK2_binding average f1 score: 0.31\n",
      "NEK2_inhibition average f1 score: 0.58\n",
      "NEK3_binding average f1 score: 0.23\n",
      "NEK5_binding average f1 score: 0.49\n",
      "NEK9_binding average f1 score: 0.13\n",
      "NEK9_inhibition average f1 score: 0.63\n",
      "\n",
      "NEK2_binding average MCC score: 0.32\n",
      "NEK2_inhibition average MCC score: 0.55\n",
      "NEK3_binding average MCC score: 0.20\n",
      "NEK5_binding average MCC score: 0.47\n",
      "NEK9_binding average MCC score: 0.13\n",
      "NEK9_inhibition average MCC score: 0.58\n",
      "\n",
      "NEK2_binding average Balanced Accuracy score: 0.65\n",
      "NEK2_inhibition average Balanced Accuracy score: 0.76\n",
      "NEK3_binding average Balanced Accuracy score: 0.61\n",
      "NEK5_binding average Balanced Accuracy score: 0.72\n",
      "NEK9_binding average Balanced Accuracy score: 0.58\n",
      "NEK9_inhibition average Balanced Accuracy score: 0.76\n",
      "\n",
      "NEK2_binding average ROC-AUC score: 0.65\n",
      "NEK2_inhibition average ROC-AUC score: 0.76\n",
      "NEK3_binding average ROC-AUC score: 0.61\n",
      "NEK5_binding average ROC-AUC score: 0.72\n",
      "NEK9_binding average ROC-AUC score: 0.58\n",
      "NEK9_inhibition average ROC-AUC score: 0.76\n",
      "\n",
      "NEK2_binding average precision score: 0.46\n",
      "NEK2_inhibition average precision score: 0.64\n",
      "NEK3_binding average precision score: 0.26\n",
      "NEK5_binding average precision score: 0.57\n",
      "NEK9_binding average precision score: 0.18\n",
      "NEK9_inhibition average precision score: 0.71\n",
      "\n",
      "NEK2_binding average accuracy score: 0.88\n",
      "NEK2_inhibition average accuracy score: 0.89\n",
      "NEK3_binding average accuracy score: 0.80\n",
      "NEK5_binding average accuracy score: 0.85\n",
      "NEK9_binding average accuracy score: 0.84\n",
      "NEK9_inhibition average accuracy score: 0.89\n",
      "\n",
      "NEK2_binding average specificity score: 0.90\n",
      "NEK2_inhibition average specificity score: 0.91\n",
      "NEK3_binding average specificity score: 0.83\n",
      "NEK5_binding average specificity score: 0.87\n",
      "NEK9_binding average specificity score: 0.86\n",
      "NEK9_inhibition average specificity score: 0.92\n",
      "\n",
      "NEK2_binding average recall score: 0.40\n",
      "NEK2_inhibition average recall score: 0.62\n",
      "NEK3_binding average recall score: 0.40\n",
      "NEK5_binding average recall score: 0.58\n",
      "NEK9_binding average recall score: 0.29\n",
      "NEK9_inhibition average recall score: 0.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_dfs = []\n",
    "neks = df['NEK'].unique()\n",
    "for model in df['model strategy'].unique(): \n",
    "    \n",
    "    this_df = df[df['model strategy'] == model] \n",
    "    print(f\"{this_df['model strategy'].loc[0]}\") \n",
    "    f1s = average_metric(this_df, 'f1')\n",
    "    MCCs = average_metric(this_df, 'MCC')\n",
    "    BAs = average_metric(this_df, 'Balanced Accuracy')\n",
    "    ROC_AUCs = average_metric(this_df, 'ROC-AUC')\n",
    "    precs = average_metric(this_df, 'precision')\n",
    "    accs = average_metric(this_df, 'accuracy')\n",
    "    specs = average_metric(this_df, 'specificity')\n",
    "    recalls = average_metric(this_df, 'recall')\n",
    "    avg_df = pd.DataFrame({'Recall': recalls, 'Accuracy': accs, 'Precision': precs, 'Specificity': specs, 'F1': f1s,\n",
    "                          'MCC': MCCs, 'Balanced Accuracy': BAs, 'ROC-AUC': ROC_AUCs})\n",
    "\n",
    "    avg_dfs.append(avg_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2bc5a233-5b5d-4f6b-8f3b-943d277e7609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEK2_binding', 'NEK2_inhibition', 'NEK3_binding', 'NEK5_binding',\n",
       "       'NEK9_binding', 'NEK9_inhibition'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0db11d44-d4a3-419c-a58d-d1d59eeb6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst in avg_dfs: \n",
    "    lst.index = neks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18cfad0b-6ba4-4938-9c33-ea2acf351f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_GP = avg_dfs[0]\n",
    "avg_RF=avg_dfs[1]\n",
    "avg_RFGS=avg_dfs[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b0386d19-4a62-463f-9cde-8d8102a5bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_GP.to_excel('average_NEK_GP.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "964065ff-99e2-4030-a83f-d097f235c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_RF.to_excel('average_NEK_RF.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "da7465d8-9efd-44b7-b0d0-ba4d87ec1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_RFGS.to_excel('average_NEK_RFGS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccce834-0b32-45dc-ad2e-db0b5bafc60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05112bab-e215-476a-aa94-666107a6a3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "atom2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
