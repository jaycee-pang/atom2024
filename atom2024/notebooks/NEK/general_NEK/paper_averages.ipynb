{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65601031-60c7-4527-b71c-1e9c9ba4e8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import sys'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyforest\n",
    "sys.path.append('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/')\n",
    "from RF_atomver import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d676c4-b083-4a45-b06a-8e6a0025c2bc",
   "metadata": {},
   "source": [
    "# Raw datasets GP performed poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c636de4-3290-4a95-9ec2-d23aebcd46bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>1-specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfp</th>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moe</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             recall  1-specificity\n",
       "feat_type                         \n",
       "mfp        0.005952            0.0\n",
       "moe        0.000000            0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_paper_models.csv')\n",
    "df = df[(df['set'] !='literature') & (df['modeling_type']!='RF_GS')]\n",
    "df = df[~df['set'].isin(['fold1', 'fold2', 'fold3', 'fold4', 'fold5'])]\n",
    "df['dataset type'] = ['binding' if nek in ['NEK2_binding','NEK3_binding','NEK5_binding','NEK9_binding'] else 'inhibition' for nek in df['NEK']]\n",
    "df['1-specificity'] = 1-df['specificity'] \n",
    "gp = df[(df['modeling_type']=='GP_matern') & (df['strategy']=='raw')]\n",
    "gp_feat_avg = gp.groupby('feat_type')[['recall', '1-specificity']].mean()\n",
    "gp_feat_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a733ffc-080f-4aa6-9693-12502a654c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "original            240\n",
       "batch2_inactives     24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e39cc767-e800-4ffc-8ebd-7c503cce16a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>1-specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>binding</th>\n",
       "      <td>0.191012</td>\n",
       "      <td>0.006642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inhibition</th>\n",
       "      <td>0.595734</td>\n",
       "      <td>0.018884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                recall  1-specificity\n",
       "dataset type                         \n",
       "binding       0.191012       0.006642\n",
       "inhibition    0.595734       0.018884"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rf = df[(df['RF_type'] == 'RF') | (df['RF_type'] == 'RF_BCW')]\n",
    "raw_rf = raw_rf[raw_rf['strategy'] =='raw']\n",
    "rf_raw_avg = raw_rf .groupby('dataset type')[['recall', '1-specificity']].mean()\n",
    "rf_raw_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06228ce-cfb9-4575-9fab-c766fcec2d77",
   "metadata": {},
   "source": [
    "# all NEK averages \n",
    "this means any nek, any feat type, any modeling strategy, just simply average of strategy type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83a973e5-0654-4e1f-8d7d-04cffee225dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw average:\n",
      "recall           0.427296\n",
      "1-specificity    0.104096\n",
      "dtype: float64\n",
      "\n",
      "UNDER average:\n",
      "recall           0.640505\n",
      "1-specificity    0.403364\n",
      "dtype: float64\n",
      "\n",
      "SMOTE average:\n",
      "recall           0.393906\n",
      "1-specificity    0.028203\n",
      "dtype: float64\n",
      "\n",
      "ADASYN average:\n",
      "recall           0.391709\n",
      "1-specificity    0.031937\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for samp in df['strategy'].unique():\n",
    "    samp_df = df[df['strategy']==samp]\n",
    "    avg = samp_df[['recall', '1-specificity']].mean()\n",
    "    print(f'{samp} average:\\n{avg}')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a5e1b-f9f7-4e5e-adc2-8192c7cf538d",
   "metadata": {},
   "source": [
    "# Rf averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "485b8da7-a200-44c3-bc28-8a1497d82374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_GP_original average:\n",
      "binding:\n",
      "recall           0.0\n",
      "1-specificity    0.0\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.008929\n",
      "1-specificity    0.000000\n",
      "dtype: float64\n",
      "\n",
      "UNDER_GP_original average:\n",
      "binding:\n",
      "recall           0.669862\n",
      "1-specificity    0.433768\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.642857\n",
      "1-specificity    0.296117\n",
      "dtype: float64\n",
      "\n",
      "SMOTE_GP_original average:\n",
      "binding:\n",
      "recall           0.242157\n",
      "1-specificity    0.007345\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.582341\n",
      "1-specificity    0.010332\n",
      "dtype: float64\n",
      "\n",
      "ADASYN_GP_original average:\n",
      "binding:\n",
      "recall           0.216054\n",
      "1-specificity    0.007364\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.610119\n",
      "1-specificity    0.011648\n",
      "dtype: float64\n",
      "\n",
      "UNDER_GP_batch2_inactives average:\n",
      "binding:\n",
      "recall           0.715092\n",
      "1-specificity    0.501584\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.574405\n",
      "1-specificity    0.284266\n",
      "dtype: float64\n",
      "\n",
      "raw_RF_original average:\n",
      "binding:\n",
      "recall           0.177630\n",
      "1-specificity    0.005862\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.591270\n",
      "1-specificity    0.017569\n",
      "dtype: float64\n",
      "\n",
      "raw_RF_BCW_original average:\n",
      "binding:\n",
      "recall           0.204393\n",
      "1-specificity    0.007422\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.600198\n",
      "1-specificity    0.020200\n",
      "dtype: float64\n",
      "\n",
      "raw_BRFC_original average:\n",
      "binding:\n",
      "recall           0.664810\n",
      "1-specificity    0.242297\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.746032\n",
      "1-specificity    0.059711\n",
      "dtype: float64\n",
      "\n",
      "raw_BRFC_BCW_original average:\n",
      "binding:\n",
      "recall           0.766516\n",
      "1-specificity    0.408157\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.83631\n",
      "1-specificity    0.13649\n",
      "dtype: float64\n",
      "\n",
      "UNDER_RF_original average:\n",
      "binding:\n",
      "recall           0.647106\n",
      "1-specificity    0.417305\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.589286\n",
      "1-specificity    0.359377\n",
      "dtype: float64\n",
      "\n",
      "SMOTE_RF_original average:\n",
      "binding:\n",
      "recall           0.315177\n",
      "1-specificity    0.026696\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.590278\n",
      "1-specificity    0.048795\n",
      "dtype: float64\n",
      "\n",
      "UNDER_RF_batch2_inactives average:\n",
      "binding:\n",
      "recall           0.585417\n",
      "1-specificity    0.465859\n",
      "dtype: float64\n",
      "inhibition:\n",
      "recall           0.636905\n",
      "1-specificity    0.385072\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/cvnnx9qn3tj18cq5_9wx39xm0000gn/T/ipykernel_46942/1009876918.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gp['strategy'] = gp['strategy'].astype(str)+'_GP_'+gp['set']\n"
     ]
    }
   ],
   "source": [
    "essentially_under = []\n",
    "# for samp in df['strategy'].unique():\n",
    "#     samp_df = df[df['strategy']==samp]\n",
    "#     avg = samp_df[['recall', '1-specificity']].mean()\n",
    "#     print(f'{samp} average:\\n{avg}')\n",
    "#     print() \n",
    "rf= df[df['modeling_type'] =='RF']\n",
    "rf_raw = rf[(rf['strategy'] == 'raw') & (rf['RF_type'].isin(['RF', 'RF_BCW', 'BRFC', 'BRFC_BCW']))]\n",
    "rf_other = rf[(rf['RF_type'] == 'RF') & (rf['strategy'].isin(['UNDER','SMOTE']))]  \n",
    "\n",
    "rf_filtered = pd.concat([rf_raw, rf_other])\n",
    "total_rf = rf_filtered.copy() \n",
    "total_rf['strategy'] =total_rf['strategy'].astype(str) +'_'+ total_rf['RF_type']+'_'+total_rf['set'] \n",
    "total_rf['strategy'].unique()\n",
    "\n",
    "gp= df[df['modeling_type'] == 'GP_matern']\n",
    "gp['strategy'] = gp['strategy'].astype(str)+'_GP_'+gp['set'] \n",
    "\n",
    "full_df = pd.concat([gp, total_rf]) \n",
    "# full_df['1-specificity'] = 1-full_df['specificity']\n",
    "full_df['dataset type'] = full_df['NEK'].str.split('_').str[1]\n",
    "batch2_inactive_df = full_df[full_df['set'] == 'batch2_inactives']\n",
    "bind_df2 = full_df[full_df['dataset type'] == 'binding'] \n",
    "inhib_df2 = full_df[full_df['dataset type'] == 'inhibition'] \n",
    "\n",
    "bind_recalls = []\n",
    "inhib_recalls = [] \n",
    "bind_1specs = []\n",
    "inhib_1specs=[]\n",
    "strategies = []\n",
    "for strat in bind_df2['strategy'].unique(): \n",
    "    bind_strat = bind_df2[bind_df2['strategy']==strat] \n",
    "    inhib_strat = inhib_df2[inhib_df2['strategy']==strat] \n",
    "    avg_bind = bind_strat[['recall', '1-specificity']].mean()\n",
    "    avg_inhib = inhib_strat[['recall', '1-specificity']].mean()\n",
    "    print(f'{strat} average:\\nbinding:\\n{avg_bind}\\ninhibition:\\n{avg_inhib}')\n",
    "    \n",
    "    print()\n",
    "    bind_recalls.append(avg_bind['recall'])\n",
    "    bind_1specs.append(avg_bind['1-specificity'])\n",
    "    inhib_recalls.append(avg_inhib['recall'])\n",
    "    inhib_1specs.append(avg_inhib['1-specificity'])\n",
    "    strategies.append(strat) \n",
    "    \n",
    "    \n",
    "bind_avgs = pd.DataFrame({'strategy': strategies,'recall average': bind_recalls, '1-specificity average': bind_1specs })\n",
    "bind_avgs['nek dataset'] = 'binding'\n",
    "inhib_avgs = pd.DataFrame({'strategy': strategies,'recall average': inhib_recalls, '1-specificity average': inhib_1specs })\n",
    "inhib_avgs['nek dataset'] = 'inhibition'\n",
    "avgs = pd.concat([bind_avgs, inhib_avgs], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf505bd-2c06-4084-9420-ae3cff5b9e62",
   "metadata": {},
   "source": [
    "# NEK averages (all models for each NEK) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b7ca65f-d713-4211-be27-3ebe7f98e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2_binding\n",
      "recall           0.424242\n",
      "1-specificity    0.171000\n",
      "dtype: float64\n",
      "\n",
      "NEK2_inhibition\n",
      "recall           0.608766\n",
      "1-specificity    0.151256\n",
      "dtype: float64\n",
      "\n",
      "NEK3_binding\n",
      "recall           0.425134\n",
      "1-specificity    0.209262\n",
      "dtype: float64\n",
      "\n",
      "NEK5_binding\n",
      "recall           0.522727\n",
      "1-specificity    0.160686\n",
      "dtype: float64\n",
      "\n",
      "NEK9_binding\n",
      "recall           0.325175\n",
      "1-specificity    0.171212\n",
      "dtype: float64\n",
      "\n",
      "NEK9_inhibition\n",
      "recall           0.570707\n",
      "1-specificity    0.130602\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neks = [] \n",
    "\n",
    "for nek in df['NEK'].unique(): \n",
    "    nek_df = df[df['NEK']==nek] \n",
    "    nek_avg = nek_df[['recall', '1-specificity']].mean()\n",
    "    print(f'{nek}\\n{nek_avg}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783a156-16cd-4cba-8f5f-d9c0821f83ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom2024",
   "language": "python",
   "name": "atom2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
