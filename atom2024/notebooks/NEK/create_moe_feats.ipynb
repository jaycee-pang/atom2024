{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e49849-eed5-43d5-8a9d-4e0492df4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import sklearn\n",
    "import imblearn as imb\n",
    "# print(\"imblearn version: \",imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "from rdkit import Chem\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "from split_data import *\n",
    "from RF_GSCV import *\n",
    "# from RF_Utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ec9703-3199-4e9d-a136-433a3967b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_df(file_path, file_name):\n",
    "    \"\"\"Standard Scalar to normalize original dataset\n",
    "    Scale data, put back feature names (including ID columns, add subset (train / test) column\n",
    "    file_path: directory where file is located \n",
    "    file_name: should be NEK#_1_uM_min_50_pct_(binding/inhibition)_5fold_random_imbalanced.csv\n",
    "    returns: final scaled dataframe\n",
    "    \"\"\"\n",
    "    df_original = pd.read_csv(file_path+file_name)\n",
    "    original_cols = df_original.columns \n",
    "    og_cols = original_cols.to_list() \n",
    "    feature_cols = og_cols[3:-1] \n",
    "    id_col_names = og_cols[0:2]\n",
    "    id_cols = df_original[id_col_names]\n",
    "    fold_col = df_original['fold']\n",
    "    true_labels = df_original['active']\n",
    "    # print(f'all cols: {original_cols.shape}, features: {len(feature_cols)}, id: {id_col_names}')\n",
    "\n",
    "    train_df = df_original[df_original['fold']!='fold1']\n",
    "    test_df = df_original[df_original['fold']=='fold1']\n",
    "    trainX_df = train_df[feature_cols]\n",
    "    testX_df = test_df[feature_cols]\n",
    "    trainy_df = train_df['active']\n",
    "    testy_df = test_df['active']\n",
    "    \n",
    "    train_id_df = train_df[id_col_names]\n",
    "    test_id_df = test_df[id_col_names]\n",
    "    train_fold = train_df['fold']\n",
    "    test_fold = test_df['fold']\n",
    "    \n",
    "    x_df = pd.concat([trainX_df, testX_df])\n",
    "    scaling=StandardScaler()\n",
    "    scaling.fit(x_df)\n",
    "    \n",
    "    scaled_data=scaling.transform(x_df)\n",
    "    trainX_scaled = scaling.transform(trainX_df)\n",
    "    testX_scaled = scaling.transform(testX_df) \n",
    "    print(f'train X: {trainX_scaled.shape}, testX: {testX_scaled.shape}')\n",
    "    trainX_final = pd.DataFrame(trainX_scaled, columns=feature_cols)\n",
    "    trainX_final['subset'] = 'train'\n",
    "    \n",
    "    testX_final = pd.DataFrame(testX_scaled, columns=feature_cols)\n",
    "    testX_final['subset']='test'\n",
    "    trainX_final[id_col_names] = train_id_df.reset_index(drop=True)\n",
    "    testX_final[id_col_names] = test_id_df.reset_index(drop=True)\n",
    "    trainX_final['fold'] = train_fold.reset_index(drop=True)\n",
    "    testX_final['fold'] = test_fold.reset_index(drop=True)\n",
    "    \n",
    "    trainX_final['active'] = trainy_df.reset_index(drop=True)\n",
    "    testX_final['active'] = testy_df.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    final_df = pd.concat([trainX_final, testX_final], ignore_index=True)\n",
    "    return final_df\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2da9c7-32aa-4654-9833-9fe81a051b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "train X: (1125, 306), testX: (283, 306)\n",
      "train X: (1635, 306), testX: (409, 306)\n",
      "\n",
      "NEK3\n",
      "train X: (1122, 306), testX: (282, 306)\n",
      "\n",
      "NEK5\n",
      "train X: (989, 306), testX: (248, 306)\n",
      "\n",
      "NEK9\n",
      "train X: (1126, 306), testX: (283, 306)\n",
      "train X: (313, 306), testX: (80, 306)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/data/NEK_ATOM_data/NEK'\n",
    "nek_nums = [2,3,5,9]\n",
    "NEK= 'NEK'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    nek_path= data_dir+nek+'/'\n",
    "    \n",
    "    bind_file = f'NEK{nek}_1_uM_min_50_pct_binding_5fold_random_imbalanced.csv'\n",
    "    nek_bind = scaled_df(nek_path,bind_file)\n",
    "\n",
    "    bind_final = f'NEK{nek}_binding_moe_scaled_df.csv'\n",
    "    nek_bind.to_csv(bind_final, index=False)\n",
    "    if n == 2 or n == 9:\n",
    "        inhib_file = f'NEK{nek}_1_uM_min_50_pct_inhibition_5fold_random_imbalanced.csv'\n",
    "        inhib_final = f'NEK{nek}_inhibition_moe_scaled_df.csv'\n",
    "        nek_inhib=scaled_df(nek_path,inhib_file)\n",
    "        nek_inhib.to_csv(inhib_final, index=False)\n",
    "    else:\n",
    "        pass\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd87f5cf-e009-48f8-804b-dd3a3118e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(filename):\n",
    "    \"\"\"Undersample the datasetes using the RandomUndersampler\n",
    "    Keeps the feature names and id cols\n",
    "    file_name (full/absolute path): use the scaled dataframe we just created above 'NEK#_binding_moe_scaled_df.csv'\n",
    "    returns: undersampled dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    original_cols = df.columns.to_list() \n",
    "    feature_names = original_cols[0:-5]\n",
    "    other_cols = original_cols[-5:]\n",
    "    id_col_names = other_cols[0:4]\n",
    "    id_cols = df[id_col_names]\n",
    "    \n",
    "    train_df = df[df['subset'] == 'train']\n",
    "    test_df = df[df['subset'] == 'test']\n",
    "    trainX = train_df[feature_names]\n",
    "    testX = test_df[feature_names]\n",
    "    trainy = train_df['active']\n",
    "    testy = test_df['active']\n",
    "    \n",
    "    train_ids = train_df[id_col_names]\n",
    "    test_ids = test_df[id_col_names]\n",
    "    undersample = RandomUnderSampler(random_state=42)\n",
    "    \n",
    "    trainX_temp, trainy_temp = undersample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    \n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feature_names)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "    \n",
    "    train_ids_resamp = train_ids.iloc[trainX_resamp.index].reset_index(drop=True)\n",
    "    train_resamp= pd.concat([train_ids_resamp, trainX_resamp,trainy_resamp], axis=1)\n",
    "    train_resamp['subset'] = 'train'\n",
    "    \n",
    "    \n",
    "    test_df_final = pd.concat([test_ids.reset_index(drop=True),testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "    test_df_final['subset'] = 'test'\n",
    "    \n",
    "    \n",
    "    final_df = pd.concat([train_resamp,test_df_final]).reset_index(drop=True)\n",
    "    return final_df \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7ddee8-bd59-481a-9488-3aa39b2e91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "NEK3\n",
      "NEK5\n",
      "NEK9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nek_nums = [2,3,5,9]\n",
    "NEK= 'NEK'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    \n",
    "    bind_file = f'NEK{nek}_binding_moe_scaled_df.csv'\n",
    "    nek_UNDER = undersample(bind_file)\n",
    "\n",
    "    bind_final = f'NEK{nek}_binding_moe_UNDER_df.csv'\n",
    "    nek_UNDER.to_csv(bind_final, index=False)\n",
    "    if n == 2 or n == 9:\n",
    "        inhib_file = f'NEK{nek}_inhibition_moe_scaled_df.csv'\n",
    "        inhib_final = f'NEK{nek}_inhibition_moe_UNDER_df.csv'\n",
    "        nek_inhib_UNDER = undersample(inhib_file)\n",
    "        nek_inhib_UNDER.to_csv(inhib_final, index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0460b4-219d-492b-a1b9-c12fa6ee3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(filename, sampling):\n",
    "    \"\"\"Oversample the datasetes using the SMOTE or ADASYN\n",
    "    Keeps the feature names and id cols\n",
    "    file_name (full/absolute path): use the scaled dataframe we just created above 'NEK#_binding_moe_scaled_df.csv'\n",
    "    sampling (str): 'SMOTE' or 'ADASYN'\n",
    "    returns: oversampled dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    original_cols = df.columns.to_list() \n",
    "    feature_names = original_cols[0:-5]\n",
    "    other_cols = original_cols[-5:]\n",
    "    id_col_names = other_cols[0:4]\n",
    "    id_cols = df[id_col_names]\n",
    "    \n",
    "    train_df = df[df['subset'] == 'train']\n",
    "    test_df = df[df['subset'] == 'test']\n",
    "    trainX = train_df[feature_names]\n",
    "    testX = test_df[feature_names]\n",
    "    trainy = train_df['active']\n",
    "    testy = test_df['active']\n",
    "    \n",
    "    # train_ids = train_df[id_col_names]\n",
    "    test_ids = test_df[id_col_names]\n",
    "    print(f'original train size: {train_df.shape}, original test size: {test_df.shape}')\n",
    "    \n",
    "    # oversample = SMOTE(random_state=42)\n",
    "    if sampling == 'ADASYN':\n",
    "        oversample = ADASYN(random_state=42)\n",
    "    else: \n",
    "        oversample = SMOTE(random_state=42)\n",
    "        \n",
    "    trainX_temp, trainy_temp = oversample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    print(f'train after {sampling}: {trainX_temp.shape}')\n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feature_names)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "    placeholder='synthetic '+sampling\n",
    "    syn_samples=pd.DataFrame({col:[placeholder]*len(trainX_resamp) for col in id_col_names})\n",
    "    # train_ids_resamp = train_ids.iloc[trainX_resamp.index].reset_index(drop=True)\n",
    "    # train_resamp= pd.concat([train_ids_resamp, trainX_resamp,trainy_resamp], axis=1)\n",
    "    train_resamp= pd.concat([syn_samples,trainX_resamp,trainy_resamp], axis=1)\n",
    "    train_resamp['subset'] = 'train'\n",
    "    \n",
    "    \n",
    "    test_df_final = pd.concat([test_ids.reset_index(drop=True),testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "    # test_df_final = pd.concat([testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "    test_df_final['subset'] = 'test'\n",
    "    \n",
    "    \n",
    "    final_df = pd.concat([train_resamp,test_df_final]).reset_index(drop=True)\n",
    "    return final_df \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb42e9f-f010-4bef-86a1-5ba40ce006ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "original train size: (1125, 311), original test size: (283, 311)\n",
      "train after SMOTE: (2160, 306)\n",
      "original train size: (1635, 311), original test size: (409, 311)\n",
      "train after SMOTE: (3046, 306)\n",
      "\n",
      "NEK3\n",
      "original train size: (1122, 311), original test size: (282, 311)\n",
      "train after SMOTE: (2116, 306)\n",
      "\n",
      "NEK5\n",
      "original train size: (989, 311), original test size: (248, 311)\n",
      "train after SMOTE: (1824, 306)\n",
      "\n",
      "NEK9\n",
      "original train size: (1126, 311), original test size: (283, 311)\n",
      "train after SMOTE: (2156, 306)\n",
      "original train size: (313, 311), original test size: (80, 311)\n",
      "train after SMOTE: (560, 306)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nek_nums = [2,3,5,9]\n",
    "NEK= 'NEK'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    \n",
    "    bind_file = f'NEK{nek}_binding_moe_scaled_df.csv'\n",
    "    nek_bind_SMOTE = oversample(bind_file, 'SMOTE')\n",
    "\n",
    "    bind_final = f'NEK{nek}_binding_moe_SMOTE_df.csv'\n",
    "    nek_bind_SMOTE.to_csv(bind_final, index=False)\n",
    "    \n",
    "    if n == 2 or n == 9:\n",
    "        inhib_file = f'NEK{nek}_inhibition_moe_scaled_df.csv'\n",
    "        inhib_final = f'NEK{nek}_inhibition_moe_SMOTE_df.csv'\n",
    "        nek_inhib_SMOTE = oversample(inhib_file, 'SMOTE')\n",
    "        nek_inhib_SMOTE.to_csv(inhib_final, index=False)\n",
    "        \n",
    "    print()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd037773-81fd-4955-9205-3292c55f824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "original train size: (1125, 311), original test size: (283, 311)\n",
      "train after ADASYN: (2158, 306)\n",
      "original train size: (1635, 311), original test size: (409, 311)\n",
      "train after ADASYN: (3037, 306)\n",
      "\n",
      "NEK3\n",
      "original train size: (1122, 311), original test size: (282, 311)\n",
      "train after ADASYN: (2113, 306)\n",
      "\n",
      "NEK5\n",
      "original train size: (989, 311), original test size: (248, 311)\n",
      "train after ADASYN: (1831, 306)\n",
      "\n",
      "NEK9\n",
      "original train size: (1126, 311), original test size: (283, 311)\n",
      "train after ADASYN: (2164, 306)\n",
      "original train size: (313, 311), original test size: (80, 311)\n",
      "train after ADASYN: (560, 306)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    print(f'NEK{nek}')\n",
    "    \n",
    "    bind_file = f'NEK{nek}_binding_moe_scaled_df.csv'\n",
    "    nek_bind_ADASYN = oversample(bind_file, 'ADASYN')\n",
    "\n",
    "    bind_final_ADASYN = f'NEK{nek}_binding_moe_ADASYN_df.csv'\n",
    "    nek_bind_ADASYN.to_csv(bind_final_ADASYN, index=False)\n",
    "    \n",
    "    if n == 2 or n == 9:\n",
    "        inhib_file = f'NEK{nek}_inhibition_moe_scaled_df.csv'\n",
    "        inhib_final_ADASYN = f'NEK{nek}_inhibition_moe_ADASYN_df.csv'\n",
    "        nek_inhib_ADASYN = oversample(inhib_file, 'ADASYN')\n",
    "        nek_inhib_ADASYN.to_csv(inhib_final_ADASYN, index=False)\n",
    "        \n",
    "    print()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41c4121-4964-48f3-bab7-82c7eb462c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_arrays(file_path, df_filename, filename_type=None, save=False):\n",
    "    \"\"\"use dataframes to get trainX, trainy, testX, testy out. Optional: save those files to csv\n",
    "    file_path: directory\n",
    "    df_filename: dataframe NEK#_binding_moe_{sampling}_df.csv (sampling: scaled, UNDER, SMOTE, ADASYN)\n",
    "    split dataframe to train and test, and x and y\n",
    "    save: bool, option to save splits to separate csv files (train X, train y, test X, test y) \n",
    "    returns: numpy arrays train X, train y, testX, test y\"\"\"\n",
    "    df = pd.read_csv(file_path+df_filename)\n",
    "    train_df= df[df['subset']=='train']\n",
    "    test_df = df[df['subset']=='test']\n",
    "    train_y = train_df['active'].to_numpy().reshape(-1)\n",
    "    test_y=test_df['active'].to_numpy().reshape(-1)\n",
    "    train_x_df = train_df.drop(columns='active')\n",
    "\n",
    "  \n",
    "    test_x_df = test_df.drop(columns='active')\n",
    "    \n",
    "    train_x_df = train_df.drop(columns='active')\n",
    "    test_x_df = test_df.drop(columns='active')\n",
    "    trainX = train_x_df.select_dtypes(include='number').to_numpy()\n",
    "    testX = test_x_df.select_dtypes(include='number').to_numpy()\n",
    "    \n",
    "    print(f'train X shape: {trainX.shape}, y: {train_y.shape}, test X: {testX.shape}, y:{test_y.shape}')\n",
    "    if (save and filename_type is not None): \n",
    "        trainxdf = pd.DataFrame(trainX)\n",
    "        trainxdf.to_csv(filename_type+'_trainX.csv', index=False)\n",
    "        # train_x_df.to_csv(filename_type+'_trainX.csv', index=False)\n",
    "        trainy_df = pd.DataFrame(train_y)\n",
    "        trainy_df.to_csv(filename_type+'_train_y.csv', index=False) \n",
    "        # test_x_df.to_csv(filename_type+'_testX.csv', index=False)\n",
    "        testxdf = pd.DataFrame(testX)\n",
    "        testxdf.to_csv(filename_type+'_testX.csv', index=False)\n",
    "        testy_df = pd.DataFrame(test_y)\n",
    "        testy_df.to_csv(filename_type+'_test_y.csv', index=False) \n",
    "        \n",
    "    return trainX, train_y, testX, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060049f6-b317-4dcc-b005-53aaf53dd8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2 scaled\n",
      "train X shape: (1125, 306), y: (1125,), test X: (283, 306), y:(283,)\n",
      "train X shape: (1635, 306), y: (1635,), test X: (409, 306), y:(409,)\n",
      "\n",
      "NEK2 UNDER\n",
      "train X shape: (90, 306), y: (90,), test X: (283, 306), y:(283,)\n",
      "train X shape: (224, 306), y: (224,), test X: (409, 306), y:(409,)\n",
      "\n",
      "NEK2 SMOTE\n",
      "train X shape: (2160, 306), y: (2160,), test X: (283, 306), y:(283,)\n",
      "train X shape: (3046, 306), y: (3046,), test X: (409, 306), y:(409,)\n",
      "\n",
      "NEK2 ADASYN\n",
      "train X shape: (2158, 306), y: (2158,), test X: (283, 306), y:(283,)\n",
      "train X shape: (3037, 306), y: (3037,), test X: (409, 306), y:(409,)\n",
      "\n",
      "\n",
      "NEK3 scaled\n",
      "train X shape: (1122, 306), y: (1122,), test X: (282, 306), y:(282,)\n",
      "\n",
      "NEK3 UNDER\n",
      "train X shape: (128, 306), y: (128,), test X: (282, 306), y:(282,)\n",
      "\n",
      "NEK3 SMOTE\n",
      "train X shape: (2116, 306), y: (2116,), test X: (282, 306), y:(282,)\n",
      "\n",
      "NEK3 ADASYN\n",
      "train X shape: (2113, 306), y: (2113,), test X: (282, 306), y:(282,)\n",
      "\n",
      "\n",
      "NEK5 scaled\n",
      "train X shape: (989, 306), y: (989,), test X: (248, 306), y:(248,)\n",
      "\n",
      "NEK5 UNDER\n",
      "train X shape: (154, 306), y: (154,), test X: (248, 306), y:(248,)\n",
      "\n",
      "NEK5 SMOTE\n",
      "train X shape: (1824, 306), y: (1824,), test X: (248, 306), y:(248,)\n",
      "\n",
      "NEK5 ADASYN\n",
      "train X shape: (1831, 306), y: (1831,), test X: (248, 306), y:(248,)\n",
      "\n",
      "\n",
      "NEK9 scaled\n",
      "train X shape: (1126, 306), y: (1126,), test X: (283, 306), y:(283,)\n",
      "train X shape: (313, 306), y: (313,), test X: (80, 306), y:(80,)\n",
      "\n",
      "NEK9 UNDER\n",
      "train X shape: (96, 306), y: (96,), test X: (283, 306), y:(283,)\n",
      "train X shape: (66, 306), y: (66,), test X: (80, 306), y:(80,)\n",
      "\n",
      "NEK9 SMOTE\n",
      "train X shape: (2156, 306), y: (2156,), test X: (283, 306), y:(283,)\n",
      "train X shape: (560, 306), y: (560,), test X: (80, 306), y:(80,)\n",
      "\n",
      "NEK9 ADASYN\n",
      "train X shape: (2164, 306), y: (2164,), test X: (283, 306), y:(283,)\n",
      "train X shape: (560, 306), y: (560,), test X: (80, 306), y:(80,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samplings = ['scaled', 'UNDER', 'SMOTE', 'ADASYN']\n",
    "\n",
    "nek_nums = [2,3,5,9]\n",
    "NEK= 'NEK'\n",
    "file_path = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/'\n",
    "for i, n in enumerate(nek_nums):\n",
    "    nek = str(n)\n",
    "    \n",
    "    for j, samp in enumerate (samplings):\n",
    "        print(f'NEK{nek} {samp}')\n",
    "        bind_df = f'NEK{nek}_binding_moe_{samp}_df.csv'\n",
    "        bind_dataset_type = f'NEK{nek}_binding_moe_{samp}'\n",
    "        get_data_arrays(file_path, bind_df, bind_dataset_type, save=True)\n",
    "        if n == 2 or n == 9:\n",
    "            inhib_df = f'NEK{nek}_inhibition_moe_{samp}_df.csv'\n",
    "            inhib_dataset_type = f'NEK{nek}_inhibition_moe_{samp}'\n",
    "            get_data_arrays(file_path, inhib_df, inhib_dataset_type, save=True)\n",
    "        print()\n",
    "        \n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e813e8-f53b-4d19-aedc-463a15f3146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_cols = nek2scaled.columns.to_list() \n",
    "# # true_labels = nek2scaled['active'] \n",
    "# feature_names = original_cols[0:-5]\n",
    "# # features = nek2scaled[feature_names] \n",
    "# other_cols = original_cols[-5:]\n",
    "# id_col_names = other_cols[0:4]\n",
    "# id_cols = nek2scaled[id_col_names]\n",
    "\n",
    "# train_df = nek2scaled[nek2scaled['subset'] == 'train']\n",
    "# test_df = nek2scaled[nek2scaled['subset'] == 'test']\n",
    "\n",
    "# trainX = train_df[feature_names]\n",
    "# testX = test_df[feature_names]\n",
    "# trainy = train_df['active']\n",
    "# testy = test_df['active']\n",
    "\n",
    "# train_ids = train_df[id_col_names]\n",
    "# test_ids = test_df[id_col_names]\n",
    "\n",
    "# undersample = RandomUnderSampler(random_state=42)\n",
    "# trainX_temp, trainy_temp = undersample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "\n",
    "# trainX_resamp = pd.DataFrame(trainX_temp, columns=feature_names)\n",
    "# trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "\n",
    "# train_ids_resamp = train_ids.iloc[trainX_resamp.index].reset_index(drop=True)\n",
    "# train_resamp= pd.concat([train_ids_resamp, trainX_resamp,trainy_resamp], axis=1)\n",
    "# train_resamp['subset'] = 'train'\n",
    "\n",
    "\n",
    "# test_df_final = pd.concat([test_ids.reset_index(drop=True),testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "# test_df_final['subset'] = 'test'\n",
    "\n",
    "\n",
    "# final_df = pd.concat([train_resamp,test_df_final]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e280557-7bdd-4a71-9600-92138527af50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bfde7-3a9c-4bed-9129-d7f80ba94cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a680059-12c4-4ad5-9692-89b49c0d6bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43423f4f-165e-4604-9b04-d5640a21507a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edcd30-4141-4acd-a8a3-95a9aa1e2372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsci",
   "language": "python",
   "name": "atomsci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
