{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf456674-bc2e-47f4-8898-7c91d24d510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/cvnnx9qn3tj18cq5_9wx39xm0000gn/T/ipykernel_60489/2293997119.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix, f1_score, roc_curve,precision_recall_curve, auc\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/')\n",
    "from RF_GSCV import * # RF_GSCV contains the calculate metrics function to get the TP, TN, FP, FN scores \n",
    "from RF_atomver import prediction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379ec7ea-fcfa-4e95-b240-791ec2db8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DirichletGPModel(ExactGP):\n",
    "    \"\"\"\n",
    "    A Dirichlet Gaussian Process (GP) model for multi-class classification.\n",
    "    This model uses a Gaussian Process with a Dirichlet prior to handle multi-class classification tasks.\n",
    "    It extends the ExactGP class from GPyTorch, a library for Gaussian Processes in PyTorch.\n",
    "    Attributes:\n",
    "        mean_module (gpytorch.means.ConstantMean): The mean module for the GP, initialized with a constant mean function for each class.\n",
    "        covar_module (gpytorch.kernels.ScaleKernel): The covariance module for the GP, using a scaled RBF kernel for each class.\n",
    "\n",
    "    Args:\n",
    "        train_x (torch.Tensor): Training data features.\n",
    "        train_y (torch.Tensor): Training data labels.\n",
    "        likelihood (gpytorch.likelihoods.Likelihood): The likelihood function.\n",
    "        num_classes (int): The number of classes for the classification task.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(MaternKernel(nu=0.5, batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the GP model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data features.\n",
    "        Returns:\n",
    "            gpytorch.distributions.MultivariateNormal: The multivariate normal distribution representing the GP posterior.\n",
    "        \"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d38620-904f-4ffb-aa50-ce6beabf1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self,model, likelihood, iterations): \n",
    "        self.model = model\n",
    "        self.likelihood = likelihood \n",
    "        smoke_test = ('CI' in os.environ)\n",
    "        self.n_iterations = 2 if smoke_test else iterations\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        self.loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "    def train(self, train_x, train_y): \n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        predictions = [] \n",
    "        for i in range(self.n_iterations): \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(train_x)\n",
    "            loss = -self.loss_fn(output, self.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if (i%10==0): \n",
    "                print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                    i + 1, self.n_iterations, loss.item(),\n",
    "                    self.model.covar_module.base_kernel.lengthscale.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "             \n",
    "            self.optimizer.step() \n",
    "    def predict(self, input): \n",
    "        \"\"\"\n",
    "        Make predictions using the GP model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input data for making predictions.\n",
    "        \n",
    "        Returns:\n",
    "            dist (gpytorch.distributions.MultivariateNormal): The distribution representing the GP posterior.\n",
    "            observed_pred (gpytorch.distributions.MultivariateNormal): The predicted distribution considering the likelihood.\n",
    "            pred_means (torch.Tensor): The means of the predicted distributions.\n",
    "            class_pred (torch.Tensor): The predicted class labels.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            dist = self.model(input)     # output distribution\n",
    "            pred_means = dist.loc          # means of distributino \n",
    "            observed_pred = self.likelihood(self.model(input))    # likelihood predictions mean and var  \n",
    "\n",
    "            class_pred = self.model(input).loc.max(0)[1]\n",
    "            \n",
    "        return dist, observed_pred, pred_means, class_pred\n",
    "    \n",
    "\n",
    "    def evaluate(self, x_input, y_true): \n",
    "        \"\"\"\n",
    "        Evaluate the GP model.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor): The true labels for the input data.\n",
    "        \n",
    "        Returns:\n",
    "            y_pred (numpy.ndarray): The predicted class labels.\n",
    "        \"\"\"\n",
    "        y_pred = self.model(x_input).loc.max(0)[1].numpy()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def gp_results(self, x_input, y_true, plot_title=None): \n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics and print results.\n",
    "\n",
    "        Args:\n",
    "            x_input (torch.Tensor): The input data features.\n",
    "            y_true (torch.Tensor or numpy.ndarray): The true labels for the input data.\n",
    "            plot_title (str, optional): The title for the confusion matrix plot.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing evaluation metrics and confusion matrix components.\n",
    "        \"\"\"\n",
    "        y_pred = self.evaluate(x_input, y_true) \n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.numpy().reshape(-1)\n",
    "        # plot_confusion_matrix(y_true, y_pred, ['0','1'], title=plot_title)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        dist = self.model(x_input)     # get predicted distributions \n",
    "        pred_means = dist.loc          # means for predicted dist  \n",
    "\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        tp, tn, fp, fn = calculate_metrics(y_true, y_pred) \n",
    "        sensitivity = tp / (tp + fn) \n",
    "        specificity = tn / (tn + fp) \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, specificity: {specificity:.4f}, cm: {cm}')\n",
    "        return {'accuracy': accuracy, 'precision': precision,  'recall':recall, 'specificity':specificity, 'TN': tn, 'FN': fn, 'FP': fp, 'TP': tp }\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03196461-714f-41ad-ab58-67c40014acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_torch_tens_float(filepath, filename): \n",
    "    df = pd.read_csv(filepath+filename+'.csv')\n",
    "    train_df = df[df['subset'] == 'train']\n",
    "    test_df = df[df['subset'] == 'test']\n",
    "    drop_cols = ['subset',\t'base_rdkit_smiles',\t'compound_id',\t'fold'\t,'active']\n",
    "    trainX_df = train_df.drop(columns=drop_cols) \n",
    "    trainy_df = train_df['active'] \n",
    "    testX_df = test_df.drop(columns=drop_cols) \n",
    "    testy_df = test_df['active'] \n",
    "\n",
    "    train_x_temp = trainX_df.to_numpy().astype(\"double\") # double \n",
    "    test_x_temp = testX_df.to_numpy().astype(\"double\") #double \n",
    "    \n",
    "    train_y_temp = trainy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "    test_y_temp = testy_df.to_numpy().flatten().astype(\"double\") #double \n",
    "\n",
    "    trainX = torch.as_tensor(train_x_temp, dtype=torch.float32)\n",
    "    trainy = torch.as_tensor(train_y_temp, dtype=torch.float32)\n",
    "    testX = torch.as_tensor(test_x_temp, dtype=torch.float32)\n",
    "    testy = torch.as_tensor(test_y_temp, dtype=torch.float32)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6faad9bf-cb3a-4e74-87d2-f8fe148378aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_path ='/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/undersampler_validation/under_batch2_jp/'\n",
    "def save_results(trainX, trainy, testX, testy, root_name, n_iterations=300, n_samples=100):\n",
    "    \"\"\"\n",
    "    Train a Dirichlet Gaussian Process model and save the training and test performance results.\n",
    "\n",
    "    This function trains a Dirichlet GP model on the given training data, evaluates it on both the training\n",
    "    and test data, and saves various performance metrics and predictions to pandas DataFrames.\n",
    "\n",
    "    Args:\n",
    "        trainX (torch.Tensor): The training data features.\n",
    "        trainy (torch.Tensor): The training data labels.\n",
    "        testX (torch.Tensor): The test data features.\n",
    "        testy (torch.Tensor): The test data labels.\n",
    "        root_name (str): The root name used for labeling the model in the results.\n",
    "        n_iterations (int, optional): The number of training iterations. Default is 300.\n",
    "        n_samples (int, optional): The number of samples for prediction. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "        train_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the training data.\n",
    "        test_perf_df (pd.DataFrame): DataFrame containing performance metrics and predictions for the test data.\n",
    "    \"\"\"\n",
    "    likelihood = DirichletClassificationLikelihood(trainy.long(), learn_additional_noise=True)\n",
    "    model = DirichletGPModel(trainX, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "    # n_iterations = 300\n",
    "    trainer = Trainer(model, likelihood, n_iterations)\n",
    "    trainer.train(trainX, trainy) \n",
    "  \n",
    "    train_dist, train_observed_pred, train_pred_means, train_pred  = trainer.predict(trainX)\n",
    "    train_results = trainer.gp_results(trainX, trainy)\n",
    "    test_dist, test_observed_pred, test_pred_means, test_pred  = trainer.predict(testX)\n",
    "    test_results = trainer.gp_results(testX, testy)\n",
    "    \n",
    "    train_observed_pred.mean.numpy()\n",
    "    train_pred_variance2D = train_observed_pred.variance.numpy()\n",
    "    test_observed_pred.mean.numpy()\n",
    "    test_pred_variance2D=test_observed_pred.variance.numpy()\n",
    "    \n",
    "    train_pred_samples = train_dist.sample(torch.Size((256,))).exp()\n",
    "    train_probabilities = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "\n",
    "    train_prob_stds = (train_pred_samples / train_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    "    test_pred_samples = test_dist.sample(torch.Size((100,))).exp()\n",
    "\n",
    "    test_probabilities = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "    test_prob_stds = (test_pred_samples / test_pred_samples.sum(-2, keepdim=True)).std(0)\n",
    "\n",
    " \n",
    "    train_perf_df = pd.DataFrame()\n",
    "    test_perf_df = pd.DataFrame()\n",
    "    train_perf_df['mean_pred_class0'] = train_observed_pred.mean.numpy()[0,]\n",
    "    train_perf_df['mean_pred_class1'] = train_observed_pred.mean.numpy()[1,]\n",
    "    train_perf_df['y'] = trainy\n",
    "    train_perf_df['y_pred'] = train_pred_means.max(0)[1]\n",
    "    train_perf_df['var_pred_class0']=train_observed_pred.variance.numpy()[0,]\n",
    "    train_perf_df['var_pred_class1']=train_observed_pred.variance.numpy()[1,]\n",
    "    train_perf_df['pred_prob_class0'] = train_probabilities.numpy()[0,]\n",
    "    train_perf_df['pred_prob_class1'] = train_probabilities.numpy()[1,]\n",
    "    train_perf_df['pred_prob_std_class0'] = train_prob_stds.numpy()[0,]\n",
    "    train_perf_df['pred_prob_std_class1'] = train_prob_stds.numpy()[1,]\n",
    "    train_perf_df['model'] = f'{root_name}_GP_Dirichlet_matern'\n",
    "    train_perf_df['subset'] = 'train' \n",
    "    train_cm = confusion_matrix(trainy, train_perf_df['y_pred'])\n",
    "    cm_flattened = train_cm.flatten().tolist()\n",
    "    train_perf_df['cm']= [cm_flattened]* len(train_perf_df)\n",
    "    train_perf_df['prediction_type'] = train_perf_df.apply(lambda x: prediction_type(x['y'], x['y_pred']), axis=1)\n",
    "    train_perf_df['ROC-AUC'] = roc_auc_score(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['MCC'] = matthews_corrcoef(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['Balanced Accuracy'] = balanced_accuracy_score(trainy, train_perf_df['y_pred'])\n",
    "    train_perf_df['f1'] = f1_score(trainy, train_perf_df['y_pred'])\n",
    "    \n",
    "    test_perf_df['mean_pred_class0'] = test_observed_pred.mean.numpy()[0,]\n",
    "    test_perf_df['mean_pred_class1'] = test_observed_pred.mean.numpy()[1,]\n",
    "    test_perf_df['y'] = testy\n",
    "    test_perf_df['y_pred'] = test_pred_means.max(0)[1]\n",
    "    test_perf_df['var_pred_class0']=test_observed_pred.variance.numpy()[0,]\n",
    "    test_perf_df['var_pred_class1']=test_observed_pred.variance.numpy()[1,]\n",
    "    test_perf_df['pred_prob_class0'] = test_probabilities.numpy()[0,]\n",
    "    test_perf_df['pred_prob_class1'] = test_probabilities.numpy()[1,]\n",
    "    test_perf_df['pred_prob_std_class0'] =test_prob_stds.numpy()[0,]\n",
    "    test_perf_df['pred_prob_std_class1'] = test_prob_stds.numpy()[1,]\n",
    "    test_perf_df['model'] = f'{root_name}_GP_Dirichlet_matern'\n",
    "    test_perf_df['subset'] = 'test' \n",
    "    test_cm = confusion_matrix(testy, test_perf_df['y_pred'])\n",
    "    test_cm_flattened = test_cm.flatten().tolist()\n",
    "    test_perf_df['cm']= [test_cm_flattened]* len(test_perf_df)\n",
    "    test_perf_df['prediction_type'] = test_perf_df.apply(lambda x: prediction_type(x['y'], x['y_pred']), axis=1)\n",
    "    test_perf_df['ROC-AUC'] = roc_auc_score(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['MCC'] = matthews_corrcoef(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['Balanced Accuracy'] = balanced_accuracy_score(testy, test_perf_df['y_pred'])\n",
    "    test_perf_df['f1'] = f1_score(testy, test_perf_df['y_pred'])\n",
    "    with open(f'{GP_path}{root_name}_GP_Dirichlet_matern_model.pkl', 'wb') as f: \n",
    "        pickle.dump(model,f)\n",
    "    with open(f'{GP_path}{root_name}_GP_Dirichlet_matern_likelihood.pkl', 'wb') as f: \n",
    "        pickle.dump(likelihood,f)\n",
    "    for k, val in train_results.items(): \n",
    "        train_perf_df[k] = val\n",
    "    for k, val in test_results.items():\n",
    "        test_perf_df[k] = val\n",
    "    return train_perf_df, test_perf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7b782a-0791-480d-8a34-cc415cb653eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2\n",
      "NEK2 binding moe UNDER\n",
      "trainX:torch.Size([90, 306]), train y: torch.Size([90]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.265   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.065   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.254   lengthscale: 3.169   noise: 2.569\n",
      "Iter 41/300 - Loss: 5.184   lengthscale: 4.482   noise: 2.987\n",
      "Iter 51/300 - Loss: 5.150   lengthscale: 5.798   noise: 3.235\n",
      "Iter 61/300 - Loss: 5.130   lengthscale: 6.980   noise: 3.339\n",
      "Iter 71/300 - Loss: 5.116   lengthscale: 7.999   noise: 3.330\n",
      "Iter 81/300 - Loss: 5.105   lengthscale: 8.871   noise: 3.242\n",
      "Iter 91/300 - Loss: 5.096   lengthscale: 9.626   noise: 3.101\n",
      "Iter 101/300 - Loss: 5.087   lengthscale: 10.293   noise: 2.927\n",
      "Iter 111/300 - Loss: 5.079   lengthscale: 10.890   noise: 2.731\n",
      "Iter 121/300 - Loss: 5.072   lengthscale: 11.433   noise: 2.523\n",
      "Iter 131/300 - Loss: 5.065   lengthscale: 11.931   noise: 2.311\n",
      "Iter 141/300 - Loss: 5.058   lengthscale: 12.391   noise: 2.097\n",
      "Iter 151/300 - Loss: 5.052   lengthscale: 12.819   noise: 1.887\n",
      "Iter 161/300 - Loss: 5.045   lengthscale: 13.218   noise: 1.683\n",
      "Iter 171/300 - Loss: 5.040   lengthscale: 13.593   noise: 1.490\n",
      "Iter 181/300 - Loss: 5.034   lengthscale: 13.946   noise: 1.308\n",
      "Iter 191/300 - Loss: 5.029   lengthscale: 14.280   noise: 1.142\n",
      "Iter 201/300 - Loss: 5.024   lengthscale: 14.597   noise: 0.991\n",
      "Iter 211/300 - Loss: 5.020   lengthscale: 14.902   noise: 0.856\n",
      "Iter 221/300 - Loss: 5.016   lengthscale: 15.195   noise: 0.739\n",
      "Iter 231/300 - Loss: 5.013   lengthscale: 15.480   noise: 0.637\n",
      "Iter 241/300 - Loss: 5.010   lengthscale: 15.758   noise: 0.550\n",
      "Iter 251/300 - Loss: 5.007   lengthscale: 16.032   noise: 0.476\n",
      "Iter 261/300 - Loss: 5.005   lengthscale: 16.302   noise: 0.414\n",
      "Iter 271/300 - Loss: 5.003   lengthscale: 16.568   noise: 0.362\n",
      "Iter 281/300 - Loss: 5.001   lengthscale: 16.832   noise: 0.318\n",
      "Iter 291/300 - Loss: 4.999   lengthscale: 17.094   noise: 0.282\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[45  0]\n",
      " [ 0 45]]\n",
      "accuracy: 0.6820, precision: 0.0851, recall: 0.6667, specificity: 0.6827, cm: [[185  86]\n",
      " [  4   8]]\n",
      "\n",
      "NEK2 binding mfp UNDER\n",
      "trainX:torch.Size([90, 2048]), train y: torch.Size([90]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 5.937   lengthscale: 1.284   noise: 1.299\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.144   noise: 1.998\n",
      "Iter 31/300 - Loss: 5.300   lengthscale: 2.950   noise: 2.648\n",
      "Iter 41/300 - Loss: 5.261   lengthscale: 3.226   noise: 3.189\n",
      "Iter 51/300 - Loss: 5.245   lengthscale: 3.148   noise: 3.604\n",
      "Iter 61/300 - Loss: 5.237   lengthscale: 2.919   noise: 3.906\n",
      "Iter 71/300 - Loss: 5.232   lengthscale: 2.634   noise: 4.122\n",
      "Iter 81/300 - Loss: 5.228   lengthscale: 2.339   noise: 4.278\n",
      "Iter 91/300 - Loss: 5.226   lengthscale: 2.072   noise: 4.394\n",
      "Iter 101/300 - Loss: 5.224   lengthscale: 1.855   noise: 4.489\n",
      "Iter 111/300 - Loss: 5.222   lengthscale: 1.685   noise: 4.572\n",
      "Iter 121/300 - Loss: 5.221   lengthscale: 1.548   noise: 4.649\n",
      "Iter 131/300 - Loss: 5.220   lengthscale: 1.436   noise: 4.724\n",
      "Iter 141/300 - Loss: 5.219   lengthscale: 1.345   noise: 4.799\n",
      "Iter 151/300 - Loss: 5.218   lengthscale: 1.272   noise: 4.875\n",
      "Iter 161/300 - Loss: 5.218   lengthscale: 1.214   noise: 4.952\n",
      "Iter 171/300 - Loss: 5.217   lengthscale: 1.167   noise: 5.031\n",
      "Iter 181/300 - Loss: 5.216   lengthscale: 1.129   noise: 5.110\n",
      "Iter 191/300 - Loss: 5.216   lengthscale: 1.098   noise: 5.190\n",
      "Iter 201/300 - Loss: 5.215   lengthscale: 1.071   noise: 5.270\n",
      "Iter 211/300 - Loss: 5.215   lengthscale: 1.047   noise: 5.350\n",
      "Iter 221/300 - Loss: 5.214   lengthscale: 1.026   noise: 5.430\n",
      "Iter 231/300 - Loss: 5.214   lengthscale: 1.008   noise: 5.510\n",
      "Iter 241/300 - Loss: 5.213   lengthscale: 0.991   noise: 5.591\n",
      "Iter 251/300 - Loss: 5.213   lengthscale: 0.976   noise: 5.671\n",
      "Iter 261/300 - Loss: 5.212   lengthscale: 0.962   noise: 5.750\n",
      "Iter 271/300 - Loss: 5.211   lengthscale: 0.949   noise: 5.830\n",
      "Iter 281/300 - Loss: 5.211   lengthscale: 0.937   noise: 5.908\n",
      "Iter 291/300 - Loss: 5.211   lengthscale: 0.925   noise: 5.986\n",
      "accuracy: 0.9778, precision: 0.9574, recall: 1.0000, specificity: 0.9556, cm: [[43  2]\n",
      " [ 0 45]]\n",
      "accuracy: 0.3463, precision: 0.0471, recall: 0.7500, specificity: 0.3284, cm: [[ 89 182]\n",
      " [  3   9]]\n",
      "\n",
      "NEK2 inhibition moe UNDER\n",
      "trainX:torch.Size([224, 306]), train y: torch.Size([224]), testX: torch.Size([408, 306]), test y: torch.Size([408])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2155: NumericalWarning: Runtime Error when computing Cholesky decomposition: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.. Using symeig method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 5.930   lengthscale: 1.288   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.429   lengthscale: 2.097   noise: 1.980\n",
      "Iter 31/300 - Loss: 5.212   lengthscale: 3.203   noise: 2.553\n",
      "Iter 41/300 - Loss: 5.091   lengthscale: 4.512   noise: 2.901\n",
      "Iter 51/300 - Loss: 5.019   lengthscale: 5.786   noise: 2.989\n",
      "Iter 61/300 - Loss: 4.973   lengthscale: 6.873   noise: 2.860\n",
      "Iter 71/300 - Loss: 4.939   lengthscale: 7.765   noise: 2.586\n",
      "Iter 81/300 - Loss: 4.911   lengthscale: 8.506   noise: 2.232\n",
      "Iter 91/300 - Loss: 4.886   lengthscale: 9.142   noise: 1.850\n",
      "Iter 101/300 - Loss: 4.863   lengthscale: 9.705   noise: 1.480\n",
      "Iter 111/300 - Loss: 4.844   lengthscale: 10.215   noise: 1.152\n",
      "Iter 121/300 - Loss: 4.827   lengthscale: 10.684   noise: 0.884\n",
      "Iter 131/300 - Loss: 4.814   lengthscale: 11.120   noise: 0.676\n",
      "Iter 141/300 - Loss: 4.803   lengthscale: 11.529   noise: 0.522\n",
      "Iter 151/300 - Loss: 4.794   lengthscale: 11.916   noise: 0.411\n",
      "Iter 161/300 - Loss: 4.787   lengthscale: 12.285   noise: 0.329\n",
      "Iter 171/300 - Loss: 4.782   lengthscale: 12.638   noise: 0.270\n",
      "Iter 181/300 - Loss: 4.777   lengthscale: 12.979   noise: 0.225\n",
      "Iter 191/300 - Loss: 4.773   lengthscale: 13.308   noise: 0.192\n",
      "Iter 201/300 - Loss: 4.769   lengthscale: 13.627   noise: 0.165\n",
      "Iter 211/300 - Loss: 4.766   lengthscale: 13.937   noise: 0.145\n",
      "Iter 221/300 - Loss: 4.763   lengthscale: 14.237   noise: 0.128\n",
      "Iter 231/300 - Loss: 4.761   lengthscale: 14.529   noise: 0.114\n",
      "Iter 241/300 - Loss: 4.758   lengthscale: 14.812   noise: 0.103\n",
      "Iter 251/300 - Loss: 4.756   lengthscale: 15.089   noise: 0.093\n",
      "Iter 261/300 - Loss: 4.755   lengthscale: 15.358   noise: 0.085\n",
      "Iter 271/300 - Loss: 4.753   lengthscale: 15.621   noise: 0.078\n",
      "Iter 281/300 - Loss: 4.751   lengthscale: 15.877   noise: 0.072\n",
      "Iter 291/300 - Loss: 4.750   lengthscale: 16.128   noise: 0.067\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[112   0]\n",
      " [  0 112]]\n",
      "accuracy: 0.8897, precision: 0.3559, recall: 0.7500, specificity: 0.9000, cm: [[342  38]\n",
      " [  7  21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK2 inhibition mfp UNDER\n",
      "trainX:torch.Size([224, 2048]), train y: torch.Size([224]), testX: torch.Size([408, 2048]), test y: torch.Size([408])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.936   lengthscale: 1.291   noise: 1.301\n",
      "Iter 21/300 - Loss: 5.451   lengthscale: 2.137   noise: 2.023\n",
      "Iter 31/300 - Loss: 5.332   lengthscale: 2.798   noise: 2.738\n",
      "Iter 41/300 - Loss: 5.293   lengthscale: 3.071   noise: 3.356\n",
      "Iter 51/300 - Loss: 5.275   lengthscale: 3.140   noise: 3.844\n",
      "Iter 61/300 - Loss: 5.266   lengthscale: 3.130   noise: 4.219\n",
      "Iter 71/300 - Loss: 5.260   lengthscale: 3.094   noise: 4.511\n",
      "Iter 81/300 - Loss: 5.256   lengthscale: 3.051   noise: 4.745\n",
      "Iter 91/300 - Loss: 5.252   lengthscale: 3.004   noise: 4.942\n",
      "Iter 101/300 - Loss: 5.248   lengthscale: 2.952   noise: 5.115\n",
      "Iter 111/300 - Loss: 5.244   lengthscale: 2.895   noise: 5.272\n",
      "Iter 121/300 - Loss: 5.241   lengthscale: 2.829   noise: 5.420\n",
      "Iter 131/300 - Loss: 5.237   lengthscale: 2.755   noise: 5.562\n",
      "Iter 141/300 - Loss: 5.234   lengthscale: 2.673   noise: 5.702\n",
      "Iter 151/300 - Loss: 5.231   lengthscale: 2.584   noise: 5.840\n",
      "Iter 161/300 - Loss: 5.228   lengthscale: 2.489   noise: 5.978\n",
      "Iter 171/300 - Loss: 5.224   lengthscale: 2.392   noise: 6.115\n",
      "Iter 181/300 - Loss: 5.222   lengthscale: 2.295   noise: 6.251\n",
      "Iter 191/300 - Loss: 5.219   lengthscale: 2.200   noise: 6.384\n",
      "Iter 201/300 - Loss: 5.217   lengthscale: 2.109   noise: 6.513\n",
      "Iter 211/300 - Loss: 5.215   lengthscale: 2.024   noise: 6.636\n",
      "Iter 221/300 - Loss: 5.213   lengthscale: 1.946   noise: 6.752\n",
      "Iter 231/300 - Loss: 5.212   lengthscale: 1.876   noise: 6.861\n",
      "Iter 241/300 - Loss: 5.210   lengthscale: 1.815   noise: 6.961\n",
      "Iter 251/300 - Loss: 5.209   lengthscale: 1.761   noise: 7.052\n",
      "Iter 261/300 - Loss: 5.208   lengthscale: 1.715   noise: 7.135\n",
      "Iter 271/300 - Loss: 5.207   lengthscale: 1.675   noise: 7.210\n",
      "Iter 281/300 - Loss: 5.207   lengthscale: 1.640   noise: 7.277\n",
      "Iter 291/300 - Loss: 5.206   lengthscale: 1.609   noise: 7.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9464, precision: 0.9630, recall: 0.9286, specificity: 0.9643, cm: [[108   4]\n",
      " [  8 104]]\n",
      "accuracy: 0.5049, precision: 0.0323, recall: 0.2143, specificity: 0.5263, cm: [[200 180]\n",
      " [ 22   6]]\n",
      "\n",
      "NEK3\n",
      "NEK3 binding moe UNDER\n",
      "trainX:torch.Size([128, 306]), train y: torch.Size([128]), testX: torch.Size([282, 306]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.285   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.122   noise: 1.981\n",
      "Iter 31/300 - Loss: 5.262   lengthscale: 3.230   noise: 2.571\n",
      "Iter 41/300 - Loss: 5.206   lengthscale: 4.438   noise: 3.003\n",
      "Iter 51/300 - Loss: 5.189   lengthscale: 5.448   noise: 3.294\n",
      "Iter 61/300 - Loss: 5.183   lengthscale: 6.169   noise: 3.475\n",
      "Iter 71/300 - Loss: 5.180   lengthscale: 6.686   noise: 3.576\n",
      "Iter 81/300 - Loss: 5.179   lengthscale: 7.087   noise: 3.620\n",
      "Iter 91/300 - Loss: 5.178   lengthscale: 7.423   noise: 3.626\n",
      "Iter 101/300 - Loss: 5.177   lengthscale: 7.719   noise: 3.606\n",
      "Iter 111/300 - Loss: 5.176   lengthscale: 7.987   noise: 3.570\n",
      "Iter 121/300 - Loss: 5.175   lengthscale: 8.231   noise: 3.524\n",
      "Iter 131/300 - Loss: 5.175   lengthscale: 8.454   noise: 3.471\n",
      "Iter 141/300 - Loss: 5.174   lengthscale: 8.656   noise: 3.414\n",
      "Iter 151/300 - Loss: 5.173   lengthscale: 8.840   noise: 3.353\n",
      "Iter 161/300 - Loss: 5.173   lengthscale: 9.008   noise: 3.290\n",
      "Iter 171/300 - Loss: 5.172   lengthscale: 9.161   noise: 3.223\n",
      "Iter 181/300 - Loss: 5.171   lengthscale: 9.301   noise: 3.154\n",
      "Iter 191/300 - Loss: 5.171   lengthscale: 9.430   noise: 3.083\n",
      "Iter 201/300 - Loss: 5.170   lengthscale: 9.548   noise: 3.009\n",
      "Iter 211/300 - Loss: 5.169   lengthscale: 9.656   noise: 2.932\n",
      "Iter 221/300 - Loss: 5.169   lengthscale: 9.755   noise: 2.854\n",
      "Iter 231/300 - Loss: 5.168   lengthscale: 9.846   noise: 2.773\n",
      "Iter 241/300 - Loss: 5.168   lengthscale: 9.929   noise: 2.691\n",
      "Iter 251/300 - Loss: 5.167   lengthscale: 10.005   noise: 2.607\n",
      "Iter 261/300 - Loss: 5.166   lengthscale: 10.073   noise: 2.522\n",
      "Iter 271/300 - Loss: 5.166   lengthscale: 10.136   noise: 2.435\n",
      "Iter 281/300 - Loss: 5.165   lengthscale: 10.192   noise: 2.348\n",
      "Iter 291/300 - Loss: 5.164   lengthscale: 10.243   noise: 2.260\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[64  0]\n",
      " [ 0 64]]\n",
      "accuracy: 0.5709, precision: 0.1000, recall: 0.7647, specificity: 0.5585, cm: [[148 117]\n",
      " [  4  13]]\n",
      "\n",
      "NEK3 binding mfp UNDER\n",
      "trainX:torch.Size([128, 2048]), train y: torch.Size([128]), testX: torch.Size([282, 2048]), test y: torch.Size([282])\n",
      "Iter 1/300 - Loss: 7.106   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.935   lengthscale: 1.297   noise: 1.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21/300 - Loss: 5.429   lengthscale: 2.161   noise: 2.002\n",
      "Iter 31/300 - Loss: 5.295   lengthscale: 2.963   noise: 2.659\n",
      "Iter 41/300 - Loss: 5.257   lengthscale: 3.334   noise: 3.205\n",
      "Iter 51/300 - Loss: 5.243   lengthscale: 3.435   noise: 3.622\n",
      "Iter 61/300 - Loss: 5.237   lengthscale: 3.423   noise: 3.928\n",
      "Iter 71/300 - Loss: 5.234   lengthscale: 3.370   noise: 4.153\n",
      "Iter 81/300 - Loss: 5.232   lengthscale: 3.305   noise: 4.323\n",
      "Iter 91/300 - Loss: 5.230   lengthscale: 3.234   noise: 4.456\n",
      "Iter 101/300 - Loss: 5.229   lengthscale: 3.158   noise: 4.567\n",
      "Iter 111/300 - Loss: 5.227   lengthscale: 3.076   noise: 4.665\n",
      "Iter 121/300 - Loss: 5.226   lengthscale: 2.986   noise: 4.754\n",
      "Iter 131/300 - Loss: 5.225   lengthscale: 2.888   noise: 4.841\n",
      "Iter 141/300 - Loss: 5.224   lengthscale: 2.784   noise: 4.926\n",
      "Iter 151/300 - Loss: 5.222   lengthscale: 2.675   noise: 5.011\n",
      "Iter 161/300 - Loss: 5.221   lengthscale: 2.564   noise: 5.097\n",
      "Iter 171/300 - Loss: 5.220   lengthscale: 2.453   noise: 5.185\n",
      "Iter 181/300 - Loss: 5.219   lengthscale: 2.345   noise: 5.274\n",
      "Iter 191/300 - Loss: 5.218   lengthscale: 2.243   noise: 5.363\n",
      "Iter 201/300 - Loss: 5.217   lengthscale: 2.150   noise: 5.453\n",
      "Iter 211/300 - Loss: 5.216   lengthscale: 2.066   noise: 5.543\n",
      "Iter 221/300 - Loss: 5.215   lengthscale: 1.994   noise: 5.633\n",
      "Iter 231/300 - Loss: 5.214   lengthscale: 1.934   noise: 5.723\n",
      "Iter 241/300 - Loss: 5.214   lengthscale: 1.884   noise: 5.813\n",
      "Iter 251/300 - Loss: 5.213   lengthscale: 1.844   noise: 5.902\n",
      "Iter 261/300 - Loss: 5.212   lengthscale: 1.813   noise: 5.990\n",
      "Iter 271/300 - Loss: 5.211   lengthscale: 1.788   noise: 6.077\n",
      "Iter 281/300 - Loss: 5.211   lengthscale: 1.769   noise: 6.163\n",
      "Iter 291/300 - Loss: 5.210   lengthscale: 1.754   noise: 6.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9688, precision: 0.9688, recall: 0.9688, specificity: 0.9688, cm: [[62  2]\n",
      " [ 2 62]]\n",
      "accuracy: 0.3865, precision: 0.0618, recall: 0.6471, specificity: 0.3698, cm: [[ 98 167]\n",
      " [  6  11]]\n",
      "\n",
      "NEK5\n",
      "NEK5 binding moe UNDER\n",
      "trainX:torch.Size([154, 306]), train y: torch.Size([154]), testX: torch.Size([248, 306]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.257   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.437   lengthscale: 2.050   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.252   lengthscale: 3.150   noise: 2.569\n",
      "Iter 41/300 - Loss: 5.175   lengthscale: 4.473   noise: 2.983\n",
      "Iter 51/300 - Loss: 5.137   lengthscale: 5.795   noise: 3.218\n",
      "Iter 61/300 - Loss: 5.116   lengthscale: 6.938   noise: 3.304\n",
      "Iter 71/300 - Loss: 5.104   lengthscale: 7.863   noise: 3.283\n",
      "Iter 81/300 - Loss: 5.096   lengthscale: 8.607   noise: 3.195\n",
      "Iter 91/300 - Loss: 5.089   lengthscale: 9.219   noise: 3.068\n",
      "Iter 101/300 - Loss: 5.084   lengthscale: 9.736   noise: 2.922\n",
      "Iter 111/300 - Loss: 5.079   lengthscale: 10.183   noise: 2.768\n",
      "Iter 121/300 - Loss: 5.075   lengthscale: 10.576   noise: 2.611\n",
      "Iter 131/300 - Loss: 5.071   lengthscale: 10.926   noise: 2.457\n",
      "Iter 141/300 - Loss: 5.068   lengthscale: 11.239   noise: 2.306\n",
      "Iter 151/300 - Loss: 5.065   lengthscale: 11.522   noise: 2.160\n",
      "Iter 161/300 - Loss: 5.062   lengthscale: 11.779   noise: 2.018\n",
      "Iter 171/300 - Loss: 5.059   lengthscale: 12.012   noise: 1.880\n",
      "Iter 181/300 - Loss: 5.057   lengthscale: 12.224   noise: 1.747\n",
      "Iter 191/300 - Loss: 5.054   lengthscale: 12.419   noise: 1.620\n",
      "Iter 201/300 - Loss: 5.052   lengthscale: 12.597   noise: 1.497\n",
      "Iter 211/300 - Loss: 5.050   lengthscale: 12.761   noise: 1.379\n",
      "Iter 221/300 - Loss: 5.048   lengthscale: 12.913   noise: 1.268\n",
      "Iter 231/300 - Loss: 5.047   lengthscale: 13.054   noise: 1.162\n",
      "Iter 241/300 - Loss: 5.045   lengthscale: 13.185   noise: 1.063\n",
      "Iter 251/300 - Loss: 5.043   lengthscale: 13.308   noise: 0.970\n",
      "Iter 261/300 - Loss: 5.042   lengthscale: 13.424   noise: 0.884\n",
      "Iter 271/300 - Loss: 5.041   lengthscale: 13.534   noise: 0.804\n",
      "Iter 281/300 - Loss: 5.040   lengthscale: 13.640   noise: 0.730\n",
      "Iter 291/300 - Loss: 5.039   lengthscale: 13.743   noise: 0.663\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[77  0]\n",
      " [ 0 77]]\n",
      "accuracy: 0.7540, precision: 0.2113, recall: 0.7500, specificity: 0.7544, cm: [[172  56]\n",
      " [  5  15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEK5 binding mfp UNDER\n",
      "trainX:torch.Size([154, 2048]), train y: torch.Size([154]), testX: torch.Size([248, 2048]), test y: torch.Size([248])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.949   lengthscale: 1.287   noise: 1.301\n",
      "Iter 21/300 - Loss: 5.451   lengthscale: 2.143   noise: 2.019\n",
      "Iter 31/300 - Loss: 5.320   lengthscale: 2.915   noise: 2.713\n",
      "Iter 41/300 - Loss: 5.279   lengthscale: 3.292   noise: 3.305\n",
      "Iter 51/300 - Loss: 5.263   lengthscale: 3.433   noise: 3.769\n",
      "Iter 61/300 - Loss: 5.255   lengthscale: 3.478   noise: 4.122\n",
      "Iter 71/300 - Loss: 5.251   lengthscale: 3.490   noise: 4.395\n",
      "Iter 81/300 - Loss: 5.247   lengthscale: 3.494   noise: 4.613\n",
      "Iter 91/300 - Loss: 5.244   lengthscale: 3.493   noise: 4.793\n",
      "Iter 101/300 - Loss: 5.242   lengthscale: 3.490   noise: 4.951\n",
      "Iter 111/300 - Loss: 5.239   lengthscale: 3.482   noise: 5.095\n",
      "Iter 121/300 - Loss: 5.237   lengthscale: 3.470   noise: 5.231\n",
      "Iter 131/300 - Loss: 5.235   lengthscale: 3.450   noise: 5.361\n",
      "Iter 141/300 - Loss: 5.233   lengthscale: 3.422   noise: 5.489\n",
      "Iter 151/300 - Loss: 5.230   lengthscale: 3.385   noise: 5.615\n",
      "Iter 161/300 - Loss: 5.228   lengthscale: 3.340   noise: 5.741\n",
      "Iter 171/300 - Loss: 5.226   lengthscale: 3.287   noise: 5.866\n",
      "Iter 181/300 - Loss: 5.224   lengthscale: 3.226   noise: 5.991\n",
      "Iter 191/300 - Loss: 5.222   lengthscale: 3.159   noise: 6.116\n",
      "Iter 201/300 - Loss: 5.220   lengthscale: 3.085   noise: 6.239\n",
      "Iter 211/300 - Loss: 5.218   lengthscale: 3.007   noise: 6.360\n",
      "Iter 221/300 - Loss: 5.216   lengthscale: 2.926   noise: 6.478\n",
      "Iter 231/300 - Loss: 5.215   lengthscale: 2.842   noise: 6.592\n",
      "Iter 241/300 - Loss: 5.213   lengthscale: 2.759   noise: 6.702\n",
      "Iter 251/300 - Loss: 5.212   lengthscale: 2.678   noise: 6.807\n",
      "Iter 261/300 - Loss: 5.211   lengthscale: 2.601   noise: 6.905\n",
      "Iter 271/300 - Loss: 5.210   lengthscale: 2.528   noise: 6.997\n",
      "Iter 281/300 - Loss: 5.209   lengthscale: 2.462   noise: 7.081\n",
      "Iter 291/300 - Loss: 5.208   lengthscale: 2.402   noise: 7.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9481, precision: 0.9481, recall: 0.9481, specificity: 0.9481, cm: [[73  4]\n",
      " [ 4 73]]\n",
      "accuracy: 0.4798, precision: 0.0709, recall: 0.4500, specificity: 0.4825, cm: [[110 118]\n",
      " [ 11   9]]\n",
      "\n",
      "NEK9\n",
      "NEK9 binding moe UNDER\n",
      "trainX:torch.Size([96, 306]), train y: torch.Size([96]), testX: torch.Size([283, 306]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.254   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.438   lengthscale: 2.055   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.260   lengthscale: 3.165   noise: 2.571\n",
      "Iter 41/300 - Loss: 5.197   lengthscale: 4.479   noise: 2.999\n",
      "Iter 51/300 - Loss: 5.170   lengthscale: 5.795   noise: 3.272\n",
      "Iter 61/300 - Loss: 5.156   lengthscale: 6.963   noise: 3.418\n",
      "Iter 71/300 - Loss: 5.148   lengthscale: 7.938   noise: 3.470\n",
      "Iter 81/300 - Loss: 5.143   lengthscale: 8.737   noise: 3.460\n",
      "Iter 91/300 - Loss: 5.140   lengthscale: 9.398   noise: 3.412\n",
      "Iter 101/300 - Loss: 5.137   lengthscale: 9.957   noise: 3.343\n",
      "Iter 111/300 - Loss: 5.134   lengthscale: 10.437   noise: 3.264\n",
      "Iter 121/300 - Loss: 5.132   lengthscale: 10.856   noise: 3.180\n",
      "Iter 131/300 - Loss: 5.131   lengthscale: 11.225   noise: 3.095\n",
      "Iter 141/300 - Loss: 5.129   lengthscale: 11.554   noise: 3.010\n",
      "Iter 151/300 - Loss: 5.128   lengthscale: 11.848   noise: 2.925\n",
      "Iter 161/300 - Loss: 5.126   lengthscale: 12.111   noise: 2.842\n",
      "Iter 171/300 - Loss: 5.125   lengthscale: 12.349   noise: 2.760\n",
      "Iter 181/300 - Loss: 5.124   lengthscale: 12.563   noise: 2.679\n",
      "Iter 191/300 - Loss: 5.123   lengthscale: 12.756   noise: 2.599\n",
      "Iter 201/300 - Loss: 5.122   lengthscale: 12.929   noise: 2.521\n",
      "Iter 211/300 - Loss: 5.122   lengthscale: 13.086   noise: 2.443\n",
      "Iter 221/300 - Loss: 5.121   lengthscale: 13.226   noise: 2.366\n",
      "Iter 231/300 - Loss: 5.120   lengthscale: 13.351   noise: 2.291\n",
      "Iter 241/300 - Loss: 5.119   lengthscale: 13.462   noise: 2.217\n",
      "Iter 251/300 - Loss: 5.119   lengthscale: 13.561   noise: 2.144\n",
      "Iter 261/300 - Loss: 5.118   lengthscale: 13.647   noise: 2.072\n",
      "Iter 271/300 - Loss: 5.118   lengthscale: 13.722   noise: 2.001\n",
      "Iter 281/300 - Loss: 5.117   lengthscale: 13.787   noise: 1.932\n",
      "Iter 291/300 - Loss: 5.117   lengthscale: 13.841   noise: 1.864\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[48  0]\n",
      " [ 0 48]]\n",
      "accuracy: 0.6820, precision: 0.0947, recall: 0.6923, specificity: 0.6815, cm: [[184  86]\n",
      " [  4   9]]\n",
      "\n",
      "NEK9 binding mfp UNDER\n",
      "trainX:torch.Size([96, 2048]), train y: torch.Size([96]), testX: torch.Size([283, 2048]), test y: torch.Size([283])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.935   lengthscale: 1.285   noise: 1.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21/300 - Loss: 5.436   lengthscale: 2.143   noise: 1.998\n",
      "Iter 31/300 - Loss: 5.303   lengthscale: 2.911   noise: 2.650\n",
      "Iter 41/300 - Loss: 5.264   lengthscale: 3.140   noise: 3.196\n",
      "Iter 51/300 - Loss: 5.248   lengthscale: 3.028   noise: 3.614\n",
      "Iter 61/300 - Loss: 5.239   lengthscale: 2.771   noise: 3.918\n",
      "Iter 71/300 - Loss: 5.233   lengthscale: 2.458   noise: 4.133\n",
      "Iter 81/300 - Loss: 5.229   lengthscale: 2.126   noise: 4.285\n",
      "Iter 91/300 - Loss: 5.225   lengthscale: 1.808   noise: 4.396\n",
      "Iter 101/300 - Loss: 5.222   lengthscale: 1.538   noise: 4.483\n",
      "Iter 111/300 - Loss: 5.220   lengthscale: 1.338   noise: 4.558\n",
      "Iter 121/300 - Loss: 5.219   lengthscale: 1.205   noise: 4.631\n",
      "Iter 131/300 - Loss: 5.218   lengthscale: 1.118   noise: 4.704\n",
      "Iter 141/300 - Loss: 5.218   lengthscale: 1.059   noise: 4.778\n",
      "Iter 151/300 - Loss: 5.217   lengthscale: 1.018   noise: 4.852\n",
      "Iter 161/300 - Loss: 5.217   lengthscale: 0.989   noise: 4.926\n",
      "Iter 171/300 - Loss: 5.216   lengthscale: 0.965   noise: 4.999\n",
      "Iter 181/300 - Loss: 5.216   lengthscale: 0.946   noise: 5.072\n",
      "Iter 191/300 - Loss: 5.215   lengthscale: 0.929   noise: 5.146\n",
      "Iter 201/300 - Loss: 5.215   lengthscale: 0.915   noise: 5.221\n",
      "Iter 211/300 - Loss: 5.214   lengthscale: 0.903   noise: 5.296\n",
      "Iter 221/300 - Loss: 5.214   lengthscale: 0.892   noise: 5.372\n",
      "Iter 231/300 - Loss: 5.213   lengthscale: 0.883   noise: 5.448\n",
      "Iter 241/300 - Loss: 5.213   lengthscale: 0.875   noise: 5.524\n",
      "Iter 251/300 - Loss: 5.212   lengthscale: 0.867   noise: 5.600\n",
      "Iter 261/300 - Loss: 5.212   lengthscale: 0.860   noise: 5.676\n",
      "Iter 271/300 - Loss: 5.211   lengthscale: 0.854   noise: 5.751\n",
      "Iter 281/300 - Loss: 5.211   lengthscale: 0.848   noise: 5.826\n",
      "Iter 291/300 - Loss: 5.210   lengthscale: 0.843   noise: 5.901\n",
      "accuracy: 0.9792, precision: 0.9792, recall: 0.9792, specificity: 0.9792, cm: [[47  1]\n",
      " [ 1 47]]\n",
      "accuracy: 0.1696, precision: 0.0524, recall: 1.0000, specificity: 0.1296, cm: [[ 35 235]\n",
      " [  0  13]]\n",
      "\n",
      "NEK9 inhibition moe UNDER\n",
      "trainX:torch.Size([66, 306]), train y: torch.Size([66]), testX: torch.Size([80, 306]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.107   lengthscale: 0.693   noise: 0.693\n",
      "Iter 11/300 - Loss: 5.931   lengthscale: 1.274   noise: 1.297\n",
      "Iter 21/300 - Loss: 5.436   lengthscale: 2.057   noise: 1.982\n",
      "Iter 31/300 - Loss: 5.242   lengthscale: 3.137   noise: 2.566\n",
      "Iter 41/300 - Loss: 5.141   lengthscale: 4.463   noise: 2.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 51/300 - Loss: 5.076   lengthscale: 5.830   noise: 3.126\n",
      "Iter 61/300 - Loss: 5.031   lengthscale: 7.063   noise: 3.089\n",
      "Iter 71/300 - Loss: 4.996   lengthscale: 8.116   noise: 2.894\n",
      "Iter 81/300 - Loss: 4.966   lengthscale: 9.013   noise: 2.590\n",
      "Iter 91/300 - Loss: 4.938   lengthscale: 9.792   noise: 2.221\n",
      "Iter 101/300 - Loss: 4.912   lengthscale: 10.488   noise: 1.827\n",
      "Iter 111/300 - Loss: 4.888   lengthscale: 11.122   noise: 1.443\n",
      "Iter 121/300 - Loss: 4.866   lengthscale: 11.709   noise: 1.102\n",
      "Iter 131/300 - Loss: 4.848   lengthscale: 12.257   noise: 0.823\n",
      "Iter 141/300 - Loss: 4.832   lengthscale: 12.772   noise: 0.612\n",
      "Iter 151/300 - Loss: 4.820   lengthscale: 13.259   noise: 0.461\n",
      "Iter 161/300 - Loss: 4.811   lengthscale: 13.722   noise: 0.356\n",
      "Iter 171/300 - Loss: 4.803   lengthscale: 14.163   noise: 0.281\n",
      "Iter 181/300 - Loss: 4.797   lengthscale: 14.586   noise: 0.229\n",
      "Iter 191/300 - Loss: 4.791   lengthscale: 14.992   noise: 0.190\n",
      "Iter 201/300 - Loss: 4.787   lengthscale: 15.383   noise: 0.162\n",
      "Iter 211/300 - Loss: 4.783   lengthscale: 15.761   noise: 0.140\n",
      "Iter 221/300 - Loss: 4.780   lengthscale: 16.125   noise: 0.122\n",
      "Iter 231/300 - Loss: 4.777   lengthscale: 16.477   noise: 0.108\n",
      "Iter 241/300 - Loss: 4.774   lengthscale: 16.818   noise: 0.097\n",
      "Iter 251/300 - Loss: 4.772   lengthscale: 17.149   noise: 0.087\n",
      "Iter 261/300 - Loss: 4.770   lengthscale: 17.470   noise: 0.080\n",
      "Iter 271/300 - Loss: 4.768   lengthscale: 17.783   noise: 0.073\n",
      "Iter 281/300 - Loss: 4.766   lengthscale: 18.087   noise: 0.067\n",
      "Iter 291/300 - Loss: 4.765   lengthscale: 18.383   noise: 0.062\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000, specificity: 1.0000, cm: [[33  0]\n",
      " [ 0 33]]\n",
      "accuracy: 0.8750, precision: 0.4615, recall: 0.6667, specificity: 0.9014, cm: [[64  7]\n",
      " [ 3  6]]\n",
      "\n",
      "NEK9 inhibition mfp UNDER\n",
      "trainX:torch.Size([66, 2048]), train y: torch.Size([66]), testX: torch.Size([80, 2048]), test y: torch.Size([80])\n",
      "Iter 1/300 - Loss: 7.108   lengthscale: 0.693   noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11/300 - Loss: 6.000   lengthscale: 1.301   noise: 1.305\n",
      "Iter 21/300 - Loss: 5.529   lengthscale: 2.173   noise: 2.053\n",
      "Iter 31/300 - Loss: 5.381   lengthscale: 3.007   noise: 2.804\n",
      "Iter 41/300 - Loss: 5.329   lengthscale: 3.381   noise: 3.473\n",
      "Iter 51/300 - Loss: 5.303   lengthscale: 3.437   noise: 4.026\n",
      "Iter 61/300 - Loss: 5.287   lengthscale: 3.356   noise: 4.473\n",
      "Iter 71/300 - Loss: 5.275   lengthscale: 3.220   noise: 4.836\n",
      "Iter 81/300 - Loss: 5.265   lengthscale: 3.062   noise: 5.140\n",
      "Iter 91/300 - Loss: 5.255   lengthscale: 2.893   noise: 5.404\n",
      "Iter 101/300 - Loss: 5.247   lengthscale: 2.724   noise: 5.642\n",
      "Iter 111/300 - Loss: 5.240   lengthscale: 2.563   noise: 5.862\n",
      "Iter 121/300 - Loss: 5.233   lengthscale: 2.420   noise: 6.068\n",
      "Iter 131/300 - Loss: 5.227   lengthscale: 2.300   noise: 6.264\n",
      "Iter 141/300 - Loss: 5.222   lengthscale: 2.205   noise: 6.447\n",
      "Iter 151/300 - Loss: 5.218   lengthscale: 2.133   noise: 6.618\n",
      "Iter 161/300 - Loss: 5.215   lengthscale: 2.079   noise: 6.774\n",
      "Iter 171/300 - Loss: 5.213   lengthscale: 2.038   noise: 6.915\n",
      "Iter 181/300 - Loss: 5.211   lengthscale: 2.008   noise: 7.041\n",
      "Iter 191/300 - Loss: 5.209   lengthscale: 1.985   noise: 7.151\n",
      "Iter 201/300 - Loss: 5.208   lengthscale: 1.967   noise: 7.248\n",
      "Iter 211/300 - Loss: 5.207   lengthscale: 1.952   noise: 7.331\n",
      "Iter 221/300 - Loss: 5.206   lengthscale: 1.940   noise: 7.402\n",
      "Iter 231/300 - Loss: 5.206   lengthscale: 1.930   noise: 7.462\n",
      "Iter 241/300 - Loss: 5.205   lengthscale: 1.922   noise: 7.513\n",
      "Iter 251/300 - Loss: 5.205   lengthscale: 1.914   noise: 7.556\n",
      "Iter 261/300 - Loss: 5.204   lengthscale: 1.908   noise: 7.592\n",
      "Iter 271/300 - Loss: 5.204   lengthscale: 1.902   noise: 7.621\n",
      "Iter 281/300 - Loss: 5.204   lengthscale: 1.897   noise: 7.646\n",
      "Iter 291/300 - Loss: 5.204   lengthscale: 1.893   noise: 7.666\n",
      "accuracy: 0.8939, precision: 0.8611, recall: 0.9394, specificity: 0.8485, cm: [[28  5]\n",
      " [ 2 31]]\n",
      "accuracy: 0.5500, precision: 0.1538, recall: 0.6667, specificity: 0.5352, cm: [[38 33]\n",
      " [ 3  6]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/Users/jayceepang/msse/capstone/gpytorch-venv/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/undersampler_validation/under_batch2_jp/'\n",
    "samplings = ['UNDER'] \n",
    "feat_types = ['moe', 'mfp']\n",
    "\n",
    "neks = ['2', '3', '5', '9']\n",
    "GP_path= '/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/undersampler_validation/under_batch2_jp/'\n",
    "for nek in neks:\n",
    "    print(f'NEK{nek}')\n",
    "    if nek in ['3','5']: \n",
    "        bind_inhib = ['binding']\n",
    "    else: \n",
    "        bind_inhib = ['binding', 'inhibition']\n",
    "    for bi in bind_inhib: \n",
    "        if bi == 'binding': \n",
    "            this_bi = 'bind' \n",
    "        if bi == 'inhibition': \n",
    "            this_bi = 'inhib'\n",
    "        \n",
    "        for feat in feat_types: \n",
    "            for samp in samplings: \n",
    "                print(f'NEK{nek} {bi} {feat} {samp}')\n",
    "                file_root = f'NEK{nek}_{bi}_{feat}_{samp}_batch2'\n",
    "                trainX, trainy, testX, testy = make_torch_tens_float(GP_path,file_root) \n",
    "                print(f'trainX:{trainX.shape}, train y: {trainy.shape}, testX: {testX.shape}, test y: {testy.shape}')\n",
    "                train_perf_df, test_perf_df = save_results(trainX, trainy, testX, testy,file_root, n_iterations=300)\n",
    "                train_perf_df['NEK'] = f'NEK{nek}_{bi}'\n",
    "                train_perf_df['strategy'] = f'{samp}'\n",
    "                train_perf_df['feat_type'] = f'{feat}'\n",
    "                test_perf_df['NEK'] = f'NEK{nek}_{bi}'\n",
    "                test_perf_df['strategy'] = f'{samp}'\n",
    "                test_perf_df['feat_type'] = f'{feat}'\n",
    "                train_perf_df.to_csv(f'{GP_path}{file_root}_train_GP_matern.csv',index=False) \n",
    "                test_perf_df.to_csv(f'{GP_path}{file_root}_test_GP_matern.csv',index=False) \n",
    "                print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13396b47-4690-48c6-b1c1-dad4ac932eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] \n",
    "metric_cols = ['accuracy', 'precision', 'recall', 'specificity','TN', 'FN', 'FP', 'TP','f1', 'ROC-AUC', 'MCC', 'Balanced Accuracy',\n",
    "       'model', 'cm', 'prediction_type', 'NEK', 'feat_type', 'strategy']\n",
    "for i, nek in enumerate(neks):\n",
    "    if nek in ['2','9']: \n",
    "        bind_inhib = ['binding', 'inhibition']\n",
    "    else: \n",
    "        bind_inhib = ['binding'] \n",
    "    for bi in bind_inhib: \n",
    "        if bi == 'binding': \n",
    "            this_bi = 'bind'\n",
    "        else: \n",
    "            this_bi = 'inhib' \n",
    "        for feat in ['moe', 'mfp']: \n",
    "            result_df = pd.read_csv(f'{GP_path}NEK{nek}_{bi}_{feat}_UNDER_batch2_test_GP_matern.csv')\n",
    "            results.append(result_df.iloc[[0]][metric_cols].values.flatten())\n",
    "results_df =  pd.DataFrame(results,columns=metric_cols)\n",
    "results_df['model'] = results_df['model'].str.replace('scaled', 'raw')\n",
    "results_df['strategy'] =results_df['strategy'].str.replace('scaled', 'raw')\n",
    "results_df['strategy'] = results_df['strategy'].str.replace('scaled', 'raw')\n",
    "results_df.to_csv(GP_path+'GP_matern_results_UDNER_batch2.csv', index=False) \n",
    "results_df['modeling_type'] = 'GP_matern' \n",
    "results_df['set'] = 'UNDER_batch2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480f6e96-44f7-4bc3-a090-0e8ef740eb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEK</th>\n",
       "      <th>modeling_type</th>\n",
       "      <th>feat_type</th>\n",
       "      <th>set</th>\n",
       "      <th>cm</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[89, 182, 3, 9]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.328413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[4, 267, 0, 12]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[185, 86, 4, 8]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[212, 59, 5, 7]</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.782288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[200, 180, 22, 6]</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[100, 280, 5, 23]</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[342, 38, 7, 21]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NEK2_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[333, 47, 7, 21]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.876316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[98, 167, 6, 11]</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.369811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[125, 140, 3, 14]</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.471698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[148, 117, 4, 13]</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.558491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NEK3_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[159, 106, 5, 12]</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[110, 118, 11, 9]</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.482456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[118, 110, 8, 12]</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.517544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[172, 56, 5, 15]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NEK5_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[167, 61, 4, 16]</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.732456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[35, 235, 0, 13]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[201, 69, 10, 3]</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[184, 86, 4, 9]</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NEK9_binding</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[180, 90, 5, 8]</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[38, 33, 3, 6]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>mfp</td>\n",
       "      <td>original</td>\n",
       "      <td>[53, 18, 7, 2]</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>UNDER_batch2</td>\n",
       "      <td>[64, 7, 3, 6]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NEK9_inhibition</td>\n",
       "      <td>GP_matern</td>\n",
       "      <td>moe</td>\n",
       "      <td>original</td>\n",
       "      <td>[66, 5, 2, 7]</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.929577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NEK modeling_type feat_type           set                 cm  \\\n",
       "1      NEK2_binding     GP_matern       mfp  UNDER_batch2    [89, 182, 3, 9]   \n",
       "5      NEK2_binding     GP_matern       mfp      original    [4, 267, 0, 12]   \n",
       "0      NEK2_binding     GP_matern       moe  UNDER_batch2    [185, 86, 4, 8]   \n",
       "1      NEK2_binding     GP_matern       moe      original    [212, 59, 5, 7]   \n",
       "3   NEK2_inhibition     GP_matern       mfp  UNDER_batch2  [200, 180, 22, 6]   \n",
       "13  NEK2_inhibition     GP_matern       mfp      original  [100, 280, 5, 23]   \n",
       "2   NEK2_inhibition     GP_matern       moe  UNDER_batch2   [342, 38, 7, 21]   \n",
       "9   NEK2_inhibition     GP_matern       moe      original   [333, 47, 7, 21]   \n",
       "5      NEK3_binding     GP_matern       mfp  UNDER_batch2   [98, 167, 6, 11]   \n",
       "21     NEK3_binding     GP_matern       mfp      original  [125, 140, 3, 14]   \n",
       "4      NEK3_binding     GP_matern       moe  UNDER_batch2  [148, 117, 4, 13]   \n",
       "17     NEK3_binding     GP_matern       moe      original  [159, 106, 5, 12]   \n",
       "7      NEK5_binding     GP_matern       mfp  UNDER_batch2  [110, 118, 11, 9]   \n",
       "29     NEK5_binding     GP_matern       mfp      original  [118, 110, 8, 12]   \n",
       "6      NEK5_binding     GP_matern       moe  UNDER_batch2   [172, 56, 5, 15]   \n",
       "25     NEK5_binding     GP_matern       moe      original   [167, 61, 4, 16]   \n",
       "9      NEK9_binding     GP_matern       mfp  UNDER_batch2   [35, 235, 0, 13]   \n",
       "37     NEK9_binding     GP_matern       mfp      original   [201, 69, 10, 3]   \n",
       "8      NEK9_binding     GP_matern       moe  UNDER_batch2    [184, 86, 4, 9]   \n",
       "33     NEK9_binding     GP_matern       moe      original    [180, 90, 5, 8]   \n",
       "11  NEK9_inhibition     GP_matern       mfp  UNDER_batch2     [38, 33, 3, 6]   \n",
       "45  NEK9_inhibition     GP_matern       mfp      original     [53, 18, 7, 2]   \n",
       "10  NEK9_inhibition     GP_matern       moe  UNDER_batch2      [64, 7, 3, 6]   \n",
       "41  NEK9_inhibition     GP_matern       moe      original      [66, 5, 2, 7]   \n",
       "\n",
       "      recall  specificity  \n",
       "1   0.750000     0.328413  \n",
       "5   1.000000     0.014760  \n",
       "0   0.666667     0.682657  \n",
       "1   0.583333     0.782288  \n",
       "3   0.214286     0.526316  \n",
       "13  0.821429     0.263158  \n",
       "2   0.750000     0.900000  \n",
       "9   0.750000     0.876316  \n",
       "5   0.647059     0.369811  \n",
       "21  0.823529     0.471698  \n",
       "4   0.764706     0.558491  \n",
       "17  0.705882     0.600000  \n",
       "7   0.450000     0.482456  \n",
       "29  0.600000     0.517544  \n",
       "6   0.750000     0.754386  \n",
       "25  0.800000     0.732456  \n",
       "9   1.000000     0.129630  \n",
       "37  0.230769     0.744444  \n",
       "8   0.692308     0.681481  \n",
       "33  0.615385     0.666667  \n",
       "11  0.666667     0.535211  \n",
       "45  0.222222     0.746479  \n",
       "10  0.666667     0.901408  \n",
       "41  0.777778     0.929577  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results = pd.read_csv('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/NEK/general_NEK/final_paper_models.csv')\n",
    "original_results = original_results[(original_results['set'] == 'original') & (original_results['modeling_type'] == 'GP_matern')]\n",
    "only_under = original_results[original_results['strategy'] == 'UNDER']\n",
    "all_under_rf = pd.concat([results_df, only_under])\n",
    "comparison = all_under_rf[['NEK', 'modeling_type','feat_type','set','cm', 'recall', 'specificity']]\n",
    "comparison = comparison.sort_values(['NEK', 'feat_type'])\n",
    "comparison "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9ae530c-d286-416c-bd40-38d387ab129c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e740db-9784-4772-9395-092f6410bafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c0b76-3ba2-424a-9b22-73587f349f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch-venv",
   "language": "python",
   "name": "gpytorch-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
