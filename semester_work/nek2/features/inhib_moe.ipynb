{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dbf1502-89db-4fed-a891-005393c451a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import sklearn\n",
    "import imblearn as imb\n",
    "# print(\"imblearn version: \",imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "from rdkit import Chem\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import utils\n",
    "from VisUtils import *\n",
    "from split_data import *\n",
    "from RF_GSCV import *\n",
    "# from RF_Utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff68eef-dc5a-46e0-9c97-f0f4dd32cbcf",
   "metadata": {},
   "source": [
    "# Using pre-split files \n",
    "These are the original 'og' splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "695baa08-22b7-4d40-b256-fc31f96e939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1635, 306]) torch.Size([1635]) torch.Size([409, 306]) torch.Size([409])\n"
     ]
    }
   ],
   "source": [
    "split_path = '../../../../../data/NEK_data_4Berkeley/NEK2/'\n",
    "\n",
    "train_x_df = pd.read_csv(split_path+\"/NEK2_inhibition_random_fold1_trainX.csv\")\n",
    "train_y_df= pd.read_csv(split_path+\"/NEK2_inhibition_random_fold1_trainY.csv\")\n",
    "test_x_df= pd.read_csv(split_path+\"/NEK2_inhibition_random_fold1_testX.csv\")\n",
    "test_y_df= pd.read_csv(split_path+\"/NEK2_inhibition_random_fold1_testY.csv\")\n",
    "train_x = torch.from_numpy(train_x_df.to_numpy())\n",
    "train_y = torch.from_numpy(train_y_df.to_numpy().reshape(-1))\n",
    "test_x = torch.from_numpy(test_x_df.to_numpy())\n",
    "test_y = torch.from_numpy(test_y_df.to_numpy().reshape(-1))\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cad04e-203c-436d-8708-15e72bfbe336",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4517c25-a295-42cf-94b4-586f0ca1d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Scale data\n",
    "x_df= pd.concat([train_x_df, test_x_df])\n",
    "scaling=StandardScaler()\n",
    " \n",
    "# Use fit and transform method \n",
    "scaling.fit(x_df)\n",
    "Scaled_data=scaling.transform(x_df)\n",
    "train_x_scaledtemp = scaling.transform(train_x_df)\n",
    "test_x_scaledtemp = scaling.transform(test_x_df) \n",
    "\n",
    "undersample = RandomUnderSampler()\n",
    "train_x_temp1, train_y_temp1 = undersample.fit_resample(train_x_scaledtemp, train_y_df)\n",
    "train_x_UNDER = train_x_temp1\n",
    "train_y_UNDER = train_y_temp1.to_numpy().flatten()\n",
    "test_y_UNDER = test_y_df.to_numpy().flatten()\n",
    "test_x_UNDER = test_x_scaledtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e26955-f606-434a-8ca6-6b5c07f6fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223, 306), (223,), (408, 306), (408,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # back to df for saving \n",
    "data_path = 'data/'\n",
    "train_x_df_UNDER = pd.DataFrame(train_x_UNDER) \n",
    "train_y_df_UNDER = pd.DataFrame(train_y_UNDER) \n",
    "test_y_df_UNDER = pd.DataFrame(test_y_UNDER)\n",
    "test_x_df_UNDER = pd.DataFrame(test_x_UNDER)\n",
    "\n",
    "train_x_df_UNDER.to_csv(data_path+'inhib/inhib_train_x_UNDER.csv', index=False, header=False)\n",
    "train_y_df_UNDER.to_csv(data_path+'inhib/inhib_train_y_UNDER.csv', index=False, header=False) \n",
    "test_y_df_UNDER.to_csv(data_path+'inhib/inhib_test_y_UNDER.csv', index=False, header=False) \n",
    "test_x_df_UNDER.to_csv(data_path+'inhib/inhib_test_x_UNDER.csv', index=False, header=False)\n",
    "\n",
    "train_x_df_UNDER = pd.read_csv(split_path+'inhib/inhib_train_x_UNDER.csv')\n",
    "train_y_df_UNDER= pd.read_csv(split_path+'inhib/inhib_train_y_UNDER.csv')\n",
    "test_x_df_UNDER= pd.read_csv(split_path+'inhib/inhib_test_x_UNDER.csv')\n",
    "test_y_df_UNDER= pd.read_csv(split_path+'inhib/inhib_test_y_UNDER.csv')\n",
    "\n",
    "train_x_UNDER = train_x_df_UNDER.to_numpy()\n",
    "train_y_UNDER = train_y_df_UNDER.to_numpy().reshape(-1)\n",
    "test_x_UNDER = test_x_df_UNDER.to_numpy()\n",
    "test_y_UNDER = test_y_df_UNDER.to_numpy().reshape(-1)\n",
    "train_x_UNDER.shape, train_y_UNDER.shape, test_x_UNDER.shape, test_y_UNDER.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed93836-d6d2-4e04-8ac9-bfa15e909a59",
   "metadata": {},
   "source": [
    "# SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d4f090-8128-4273-be17-6929515931a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3045, 306), (3045,), (408, 306), (408,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Scale data\n",
    "split_path = '../../../../../data/NEK_data_4Berkeley/NEK2/'\n",
    "data_path = 'data/inhib/'\n",
    "\n",
    "oversample = SMOTE() \n",
    "# train_x_temp2, train_y_temp2 = oversample.fit_resample(train_x_temp, train_y_df)\n",
    "train_x_temp2, train_y_temp2 = oversample.fit_resample(train_x_scaledtemp, train_y_df)\n",
    "train_x_SMOTE = train_x_temp2\n",
    "train_y_SMOTE = train_y_temp2.to_numpy().flatten()\n",
    "test_y_SMOTE = test_y_df.to_numpy().flatten()\n",
    "\n",
    "# back to df for saving \n",
    "train_x_df_SMOTE = pd.DataFrame(train_x_SMOTE) \n",
    "train_y_df_SMOTE = pd.DataFrame(train_y_SMOTE) \n",
    "test_y_df_SMOTE = pd.DataFrame(test_y_SMOTE)\n",
    "test_x_df_SMOTE = pd.DataFrame(test_x_scaledtemp)\n",
    "\n",
    "train_x_df_SMOTE.to_csv(data_path+'inhib_train_x_SMOTE.csv', index=False, header=False)\n",
    "train_y_df_SMOTE.to_csv(data_path+'inhib_train_y_SMOTE.csv', index=False, header=False) \n",
    "test_y_df_SMOTE.to_csv(data_path+'inhib_test_y_SMOTE.csv', index=False, header=False) \n",
    "test_x_df_SMOTE.to_csv(data_path+'inhib_test_x_SMOTE.csv', index=False, header=False) \n",
    "train_x_df_SMOTE = pd.read_csv(data_path+'inhib_train_x_SMOTE.csv')\n",
    "train_y_df_SMOTE= pd.read_csv(data_path+'inhib_train_y_SMOTE.csv')\n",
    "test_x_df_SMOTE= pd.read_csv(data_path+'inhib_test_x_SMOTE.csv')\n",
    "test_y_df_SMOTE= pd.read_csv(data_path+'inhib_test_y_SMOTE.csv')\n",
    "\n",
    "train_x_SMOTE= train_x_df_SMOTE.to_numpy()\n",
    "train_y_SMOTE = train_y_df_SMOTE.to_numpy().reshape(-1)\n",
    "test_x_SMOTE = test_x_df_SMOTE.to_numpy()\n",
    "test_y_SMOTE = test_y_df_SMOTE.to_numpy().reshape(-1)\n",
    "train_x_SMOTE.shape, train_y_SMOTE.shape, test_x_SMOTE.shape, test_y_SMOTE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3468b-466d-44f8-a4ef-94c8bb875ada",
   "metadata": {},
   "source": [
    "# ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973f2aa7-4038-49b3-bab9-8aba35cb4cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 306), (3036,), (408, 306), (408,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/inhib/'\n",
    "adasyn = ADASYN() \n",
    "train_x_temp3, train_y_temp3 = adasyn.fit_resample(train_x_scaledtemp, train_y_df)\n",
    "train_x_ADASYN = train_x_temp3\n",
    "train_y_ADASYN = train_y_temp3.to_numpy().flatten()\n",
    "test_y_ADASYN = test_y_df.to_numpy().flatten()\n",
    "\n",
    "# # back to df for saving \n",
    "train_x_df_ADASYN  = pd.DataFrame(train_x_ADASYN ) \n",
    "train_y_df_ADASYN  = pd.DataFrame(train_y_ADASYN ) \n",
    "test_y_df_ADASYN  = pd.DataFrame(test_y_ADASYN )\n",
    "test_x_df_ADASYN  = pd.DataFrame(test_x_scaledtemp)\n",
    "\n",
    "train_x_df_ADASYN .to_csv(data_path+'inhib_train_x_ADASYN.csv', index=False, header=False)\n",
    "train_y_df_ADASYN .to_csv(data_path+'inhib_train_y_ADASYN.csv', index=False, header=False) \n",
    "test_y_df_ADASYN .to_csv(data_path+'inhib_test_y_ADASYN.csv', index=False, header=False) \n",
    "test_x_df_ADASYN .to_csv(data_path+'inhib_test_x_ADASYN.csv', index=False, header=False) \n",
    "\n",
    "\n",
    "train_x_df_ADASYN = pd.read_csv(data_path+'inhib_train_x_ADASYN.csv')\n",
    "train_y_df_ADASYN= pd.read_csv(data_path+'inhib_train_y_ADASYN.csv')\n",
    "test_x_df_ADASYN= pd.read_csv(data_path+'inhib_test_x_ADASYN.csv')\n",
    "test_y_df_ADASYN= pd.read_csv(data_path+'inhib_test_y_ADASYN.csv')\n",
    "\n",
    "train_x_ADASYN= train_x_df_ADASYN.to_numpy()\n",
    "train_y_ADASYN = train_y_df_ADASYN.to_numpy().reshape(-1)\n",
    "test_x_ADASYN = test_x_df_ADASYN.to_numpy()\n",
    "test_y_ADASYN = test_y_df_ADASYN.to_numpy().reshape(-1)\n",
    "train_x_ADASYN.shape, train_y_ADASYN.shape, test_x_ADASYN.shape, test_y_ADASYN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f81760-fea3-48b1-8a7c-941a310e16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1635, 306) (1635,) (409, 306) (409,)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/inhib/'\n",
    "x_df = pd.concat([train_x_df, test_x_df])\n",
    "scaling = StandardScaler()\n",
    "\n",
    "\n",
    "scaling.fit(x_df)\n",
    "train_x_scaledtemp = scaling.transform(train_x_df)\n",
    "test_x_scaledtemp = scaling.transform(test_x_df)\n",
    "\n",
    "train_x_scaled_df = pd.DataFrame(train_x_scaledtemp)\n",
    "test_x_scaled_df = pd.DataFrame(test_x_scaledtemp)\n",
    "train_y_df = pd.DataFrame(train_y_df).reset_index(drop=True) \n",
    "test_y_df = pd.DataFrame(test_y_df).reset_index(drop=True)   \n",
    "\n",
    "train_x_scaled_df.to_csv(data_path + 'inhib_train_x_scaledoriginal.csv', index=False, header=False)\n",
    "train_y_df.to_csv(data_path + 'inhib_train_y_scaledoriginal.csv', index=False, header=False)\n",
    "test_x_scaled_df.to_csv(data_path + 'inhib_test_x_scaledoriginal.csv', index=False, header=False)\n",
    "test_y_df.to_csv(data_path + 'inhib_test_y_scaledoriginal.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "train_x_scaled_df = pd.read_csv(data_path + 'inhib_train_x_scaledoriginal.csv', header=None)\n",
    "train_y_df = pd.read_csv(data_path + 'inhib_train_y_scaledoriginal.csv', header=None)\n",
    "test_x_scaled_df = pd.read_csv(data_path + 'inhib_test_x_scaledoriginal.csv', header=None)\n",
    "test_y_df = pd.read_csv(data_path + 'inhib_test_y_scaledoriginal.csv', header=None)\n",
    "\n",
    "train_x_scaled = train_x_scaled_df.to_numpy()\n",
    "train_y = train_y_df.to_numpy().flatten()\n",
    "test_x_scaled = test_x_scaled_df.to_numpy()\n",
    "test_y = test_y_df.to_numpy().flatten()\n",
    "\n",
    "\n",
    "print(train_x_scaled.shape, train_y.shape, test_x_scaled.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbac269-18ca-4350-803b-ad712a58036e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsci",
   "language": "python",
   "name": "atomsci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
